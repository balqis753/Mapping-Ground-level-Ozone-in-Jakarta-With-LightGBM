# -*- coding: utf-8 -*-
"""Pengolahan TA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Qoo2h0RfUaEd88bl1s334phDKr5H7Fg

# Preparation Stage
Pada tahapan persiapan ini dilakukan penentuan area (AOI), import library yang akan digunakan, serta pembentukan grid. Setelah itu dilakukan preprocessing dan processing dari multi source satellite imagery dan ground station.
"""

# install necessary package
!pip install geemap
!pip install pycrs
!pip install optuna
!pip install lightgbm
!pip install rioxarray
!pip install xarray rasterio geopandas pykrige matplotlib
!pip install scikit-gstat
!pip install -U scikit-learn
!pip install gdal
!pip install cartopy

# Import packages
import ee
import geemap
import geemap.foliumap as eefolium
import xarray as xr
import numpy as np
import pandas as pd
import seaborn as sns
import geopandas as gpd
import matplotlib.pyplot as plt
import rasterio
import lightgbm as lgb
import optuna
import os
import rioxarray as rxr
from IPython.display import display, Image
import matplotlib.dates as mdates
from pykrige.ok import OrdinaryKriging
from shapely.geometry import Point
from rasterio.features import rasterize
from rasterio.transform import from_origin
from rasterio.plot import show
from scipy.ndimage import zoom
from rasterio import features
from scipy.interpolate import griddata
from rasterio.enums import Resampling
from rasterio.warp import calculate_default_transform, reproject
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from skimage.transform import resize
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from lightgbm import LGBMRegressor
from sklearn.model_selection import cross_validate, KFold
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score ,mean_absolute_percentage_error
import warnings # Import the warnings module
warnings.filterwarnings('ignore')
from skgstat import Variogram
from osgeo import gdal
from shapely.geometry import Point

from google.colab import drive
drive.mount('/content/drive')

print("Setup completed")

# Melakukan autentikasi dan mendefinisikan Google Cloud Project yang akan digunakan
ee.Authenticate()
ee.Initialize(project='ee-sidangapril2024')

Map = geemap.Map()
Map

AOI =  ee.Geometry.Polygon(
        [[[106.39841141843407, -5.896207900009297],
          [106.39841141843407, -6.6415358269976075],
          [107.26633134030907, -6.6415358269976075],
          [107.26633134030907, -5.896207900009297]]])

Map.addLayer(AOI, {}, "AOI")
Map.centerObject(AOI, 8)

"""# NITROGEN DIOKSIDA (NO2)

**Akuisisi Citra**
"""

# === Load dataset TROPOMI O3 dan filter berdasarkan waktu dan lokasi ===
NO2_collection = ee.ImageCollection("COPERNICUS/S5P/NRTI/L3_NO2") \
    .select('tropospheric_NO2_column_number_density') \
    .filterDate('2022-01-01', '2024-12-31') \
    .filterBounds(AOI)

# === Konstanta untuk konversi ===
MOLAR_MASS_NO2 = 46.0055       # Molar mass of NO2 in g/mol
HEIGHT_TROPOSPHERE = 10000      # Height in meters (10 km)
A = 1e6                       # Conversion factor from g/mÂ³ to Âµg/mÂ³

# === Faktor konversi mol/mÂ² ke Âµg/mÂ³ ===
CONVERSION_FACTOR = (MOLAR_MASS_NO2 * A) / HEIGHT_TROPOSPHERE

# === List bulan dan tahun ===
months = list(range(1, 13))
years = list(range(2022, 2025))

# === Looping untuk menghasilkan image bulanan yang telah dikonversi ===
NO2_monthly_images = []

for y in years:
    for m in months:
        filtered = NO2_collection \
            .filter(ee.Filter.calendarRange(y, y, 'year')) \
            .filter(ee.Filter.calendarRange(m, m, 'month'))

        monthly_mean_mol = filtered.mean()

        # === Konversi ke Âµg/mÂ³ ===
        monthly_mean_ug = monthly_mean_mol.multiply(CONVERSION_FACTOR) \
            .clip(AOI) \
            .set('year', y) \
            .set('month', m) \
            .set('system:time_start', ee.Date.fromYMD(y, m, 1)) \
            .set('label', f"NO2_{y:04d}_{m:02d}")

        NO2_monthly_images.append(monthly_mean_ug)

# === Konversi list ke ImageCollection ===
NO2_monthly_collection = ee.ImageCollection(NO2_monthly_images)

# === Ekspor setiap citra bulanan ke Google Drive ===
for image in NO2_monthly_images:
    label = image.get('label').getInfo()  # Take the label name
    task = ee.batch.Export.image.toDrive(
        image=image,
        description=label,
        folder='Tropomi_NO2_Monthly',
        fileNamePrefix=label,
        region=AOI,
        crs='EPSG:32748',
        scale=1113.2,
        maxPixels=1e13
    )
    task.start()
    print(f"Export task '{label}' has started.")

"""**Missing Value Filling**"""

import glob

# === Path setting ===
input_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_NO2_Monthly"
output_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_NO2_Monthly/output_interpolasi_no2"
os.makedirs(output_folder, exist_ok=True)


# === Multiple raster loops ===
raster_files = glob.glob(os.path.join(input_folder, "*.tif"))

for raster_file in raster_files:
    print(f"Processing: {os.path.basename(raster_file)}")

    with rasterio.open(raster_file) as src:
        no2 = src.read(1).astype(float)
        no2[no2 < 0] = np.nan  # Sentinel-5P usually stores invalid values â€‹â€‹< 0
        transform = src.transform
        crs = src.crs
        shape = src.shape

        # === Interpolate the entire raster area ===
        x = np.arange(shape[1])
        y = np.arange(shape[0])
        xv, yv = np.meshgrid(x, y)

        x_flat = xv.flatten()
        y_flat = yv.flatten()
        z_flat = no2.flatten()

        valid = ~np.isnan(z_flat)
        x_valid = x_flat[valid]
        y_valid = y_flat[valid]
        z_valid = z_flat[valid]

        # Linear interpolation
        z_interp = griddata(
            (x_valid, y_valid), z_valid, (xv, yv), method='linear'
        )

        # Combine the interpolation results over all areas
        no2_filled = np.where(np.isnan(no2), z_interp, no2)

        # === Save output ===
        output_path = os.path.join(output_folder, os.path.basename(raster_file))

        with rasterio.open(
            output_path, "w",
            driver="GTiff",
            height=shape[0],
            width=shape[1],
            count=1,
            dtype="float32",
            crs=crs,
            transform=transform
        ) as dst:
            dst.write(no2_filled.astype("float32"), 1)

        # === Visualisasi ===
        fig, axs = plt.subplots(1, 2, figsize=(12, 5))
        cmap = 'viridis'

        im1 = axs[0].imshow(no2, cmap=cmap)
        axs[0].set_title("Before Interpolation")
        plt.colorbar(im1, ax=axs[0], orientation="vertical", fraction=0.05)

        im2 = axs[1].imshow(no2_filled, cmap=cmap)
        axs[1].set_title("After Interpolation")
        plt.colorbar(im2, ax=axs[1], orientation="vertical", fraction=0.05)

        plt.suptitle(os.path.basename(raster_file))
        plt.tight_layout()
        plt.show()

print("\nâœ… All Sentinel-5P NOâ‚‚ rasters were successfully filled and visualized.")

"""**Downscaling**"""

import glob

# === Visualization before and after downscaling ===
def visualize_comparison(before_array, after_array, title):
    fig, axs = plt.subplots(1, 2, figsize=(12, 5))
    cmap = 'viridis'

    vmin = min(np.nanmin(before_array), np.nanmin(after_array))
    vmax = max(np.nanmax(before_array), np.nanmax(after_array))

    im1 = axs[0].imshow(before_array, cmap=cmap, vmin=vmin, vmax=vmax)
    axs[0].set_title("Before Downcaling")
    axs[0].set_xlabel("Colomn")
    axs[0].set_ylabel("Row")
    plt.colorbar(im1, ax=axs[0], orientation="vertical", fraction=0.05)

    im2 = axs[1].imshow(after_array, cmap=cmap, vmin=vmin, vmax=vmax)
    axs[1].set_title("After Downscaling (1000m)")
    axs[1].set_xlabel("Colomn")
    axs[1].set_ylabel("Row")
    plt.colorbar(im2, ax=axs[1], orientation="vertical", fraction=0.05)

    plt.suptitle(title, fontsize=14)
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

# === Statistical Evaluation ===
def evaluate_stats(before, after, filename):
    after_resized = resize(after, before.shape, order=1, preserve_range=True, anti_aliasing=False)

    mask = ~np.isnan(before) & ~np.isnan(after_resized)
    if np.count_nonzero(mask) == 0:
        print(f"âš ï¸ {filename} not evaluable (all NaN).")
        return None

    y_true = before[mask]
    y_pred = after_resized[mask]

    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    print(f"ðŸ“Š Evaluation Statistics: {filename}")
    print(f"- RMSE : {rmse:.2e}")
    print(f"- MSE  : {mse:.2e}")
    print(f"- MAE  : {mae:.2e}")
    print(f"- RÂ²   : {r2:.4f}")
    print()

    return {
        "Filename": filename,
        "RMSE": rmse,
        "MSE": mse,
        "MAE": mae,
        "R2": r2
    }

# === Raster downscaling function to 1000 m resolution ===
def resample_raster_to_1km(input_path, output_path, visualize=True):
    with rasterio.open(input_path) as src:
        src_array = src.read(1)
        src_transform = src.transform
        src_crs = src.crs
        src_bounds = src.bounds

        dst_transform, width, height = calculate_default_transform(
            src_crs, src_crs, src.width, src.height, *src_bounds, resolution=1000
        )

        kwargs = src.meta.copy()
        kwargs.update({
            'crs': src_crs,
            'transform': dst_transform,
            'width': width,
            'height': height
        })

        with rasterio.open(output_path, 'w', **kwargs) as dst:
            dst_array = np.empty((height, width), dtype=src.dtypes[0])
            reproject(
                source=src_array,
                destination=dst_array,
                src_transform=src_transform,
                src_crs=src_crs,
                dst_transform=dst_transform,
                dst_crs=src_crs,
                resampling=Resampling.bilinear,
                dst_nodata=np.nan,
                src_nodata=np.nan
            )
            dst.write(dst_array, 1)

    print(f"âœ… {os.path.basename(input_path)} successfully downscaled to 1000m")

    if visualize:
        visualize_comparison(src_array, dst_array, os.path.basename(input_path))

    return src_array, dst_array

# === Batch processing ===
input_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_NO2_Monthly/output_interpolasi_no2"
output_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_NO2_Monthly/no2_1km"
os.makedirs(output_folder, exist_ok=True)

raster_files = glob.glob(os.path.join(input_folder, "*.tif"))
results = []

for raster_file in raster_files:
    filename = os.path.basename(raster_file)
    output_path = os.path.join(output_folder, f"{os.path.splitext(filename)[0]}_resampled.tif")

    before, after = resample_raster_to_1km(raster_file, output_path, visualize=True)
    stats = evaluate_stats(before, after, filename)
    if stats:
        results.append(stats)

"""**Layer Stacking**"""

# === Directory Where NO2 Raster Files are Stored ===
input_dir = '/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_NO2_Monthly/no2_1km'  # Ganti dengan direktori sebenarnya

# List of Raster Files
raster_files = [
    'NO2_2022_01_resampled.tif', 'NO2_2022_02_resampled.tif', 'NO2_2022_03_resampled.tif',
    'NO2_2022_04_resampled.tif', 'NO2_2022_05_resampled.tif', 'NO2_2022_06_resampled.tif',
    'NO2_2022_07_resampled.tif', 'NO2_2022_08_resampled.tif', 'NO2_2022_09_resampled.tif',
    'NO2_2022_10_resampled.tif', 'NO2_2022_11_resampled.tif', 'NO2_2022_12_resampled.tif',
    'NO2_2023_01_resampled.tif', 'NO2_2023_02_resampled.tif', 'NO2_2023_03_resampled.tif',
    'NO2_2023_04_resampled.tif', 'NO2_2023_05_resampled.tif', 'NO2_2023_06_resampled.tif',
    'NO2_2023_07_resampled.tif', 'NO2_2023_08_resampled.tif', 'NO2_2023_09_resampled.tif',
    'NO2_2023_10_resampled.tif', 'NO2_2023_11_resampled.tif', 'NO2_2023_12_resampled.tif',
    'NO2_2024_01_resampled.tif', 'NO2_2024_02_resampled.tif', 'NO2_2024_03_resampled.tif',
    'NO2_2024_04_resampled.tif', 'NO2_2024_05_resampled.tif', 'NO2_2024_06_resampled.tif',
    'NO2_2024_07_resampled.tif', 'NO2_2024_08_resampled.tif', 'NO2_2024_09_resampled.tif',
    'NO2_2024_10_resampled.tif', 'NO2_2024_11_resampled.tif', 'NO2_2024_12_resampled.tif'
]

# === Initialize List to Store Raster Objects ===
raster_list = []

# === Read All Rasters and Add Them to the List ===
for file in raster_files:
    file_path = os.path.join(input_dir, file)
    raster = rxr.open_rasterio(file_path)
    raster_list.append(raster)

# === Stack all rasters into one layer with xarray.concat ===
stacked_raster = xr.concat(raster_list, dim='band')

# === Save the stacking results to a new file using rioxarray ===
stacked_raster.rio.to_raster('/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_NO2_Monthly/Stacking Layer/NO2_Jakarta.tif')

print("Stacking is complete and the file is saved.")

"""# FORMALDEHIDA (HCHO)

**Akuisisi Citra**
"""

# === Load dataset TROPOMI O3 dan filter berdasarkan waktu dan lokasi ===
HCHO_collection = ee.ImageCollection("COPERNICUS/S5P/NRTI/L3_HCHO") \
    .select('tropospheric_HCHO_column_number_density') \
    .filterDate('2022-01-01', '2024-12-31') \
    .filterBounds(AOI)

# === Konstanta untuk konversi ===
molar_mass_HCHO = 30.031       # gram/mol
HEIGHT_TROPOSPHERE = 10000      # meter
GRAM_TO_MICROGRAM = 1e6

# === Faktor konversi mol/mÂ² ke Âµg/mÂ³ ===
CONVERSION_FACTOR = (molar_mass_HCHO  * GRAM_TO_MICROGRAM) /  HEIGHT_TROPOSPHERE

# === List bulan dan tahun ===
months = list(range(1, 13))
years = list(range(2022, 2025))

# === Looping untuk menghasilkan image bulanan yang telah dikonversi ===
HCHO_monthly_images = []

for y in years:
    for m in months:
        filtered = HCHO_collection \
            .filter(ee.Filter.calendarRange(y, y, 'year')) \
            .filter(ee.Filter.calendarRange(m, m, 'month'))

        monthly_mean_mol = filtered.mean()

        # === Konversi ke Âµg/mÂ³ ===
        monthly_mean_ug = monthly_mean_mol.multiply(CONVERSION_FACTOR) \
            .clip(AOI) \
            .set('year', y) \
            .set('month', m) \
            .set('system:time_start', ee.Date.fromYMD(y, m, 1)) \
            .set('label', f"HCHO_{y:04d}_{m:02d}")

        HCHO_monthly_images.append(monthly_mean_ug)

# === Konversi list ke ImageCollection ===
HCHO_monthly_collection = ee.ImageCollection(HCHO_monthly_images)

# === Ekspor setiap citra bulanan ke Google Drive ===
for image in HCHO_monthly_images:
    label = image.get('label').getInfo()  # Ambil nama label
    task = ee.batch.Export.image.toDrive(
        image=image,
        description=label,
        folder='Tropomi_HCHO_Monthly',
        fileNamePrefix=label,
        scale=1113.2,
        region=AOI,
        crs='EPSG:32748',
        maxPixels=1e13
    )
    task.start()
    print(f"Tugas ekspor '{label}' telah dimulai.")

"""**Missing Value Filling**"""

# === PATH SETTING ===
input_folder = "/content/drive/MyDrive/Tropomi_HCHO_Monthly"  # Ganti dengan folder data NO2 Anda
shapefile_path = "/content/drive/MyDrive/JABODETABEK/JABODETABEK.shp"
output_folder = "/content/drive/MyDrive/Tropomi_HCHO_Monthly/output_interpolasi_hcho"
os.makedirs(output_folder, exist_ok=True)

# === LOAD SHAPEFILE DARATAN ===
gdf = gpd.read_file(shapefile_path)

# === LOOP MULTIPLE RASTER ===
raster_files = glob.glob(os.path.join(input_folder, "*.tif"))

for raster_file in raster_files:
    print(f"Processing: {os.path.basename(raster_file)}")

    with rasterio.open(raster_file) as src:
        hcho = src.read(1).astype(float)
        hcho[hcho < 0] = np.nan  # Sentinel-5P biasanya menyimpan nilai tidak valid < 0
        transform = src.transform
        crs = src.crs
        shape = src.shape

        # Reproject shapefile ke CRS raster
        gdf_raster_crs = gdf.to_crs(crs)

        # === Rasterize shapefile daratan ===
        mask = features.rasterize(
            ((geom, 1) for geom in gdf_raster_crs.geometry),
            out_shape=shape,
            transform=transform,
            fill=0,
            dtype='uint8'
        )

        # === Interpolasi hanya di daratan ===
        x = np.arange(shape[1])
        y = np.arange(shape[0])
        xv, yv = np.meshgrid(x, y)

        x_flat = xv.flatten()
        y_flat = yv.flatten()
        z_flat = hcho.flatten()
        mask_flat = mask.flatten()

        valid = ~np.isnan(z_flat) & (mask_flat == 1)
        x_valid = x_flat[valid]
        y_valid = y_flat[valid]
        z_valid = z_flat[valid]

        # Linear interpolation
        z_interp = griddata(
            (x_valid, y_valid), z_valid, (xv, yv), method='linear'
        )

        # Gabungkan hasil interpolasi hanya di area daratan
        hcho_filled = np.where((np.isnan(hcho)) & (mask == 1), z_interp, hcho)

        # === Save output ===
        output_path = os.path.join(output_folder, os.path.basename(raster_file))

        with rasterio.open(
            output_path, "w",
            driver="GTiff",
            height=shape[0],
            width=shape[1],
            count=1,
            dtype="float32",
            crs=crs,
            transform=transform
        ) as dst:
            dst.write(hcho_filled.astype("float32"), 1)

        # === Visualization ===
        fig, axs = plt.subplots(1, 2, figsize=(12, 5))
        cmap = 'viridis'

        im1 = axs[0].imshow(hcho, cmap=cmap)
        axs[0].set_title("Sebelum Interpolasi")
        plt.colorbar(im1, ax=axs[0], orientation="vertical", fraction=0.05)

        im2 = axs[1].imshow(hcho_filled, cmap=cmap)
        axs[1].set_title("Setelah Interpolasi")
        plt.colorbar(im2, ax=axs[1], orientation="vertical", fraction=0.05)

        plt.suptitle(os.path.basename(raster_file))
        plt.tight_layout()
        plt.show()

print("\nâœ… Semua raster Sentinel-5P HCHO berhasil diisi dan divisualisasikan.")

"""**Downscaling**"""

# === Visualisasi Sebelum dan Setelah Downscaling ===
def visualize_comparison(before_array, after_array, title):
    fig, axs = plt.subplots(1, 2, figsize=(12, 5))
    cmap = 'viridis'

    vmin = min(np.nanmin(before_array), np.nanmin(after_array))
    vmax = max(np.nanmax(before_array), np.nanmax(after_array))

    im1 = axs[0].imshow(before_array, cmap=cmap, vmin=vmin, vmax=vmax)
    axs[0].set_title("Sebelum Resampling")
    axs[0].set_xlabel("Kolom")
    axs[0].set_ylabel("Baris")
    plt.colorbar(im1, ax=axs[0], orientation="vertical", fraction=0.05)

    im2 = axs[1].imshow(after_array, cmap=cmap, vmin=vmin, vmax=vmax)
    axs[1].set_title("Setelah Resampling (1000m)")
    axs[1].set_xlabel("Kolom")
    axs[1].set_ylabel("Baris")
    plt.colorbar(im2, ax=axs[1], orientation="vertical", fraction=0.05)

    plt.suptitle(title, fontsize=14)
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

# === Downscaling Ke Resolusi 1000 m ===
def resample_raster_to_1km(input_path, output_path, target_resolution=1000, visualize=True):
    with rasterio.open(input_path) as src:
        src_array = src.read(1)
        src_transform = src.transform
        src_crs = src.crs
        src_bounds = src.bounds

        dst_transform, width, height = calculate_default_transform(
            src_crs, src_crs, src.width, src.height, *src_bounds, resolution=target_resolution
        )

        kwargs = src.meta.copy()
        kwargs.update({
            'crs': src_crs,
            'transform': dst_transform,
            'width': width,
            'height': height
        })

        with rasterio.open(output_path, 'w', **kwargs) as dst:
            dst_array = np.empty((height, width), dtype=src.dtypes[0])
            reproject(
                source=src_array,
                destination=dst_array,
                src_transform=src_transform,
                src_crs=src_crs,
                dst_transform=dst_transform,
                src_nodata=np.nan,
                dst_nodata=np.nan,
                dst_crs=src_crs,
                resampling=Resampling.bilinear

            )
            dst.write(dst_array, 1)

    print(f"âœ… {os.path.basename(input_path)} berhasil di-resample ke 1000m")

    if visualize:
        visualize_comparison(src_array, dst_array, os.path.basename(input_path))

# === Batch Processing ===
input_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_HCHO_Monthly/output_interpolasi_hcho"
output_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_HCHO_Monthly/output_resampling_hcho"
os.makedirs(output_folder, exist_ok=True)

raster_files = glob(os.path.join(input_folder, "*.tif"))

for raster_file in raster_files:
    filename = os.path.basename(raster_file)
    output_path = os.path.join(output_folder, f"{os.path.splitext(filename)[0]}.tif")
    resample_raster_to_1km(raster_file, output_path, visualize=True)

# === Evaluasi Statistik ===
def evaluate_resampling_accuracy(original_path, resampled_path):
    with rasterio.open(original_path) as src1, rasterio.open(resampled_path) as src2:
        original = src1.read(1)
        resampled = src2.read(1)

        # Upscale hasil resampling ke dimensi asli
        zoom_factors = (
            original.shape[0] / resampled.shape[0],
            original.shape[1] / resampled.shape[1]
        )
        resampled_upscaled = zoom(resampled, zoom_factors, order=1)  # bilinear interpolation

        # Mask untuk membandingkan hanya nilai valid (bukan NaN)
        mask = ~np.isnan(original) & ~np.isnan(resampled_upscaled)
        y_true = original[mask]
        y_pred = resampled_upscaled[mask]

        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)

        return {
            "filename": os.path.basename(original_path),
            "RMSE": rmse,
            "MAE": mae,
            "MSE": mse,
            "R2": r2
        }

# === Batch Evaluasi ===
original_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_HCHO_Monthly/output_interpolasi_hcho"
resampled_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_HCHO_Monthly/output_resampling_hcho"

original_files = sorted(glob(os.path.join(original_folder, "*.tif")))
resampled_files = sorted(glob(os.path.join(resampled_folder, "*.tif")))

results = []
for orig, resamp in zip(original_files, resampled_files):
    res = evaluate_resampling_accuracy(orig, resamp)
    print(f"ðŸ“Š {res['filename']}: RMSE={res['RMSE']:.2e}, MAE={res['MAE']:.2e}, MSE={res['MSE']:.2e}, R2={res['R2']:.4f}")
    results.append(res)

"""**Layer Stacking**"""

# === Direktori tempat file raster disimpan ===
input_dir = '/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_HCHO_Monthly/output_resampling_hcho'  # Ganti dengan direktori sebenarnya

# === Daftar file raster ===
raster_files = [
    'HCHO_2022_01.tif', 'HCHO_2022_02.tif', 'HCHO_2022_03.tif',
    'HCHO_2022_04.tif', 'HCHO_2022_05.tif', 'HCHO_2022_06.tif',
    'HCHO_2022_07.tif', 'HCHO_2022_08.tif', 'HCHO_2022_09.tif',
    'HCHO_2022_10.tif', 'HCHO_2022_11.tif', 'HCHO_2022_12.tif',
    'HCHO_2023_01.tif', 'HCHO_2023_02.tif', 'HCHO_2023_03.tif',
    'HCHO_2023_04.tif', 'HCHO_2023_05.tif', 'HCHO_2023_06.tif',
    'HCHO_2023_07.tif', 'HCHO_2023_08.tif', 'HCHO_2023_09.tif',
    'HCHO_2023_10.tif', 'HCHO_2023_11.tif', 'HCHO_2023_12.tif',
    'HCHO_2024_01.tif', 'HCHO_2024_02.tif', 'HCHO_2024_03.tif',
    'HCHO_2024_04.tif', 'HCHO_2024_05.tif', 'HCHO_2024_06.tif',
    'HCHO_2024_07.tif', 'HCHO_2024_08.tif', 'HCHO_2024_09.tif',
    'HCHO_2024_10.tif', 'HCHO_2024_11.tif', 'HCHO_2024_12.tif'
]


# === Inisialisasi list untuk menyimpan objek raster ===
raster_list = []

# === Baca semua raster dan tambahkan ke list ===
for file in raster_files:
    file_path = os.path.join(input_dir, file)
    raster = rxr.open_rasterio(file_path)
    raster_list.append(raster)

# === Stack semua raster menjadi satu dengan xarray.concat ===
stacked_raster = xr.concat(raster_list, dim='band')

# === Simpan hasil stacking ke file baru menggunakan rioxarray ===
stacked_raster.rio.to_raster('/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_HCHO_Monthly/Stacking Layer/HCHO_Jakarta.tif')

print("Stacking selesai dan file disimpan.")

"""# KOLOM OZON

Data ini diambil dari Sentinel-5P menggunakan Google Earth Engine

**Akuisisi Citra**
"""

# === Load dataset TROPOMI O3 dan filter berdasarkan waktu dan lokasi
O3_collection = ee.ImageCollection("COPERNICUS/S5P/NRTI/L3_O3") \
    .select('O3_column_number_density') \
    .filterDate('2022-01-01', '2024-12-31') \
    .filterBounds(AOI)

# Konstanta untuk konversi
molar_mass_O3 = 48             # gram/mol
HEIGHT_TROPOSPHERE = 10000      # meter
GRAM_TO_MICROGRAM = 1e6

# Faktor konversi mol/mÂ² ke Âµg/mÂ³
CONVERSION_FACTOR = (molar_mass_O3 * GRAM_TO_MICROGRAM) / HEIGHT_TROPOSPHERE

# List bulan dan tahun
months = list(range(1, 13))
years = list(range(2022, 2025))

# Looping untuk menghasilkan image bulanan yang telah dikonversi
O3_monthly_images = []

for y in years:
    for m in months:
        filtered = O3_collection \
            .filter(ee.Filter.calendarRange(y, y, 'year')) \
            .filter(ee.Filter.calendarRange(m, m, 'month'))

        monthly_mean_mol = filtered.mean()

        # Konversi ke Âµg/mÂ³
        monthly_mean_ug = monthly_mean_mol.multiply(CONVERSION_FACTOR) \
            .clip(AOI) \
            .set('year', y) \
            .set('month', m) \
            .set('system:time_start', ee.Date.fromYMD(y, m, 1)) \
            .set('label', f"O3_{y:04d}_{m:02d}")

        O3_monthly_images.append(monthly_mean_ug)

# Konversi list ke ImageCollection
O3_monthly_collection = ee.ImageCollection(O3_monthly_images)

# Ekspor setiap citra bulanan ke Google Drive
for image in O3_monthly_images:
    label = image.get('label').getInfo()  # Ambil nama label
    task = ee.batch.Export.image.toDrive(
        image=image,
        description=label,
        folder='O3_Monthly',
        fileNamePrefix=label,
        scale=1113.2,
        region=AOI,
        crs='EPSG:32748',
        maxPixels=1e13
    )
    task.start()
    print(f"Tugas ekspor '{label}' telah dimulai.")

"""**Missing Value Filling**"""

# === PATH SETTING ===
input_folder = "/content/drive/MyDrive/O3_Monthly (2)"  # Ganti dengan folder data NO2 Anda
output_folder = "/content/drive/MyDrive/O3_Monthly (2)/output_interpolasi_O3"
os.makedirs(output_folder, exist_ok=True)

# === LOOP MULTIPLE RASTER ===
raster_files = glob.glob(os.path.join(input_folder, "*.tif"))

for raster_file in raster_files:
    print(f"Processing: {os.path.basename(raster_file)}")

    with rasterio.open(raster_file) as src:
        o3 = src.read(1).astype(float)
        o3[o3 < 0] = np.nan  # Sentinel-5P biasanya menyimpan nilai tidak valid < 0
        transform = src.transform
        crs = src.crs
        shape = src.shape

        # === Interpolasi pada seluruh area raster ===
        x = np.arange(shape[1])
        y = np.arange(shape[0])
        xv, yv = np.meshgrid(x, y)

        x_flat = xv.flatten()
        y_flat = yv.flatten()
        z_flat = no2.flatten()

        valid = ~np.isnan(z_flat)
        x_valid = x_flat[valid]
        y_valid = y_flat[valid]
        z_valid = z_flat[valid]

        # Linear interpolation
        z_interp = griddata(
            (x_valid, y_valid), z_valid, (xv, yv), method='linear'
        )

        # Gabungkan hasil interpolasi pada seluruh area
        o3_filled = np.where(np.isnan(o3), z_interp, o3)

        # === Save output ===
        output_path = os.path.join(output_folder, os.path.basename(raster_file))

        with rasterio.open(
            output_path, "w",
            driver="GTiff",
            height=shape[0],
            width=shape[1],
            count=1,
            dtype="float32",
            crs=crs,
            transform=transform
        ) as dst:
            dst.write(o3_filled.astype("float32"), 1)

        # === Visualization ===
        fig, axs = plt.subplots(1, 2, figsize=(12, 5))
        cmap = 'viridis'

        im1 = axs[0].imshow(o3, cmap=cmap)
        axs[0].set_title("Sebelum Interpolasi")
        plt.colorbar(im1, ax=axs[0], orientation="vertical", fraction=0.05)

        im2 = axs[1].imshow(o3_filled, cmap=cmap)
        axs[1].set_title("Setelah Interpolasi")
        plt.colorbar(im2, ax=axs[1], orientation="vertical", fraction=0.05)

        plt.suptitle(os.path.basename(raster_file))
        plt.tight_layout()
        plt.show()

print("\nâœ… Semua raster Sentinel-5P O3 berhasil diisi dan divisualisasikan.")

"""**Downscaling**"""

def visualize_comparison(before_array, after_array, title):
    fig, axs = plt.subplots(1, 2, figsize=(12, 5))
    cmap = 'viridis'

    vmin = min(np.nanmin(before_array), np.nanmin(after_array))
    vmax = max(np.nanmax(before_array), np.nanmax(after_array))

    im1 = axs[0].imshow(before_array, cmap=cmap, vmin=vmin, vmax=vmax)
    axs[0].set_title("Sebelum Resampling")
    axs[0].set_xlabel("Kolom")
    axs[0].set_ylabel("Baris")
    plt.colorbar(im1, ax=axs[0], orientation="vertical", fraction=0.05)

    im2 = axs[1].imshow(after_array, cmap=cmap, vmin=vmin, vmax=vmax)
    axs[1].set_title("Setelah Resampling (1000m)")
    axs[1].set_xlabel("Kolom")
    axs[1].set_ylabel("Baris")
    plt.colorbar(im2, ax=axs[1], orientation="vertical", fraction=0.05)

    plt.suptitle(title, fontsize=14)
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

def resample_raster_to_1km(input_path, output_path, target_resolution=1000, visualize=True):
    with rasterio.open(input_path) as src:
        src_array = src.read(1)
        src_transform = src.transform
        src_crs = src.crs
        src_bounds = src.bounds

        dst_transform, width, height = calculate_default_transform(
            src_crs, src_crs, src.width, src.height, *src_bounds, resolution=target_resolution
        )

        kwargs = src.meta.copy()
        kwargs.update({
            'crs': src_crs,
            'transform': dst_transform,
            'width': width,
            'height': height
        })

        with rasterio.open(output_path, 'w', **kwargs) as dst:
            dst_array = np.empty((height, width), dtype=src.dtypes[0])
            reproject(
                source=src_array,
                destination=dst_array,
                src_transform=src_transform,
                src_crs=src_crs,
                dst_transform=dst_transform,
                dst_crs=src_crs,
                resampling=Resampling.bilinear,
                src_nodata=np.nan,
                dst_nodata=np.nan
            )
            dst.write(dst_array, 1)

    print(f"âœ… {os.path.basename(input_path)} berhasil di-resample ke 1000m")

    if visualize:
        visualize_comparison(src_array, dst_array, os.path.basename(input_path))

# === Batch Processing ===
input_folder = "/content/drive/MyDrive/O3_Monthly (2)/output_interpolasi_O3"
output_folder = "/content/drive/MyDrive/O3_Monthly (2)/output_resampling_O3"
os.makedirs(output_folder, exist_ok=True)

raster_files = glob(os.path.join(input_folder, "*.tif"))

for raster_file in raster_files:
    filename = os.path.basename(raster_file)
    output_path = os.path.join(output_folder, f"{os.path.splitext(filename)[0]}.tif")
    resample_raster_to_1km(raster_file, output_path, visualize=True)

def evaluate_resampling_accuracy(original_path, resampled_path):
    with rasterio.open(original_path) as src_orig, rasterio.open(resampled_path) as src_resamp:
        original = src_orig.read(1)
        resampled_reproj = np.empty_like(original)

        reproject(
            source=src_resamp.read(1),
            destination=resampled_reproj,
            src_transform=src_resamp.transform,
            src_crs=src_resamp.crs,
            dst_transform=src_orig.transform,
            dst_crs=src_orig.crs,
            resampling=Resampling.bilinear
        )

        # Mask nilai valid (bukan NaN)
        mask = ~np.isnan(original) & ~np.isnan(resampled_reproj)
        y_true = original[mask]
        y_pred = resampled_reproj[mask]

        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)

        return {
            "filename": os.path.basename(original_path),
            "RMSE": rmse,
            "MAE": mae,
            "MSE": mse,
            "R2": r2
        }
# === Batch Evaluasi ===
original_folder = "/content/drive/MyDrive/O3_Monthly (2)/output_interpolasi_O3"
resampled_folder = "/content/drive/MyDrive/O3_Monthly (2)/output_resampling_O3"

original_files = sorted(glob(os.path.join(original_folder, "*.tif")))
resampled_files = sorted(glob(os.path.join(resampled_folder, "*.tif")))

results = []
for orig, resamp in zip(original_files, resampled_files):
    res = evaluate_resampling_accuracy(orig, resamp)
    print(f"ðŸ“Š {res['filename']}: RMSE={res['RMSE']:.2e}, MAE={res['MAE']:.2e}, MSE={res['MSE']:.2e}, R2={res['R2']:.4f}")
    results.append(res)

"""**Layer Stacking**"""

# Direktori tempat file raster NO2 disimpan
input_dir = '/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_O3_Monthly/output_resampling_O3'  # Ganti dengan direktori sebenarnya

# Daftar file raster NO2 per bulan (misalnya NO2_Jan2022.tif, NO2_Feb2022.tif, dll)
raster_files = [
    'O3_2022_01.tif', 'O3_2022_02.tif', 'O3_2022_03.tif',
    'O3_2022_04.tif', 'O3_2022_05.tif', 'O3_2022_06.tif',
    'O3_2022_07.tif', 'O3_2022_08.tif', 'O3_2022_09.tif',
    'O3_2022_10.tif', 'O3_2022_11.tif', 'O3_2022_12.tif',
    'O3_2023_01.tif', 'O3_2023_02.tif', 'O3_2023_03.tif',
    'O3_2023_04.tif', 'O3_2023_05.tif', 'O3_2023_06.tif',
    'O3_2023_07.tif', 'O3_2023_08.tif', 'O3_2023_09.tif',
    'O3_2023_10.tif', 'O3_2023_11.tif', 'O3_2023_12.tif',
    'O3_2024_01.tif', 'O3_2024_02.tif', 'O3_2024_03.tif',
    'O3_2024_04.tif', 'O3_2024_05.tif', 'O3_2024_06.tif',
    'O3_2024_07.tif', 'O3_2024_08.tif', 'O3_2024_09.tif',
    'O3_2024_10.tif', 'O3_2024_11.tif', 'O3_2024_12.tif'
]

# Inisialisasi list untuk menyimpan objek raster
raster_list = []

# Baca semua raster dan tambahkan ke list
for file in raster_files:
    file_path = os.path.join(input_dir, file)
    raster = rxr.open_rasterio(file_path)
    raster_list.append(raster)

# Stack semua raster menjadi satu dengan xarray.concat
stacked_raster = xr.concat(raster_list, dim='band')

# Simpan hasil stacking ke file baru menggunakan rioxarray
stacked_raster.rio.to_raster('/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_O3_Monthly/Stacking Layer/TrO3_Jakarta.tif')

print("Stacking selesai dan file disimpan.")

"""**KARBON MONOKSIDA**

# KARBON MONOKSIDA (CO)

Data ini diambil dari Sentinel-5P menggunakan Google Earth Engine
"""

# Load dataset TROPOMI CO dan filter berdasarkan waktu dan lokasi
CO_collection = ee.ImageCollection("COPERNICUS/S5P/NRTI/L3_CO") \
    .select('CO_column_number_density') \
    .filterDate('2022-01-01', '2024-12-31') \
    .filterBounds(AOI)

# Konstanta untuk konversi
molar_mass_CO = 28             # gram/mol
HEIGHT_TROPOSPHERE = 10000      # meter
GRAM_TO_MICROGRAM = 1e6

# Faktor konversi mol/mÂ² ke Âµg/mÂ³
CONVERSION_FACTOR = (molar_mass_CO * GRAM_TO_MICROGRAM) /HEIGHT_TROPOSPHERE

# List bulan dan tahun
months = list(range(1, 13))
years = list(range(2022, 2025))

# Looping untuk menghasilkan image bulanan yang telah dikonversi
CO_monthly_images = []

for y in years:
    for m in months:
        filtered = CO_collection \
            .filter(ee.Filter.calendarRange(y, y, 'year')) \
            .filter(ee.Filter.calendarRange(m, m, 'month'))

        monthly_mean_mol = filtered.mean()

        # Konversi ke Âµg/mÂ³
        monthly_mean_ug = monthly_mean_mol.multiply(CONVERSION_FACTOR) \
            .clip(AOI) \
            .set('year', y) \
            .set('month', m) \
            .set('system:time_start', ee.Date.fromYMD(y, m, 1)) \
            .set('label', f"CO_{y:04d}_{m:02d}")

        CO_monthly_images.append(monthly_mean_ug)

# Konversi list ke ImageCollection
CO_monthly_collection = ee.ImageCollection(CO_monthly_images)

# Ekspor setiap citra bulanan ke Google Drive
for image in CO_monthly_images:
    label = image.get('label').getInfo()  # Ambil nama label
    task = ee.batch.Export.image.toDrive(
        image=image,
        description=label,
        folder='Tropomi_CO_Monthly',
        fileNamePrefix=label,
        scale=1113.2,
        region=AOI,
        crs='EPSG:32748',
        maxPixels=1e13
    )
    task.start()
    print(f"Tugas ekspor '{label}' telah dimulai.")

# === PATH SETTING ===
input_folder = "/content/drive/MyDrive/Tropomi_CO_Monthly (1)"  # Ganti dengan folder data NO2 Anda
shapefile_path = "/content/drive/MyDrive/JABODETABEK/JABODETABEK.shp"
output_folder = "/content/drive/MyDrive/Tropomi_CO_Monthly (1)/output_interpolasi_CO"
os.makedirs(output_folder, exist_ok=True)

# === LOAD SHAPEFILE DARATAN SEKALI SAJA ===
gdf = gpd.read_file(shapefile_path)

# === LOOP MULTIPLE RASTER ===
raster_files = glob.glob(os.path.join(input_folder, "*.tif"))

for raster_file in raster_files:
    print(f"Processing: {os.path.basename(raster_file)}")

    with rasterio.open(raster_file) as src:
        no2 = src.read(1).astype(float)
        no2[no2 < 0] = np.nan  # Sentinel-5P biasanya menyimpan nilai tidak valid < 0
        transform = src.transform
        crs = src.crs
        shape = src.shape

        # Reproject shapefile ke CRS raster
        gdf_raster_crs = gdf.to_crs(crs)

        # === Rasterize shapefile daratan ===
        mask = features.rasterize(
            ((geom, 1) for geom in gdf_raster_crs.geometry),
            out_shape=shape,
            transform=transform,
            fill=0,
            dtype='uint8'
        )

        # === Interpolasi hanya di daratan ===
        x = np.arange(shape[1])
        y = np.arange(shape[0])
        xv, yv = np.meshgrid(x, y)

        x_flat = xv.flatten()
        y_flat = yv.flatten()
        z_flat = no2.flatten()
        mask_flat = mask.flatten()

        valid = ~np.isnan(z_flat) & (mask_flat == 1)
        x_valid = x_flat[valid]
        y_valid = y_flat[valid]
        z_valid = z_flat[valid]

        # Linear interpolation
        z_interp = griddata(
            (x_valid, y_valid), z_valid, (xv, yv), method='linear'
        )

        # Gabungkan hasil interpolasi hanya di area daratan
        no2_filled = np.where((np.isnan(no2)) & (mask == 1), z_interp, no2)

        # === Save output ===
        output_path = os.path.join(output_folder, os.path.basename(raster_file))

        with rasterio.open(
            output_path, "w",
            driver="GTiff",
            height=shape[0],
            width=shape[1],
            count=1,
            dtype="float32",
            crs=crs,
            transform=transform
        ) as dst:
            dst.write(no2_filled.astype("float32"), 1)

        # === Visualization ===
        fig, axs = plt.subplots(1, 2, figsize=(12, 5))
        cmap = 'viridis'

        im1 = axs[0].imshow(no2, cmap=cmap)
        axs[0].set_title("Sebelum Interpolasi")
        plt.colorbar(im1, ax=axs[0], orientation="vertical", fraction=0.05)

        im2 = axs[1].imshow(no2_filled, cmap=cmap)
        axs[1].set_title("Setelah Interpolasi")
        plt.colorbar(im2, ax=axs[1], orientation="vertical", fraction=0.05)

        plt.suptitle(os.path.basename(raster_file))
        plt.tight_layout()
        plt.show()

print("\nâœ… Semua raster Sentinel-5P NOâ‚‚ berhasil diisi dan divisualisasikan.")

def visualize_comparison(before_array, after_array, title):
    fig, axs = plt.subplots(1, 2, figsize=(12, 5))
    cmap = 'viridis'

    vmin = min(np.nanmin(before_array), np.nanmin(after_array))
    vmax = max(np.nanmax(before_array), np.nanmax(after_array))

    im1 = axs[0].imshow(before_array, cmap=cmap, vmin=vmin, vmax=vmax)
    axs[0].set_title("Sebelum Resampling")
    axs[0].set_xlabel("Kolom")
    axs[0].set_ylabel("Baris")
    plt.colorbar(im1, ax=axs[0], orientation="vertical", fraction=0.05)

    im2 = axs[1].imshow(after_array, cmap=cmap, vmin=vmin, vmax=vmax)
    axs[1].set_title("Setelah Resampling (1000m)")
    axs[1].set_xlabel("Kolom")
    axs[1].set_ylabel("Baris")
    plt.colorbar(im2, ax=axs[1], orientation="vertical", fraction=0.05)

    plt.suptitle(title, fontsize=14)
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

def resample_raster_to_1km(input_path, output_path, target_resolution=1000, visualize=True):
    with rasterio.open(input_path) as src:
        src_array = src.read(1)
        src_transform = src.transform
        src_crs = src.crs
        src_bounds = src.bounds

        dst_transform, width, height = calculate_default_transform(
            src_crs, src_crs, src.width, src.height, *src_bounds, resolution=target_resolution
        )

        kwargs = src.meta.copy()
        kwargs.update({
            'crs': src_crs,
            'transform': dst_transform,
            'width': width,
            'height': height
        })

        with rasterio.open(output_path, 'w', **kwargs) as dst:
            dst_array = np.empty((height, width), dtype=src.dtypes[0])
            reproject(
                source=src_array,
                destination=dst_array,
                src_transform=src_transform,
                src_crs=src_crs,
                dst_transform=dst_transform,
                dst_crs=src_crs,
                resampling=Resampling.bilinear,
                src_nodata=np.nan,
                dst_nodata=np.nan
            )
            dst.write(dst_array, 1)

    print(f"âœ… {os.path.basename(input_path)} berhasil di-resample ke 1000m")

    if visualize:
        visualize_comparison(src_array, dst_array, os.path.basename(input_path))

# === Batch Processing ===
input_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_CO_Monthly/output_interpolasi_CO"
output_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_CO_Monthly/output_resampling_CO"
os.makedirs(output_folder, exist_ok=True)

raster_files = glob(os.path.join(input_folder, "*.tif"))

for raster_file in raster_files:
    filename = os.path.basename(raster_file)
    output_path = os.path.join(output_folder, f"{os.path.splitext(filename)[0]}.tif")
    resample_raster_to_1km(raster_file, output_path, visualize=True)

def evaluate_resampling_accuracy(original_path, resampled_path):
    with rasterio.open(original_path) as src1, rasterio.open(resampled_path) as src2:
        original = src1.read(1)
        resampled = src2.read(1)

        # Upscale hasil resampling ke dimensi asli
        zoom_factors = (
            original.shape[0] / resampled.shape[0],
            original.shape[1] / resampled.shape[1]
        )
        resampled_upscaled = zoom(resampled, zoom_factors, order=1)  # bilinear interpolation

        # Mask untuk membandingkan hanya nilai valid (bukan NaN)
        mask = ~np.isnan(original) & ~np.isnan(resampled_upscaled)
        y_true = original[mask]
        y_pred = resampled_upscaled[mask]

        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)

        return {
            "filename": os.path.basename(original_path),
            "RMSE": rmse,
            "MAE": mae,
            "MSE": mse,
            "R2": r2
        }

# === Batch Evaluasi ===
original_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_CO_Monthly/output_interpolasi_CO"
resampled_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_CO_Monthly/output_resampling_CO"

original_files = sorted(glob(os.path.join(original_folder, "*.tif")))
resampled_files = sorted(glob(os.path.join(resampled_folder, "*.tif")))

results = []
for orig, resamp in zip(original_files, resampled_files):
    res = evaluate_resampling_accuracy(orig, resamp)
    print(f"ðŸ“Š {res['filename']}: RMSE={res['RMSE']:.2e}, MAE={res['MAE']:.2e}, MSE={res['MSE']:.2e}, R2={res['R2']:.4f}")
    results.append(res)

import geopandas as gpd
import rioxarray
import os
import pandas as pd

# Direktori tempat file raster NO2 disimpan
input_dir = '/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_CO_Monthly/output_resampling_CO'  # Ganti dengan direktori sebenarnya

# Daftar file raster NO2 per bulan (misalnya NO2_Jan2022.tif, NO2_Feb2022.tif, dll)
raster_files = [
    'CO_2022_01.tif', 'CO_2022_02.tif', 'CO_2022_03.tif',
    'CO_2022_04.tif', 'CO_2022_05.tif', 'CO_2022_06.tif',
    'CO_2022_07.tif', 'CO_2022_08.tif', 'CO_2022_09.tif',
    'CO_2022_10.tif', 'CO_2022_11.tif', 'CO_2022_12.tif',
    'CO_2023_01.tif', 'CO_2023_02.tif', 'CO_2023_03.tif',
    'CO_2023_04.tif', 'CO_2023_05.tif', 'CO_2023_06.tif',
    'CO_2023_07.tif', 'CO_2023_08.tif', 'CO_2023_09.tif',
    'CO_2023_10.tif', 'CO_2023_11.tif', 'CO_2023_12.tif',
    'CO_2024_01.tif', 'CO_2024_02.tif', 'CO_2024_03.tif',
    'CO_2024_04.tif', 'CO_2024_05.tif', 'CO_2024_06.tif',
    'CO_2024_07.tif', 'CO_2024_08.tif', 'CO_2024_09.tif',
    'CO_2024_10.tif', 'CO_2024_11.tif', 'CO_2024_12.tif'
]


# Inisialisasi list untuk menyimpan objek raster
raster_list = []

# Baca semua raster dan tambahkan ke list
for file in raster_files:
    file_path = os.path.join(input_dir, file)
    raster = rioxarray.open_rasterio(file_path)
    raster_list.append(raster)

# Stack semua raster menjadi satu dengan xarray.concat
stacked_raster = xr.concat(raster_list, dim='band')

# Simpan hasil stacking ke file baru menggunakan rioxarray
stacked_raster.rio.to_raster('/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_CO_Monthly/Stacking Layer/CO_Jakarta.tif')

print("Stacking selesai dan file disimpan.")

"""#SULFUR DIOKSIDA (SO2)

**Akuisisi Citra**
"""

# Load dataset TROPOMI SO2 dan filter berdasarkan waktu dan lokasi
SO2_collection = ee.ImageCollection("COPERNICUS/S5P/NRTI/L3_SO2") \
    .select('SO2_column_number_density') \
    .filterDate('2022-01-01', '2024-12-31') \
    .filterBounds(AOI)

# Konstanta untuk konversi
molar_mass_SO2 = 64.066        # gram/mol
HEIGHT_TROPOSPHERE = 10000      # meter
GRAM_TO_MICROGRAM = 1e6

# Faktor konversi mol/mÂ² ke Âµg/mÂ³
CONVERSION_FACTOR = (molar_mass_SO2 * GRAM_TO_MICROGRAM) / HEIGHT_TROPOSPHERE

# List bulan dan tahun
months = list(range(1, 13))
years = list(range(2022, 2025))

# Looping untuk menghasilkan image bulanan yang telah dikonversi
SO2_monthly_images = []

for y in years:
    for m in months:
        filtered = SO2_collection \
            .filter(ee.Filter.calendarRange(y, y, 'year')) \
            .filter(ee.Filter.calendarRange(m, m, 'month'))

        monthly_mean_mol = filtered.mean()

        # Konversi ke Âµg/mÂ³
        monthly_mean_ug = monthly_mean_mol.multiply(CONVERSION_FACTOR) \
            .clip(AOI) \
            .set('year', y) \
            .set('month', m) \
            .set('system:time_start', ee.Date.fromYMD(y, m, 1)) \
            .set('label', f"SO2_{y:04d}_{m:02d}")

        SO2_monthly_images.append(monthly_mean_ug)

# Konversi list ke ImageCollection
SO2_monthly_collection = ee.ImageCollection(SO2_monthly_images)

# Ekspor setiap citra bulanan ke Google Drive
for image in SO2_monthly_images:
    label = image.get('label').getInfo()  # Ambil nama label
    task = ee.batch.Export.image.toDrive(
        image=image,
        description=label,
        folder='Tropomi_SO2_Monthly',
        fileNamePrefix=label,
        scale=1113.2,
        region=AOI,
        crs='EPSG:32748',
        maxPixels=1e13
    )
    task.start()
    print(f"Tugas ekspor '{label}' telah dimulai.")

"""**Missing Value Filling**"""

# === PATH SETTING ===
input_folder = "/content/drive/MyDrive/Tropomi_SO2_Monthly (3)"  # Ganti dengan folder data NO2 Anda
output_folder = "/content/drive/MyDrive/Tropomi_SO2_Monthly (3)/output_interpolasi_SO2"
os.makedirs(output_folder, exist_ok=True)

# === LOOP MULTIPLE RASTER ===
raster_files = glob.glob(os.path.join(input_folder, "*.tif"))

for raster_file in raster_files:
    print(f"Processing: {os.path.basename(raster_file)}")

    with rasterio.open(raster_file) as src:
        no2 = src.read(1).astype(float)
        no2[no2 < 0] = np.nan  # Sentinel-5P biasanya menyimpan nilai tidak valid < 0
        transform = src.transform
        crs = src.crs
        shape = src.shape

        # === Interpolasi pada seluruh area raster ===
        x = np.arange(shape[1])
        y = np.arange(shape[0])
        xv, yv = np.meshgrid(x, y)

        x_flat = xv.flatten()
        y_flat = yv.flatten()
        z_flat = no2.flatten()

        valid = ~np.isnan(z_flat)
        x_valid = x_flat[valid]
        y_valid = y_flat[valid]
        z_valid = z_flat[valid]

        # Linear interpolation
        z_interp = griddata(
            (x_valid, y_valid), z_valid, (xv, yv), method='linear'
        )

        # Gabungkan hasil interpolasi pada seluruh area
        no2_filled = np.where(np.isnan(no2), z_interp, no2)

        # === Save output ===
        output_path = os.path.join(output_folder, os.path.basename(raster_file))

        with rasterio.open(
            output_path, "w",
            driver="GTiff",
            height=shape[0],
            width=shape[1],
            count=1,
            dtype="float32",
            crs=crs,
            transform=transform
        ) as dst:
            dst.write(no2_filled.astype("float32"), 1)

        # === Visualization ===
        fig, axs = plt.subplots(1, 2, figsize=(12, 5))
        cmap = 'viridis'

        im1 = axs[0].imshow(no2, cmap=cmap)
        axs[0].set_title("Sebelum Interpolasi")
        plt.colorbar(im1, ax=axs[0], orientation="vertical", fraction=0.05)

        im2 = axs[1].imshow(no2_filled, cmap=cmap)
        axs[1].set_title("Setelah Interpolasi")
        plt.colorbar(im2, ax=axs[1], orientation="vertical", fraction=0.05)

        plt.suptitle(os.path.basename(raster_file))
        plt.tight_layout()
        plt.show()

print("\nâœ… Semua raster Sentinel-5P NOâ‚‚ berhasil diisi dan divisualisasikan.")

"""**Downscaling**"""

def visualize_comparison(before_array, after_array, title):
    fig, axs = plt.subplots(1, 2, figsize=(12, 5))
    cmap = 'viridis'

    vmin = min(np.nanmin(before_array), np.nanmin(after_array))
    vmax = max(np.nanmax(before_array), np.nanmax(after_array))

    im1 = axs[0].imshow(before_array, cmap=cmap, vmin=vmin, vmax=vmax)
    axs[0].set_title("Sebelum Resampling")
    axs[0].set_xlabel("Kolom")
    axs[0].set_ylabel("Baris")
    plt.colorbar(im1, ax=axs[0], orientation="vertical", fraction=0.05)

    im2 = axs[1].imshow(after_array, cmap=cmap, vmin=vmin, vmax=vmax)
    axs[1].set_title("Setelah Resampling (1000m)")
    axs[1].set_xlabel("Kolom")
    axs[1].set_ylabel("Baris")
    plt.colorbar(im2, ax=axs[1], orientation="vertical", fraction=0.05)

    plt.suptitle(title, fontsize=14)
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

def resample_raster_to_1km(input_path, output_path, target_resolution=1000, visualize=True):
    with rasterio.open(input_path) as src:
        src_array = src.read(1)
        src_transform = src.transform
        src_crs = src.crs
        src_bounds = src.bounds

        dst_transform, width, height = calculate_default_transform(
            src_crs, src_crs, src.width, src.height, *src_bounds, resolution=target_resolution
        )

        kwargs = src.meta.copy()
        kwargs.update({
            'crs': src_crs,
            'transform': dst_transform,
            'width': width,
            'height': height
        })

        with rasterio.open(output_path, 'w', **kwargs) as dst:
            dst_array = np.empty((height, width), dtype=src.dtypes[0])
            reproject(
                source=src_array,
                destination=dst_array,
                src_transform=src_transform,
                src_crs=src_crs,
                dst_transform=dst_transform,
                dst_crs=src_crs,
                resampling=Resampling.bilinear,
                src_nodata=np.nan,
                dst_nodata=np.nan
            )
            dst.write(dst_array, 1)

    print(f"âœ… {os.path.basename(input_path)} berhasil di-resample ke 1000m")

    if visualize:
        visualize_comparison(src_array, dst_array, os.path.basename(input_path))

# === Batch Processing ===
input_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_SO2_Monthly/output_interpolasi_SO2"
output_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_SO2_Monthly/output_resampling_SO2"
os.makedirs(output_folder, exist_ok=True)

raster_files = glob(os.path.join(input_folder, "*.tif"))

for raster_file in raster_files:
    filename = os.path.basename(raster_file)
    output_path = os.path.join(output_folder, f"{os.path.splitext(filename)[0]}.tif")
    resample_raster_to_1km(raster_file, output_path, visualize=True)

def evaluate_resampling_accuracy(original_path, resampled_path):
    with rasterio.open(original_path) as src1, rasterio.open(resampled_path) as src2:
        original = src1.read(1)
        resampled = src2.read(1)

        # Upscale hasil resampling ke dimensi asli
        zoom_factors = (
            original.shape[0] / resampled.shape[0],
            original.shape[1] / resampled.shape[1]
        )
        resampled_upscaled = zoom(resampled, zoom_factors, order=1)  # bilinear interpolation

        # Mask untuk membandingkan hanya nilai valid (bukan NaN)
        mask = ~np.isnan(original) & ~np.isnan(resampled_upscaled)
        y_true = original[mask]
        y_pred = resampled_upscaled[mask]

        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)

        return {
            "filename": os.path.basename(original_path),
            "RMSE": rmse,
            "MAE": mae,
            "MSE": mse,
            "R2": r2
        }

# === Batch Evaluasi ===
original_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_SO2_Monthly/output_interpolasi_SO2"
resampled_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_SO2_Monthly/output_resampling_SO2"

original_files = sorted(glob(os.path.join(original_folder, "*.tif")))
resampled_files = sorted(glob(os.path.join(resampled_folder, "*.tif")))

results = []
for orig, resamp in zip(original_files, resampled_files):
    res = evaluate_resampling_accuracy(orig, resamp)
    print(f"ðŸ“Š {res['filename']}: RMSE={res['RMSE']:.2e}, MAE={res['MAE']:.2e}, MSE={res['MSE']:.2e}, R2={res['R2']:.4f}")
    results.append(res)

"""**Layer Stacking**"""

# Direktori tempat file raster NO2 disimpan
input_dir = '/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_SO2_Monthly/output_resampling_SO2'  # Ganti dengan direktori sebenarnya

# Daftar file raster NO2 per bulan (misalnya NO2_Jan2022.tif, NO2_Feb2022.tif, dll)
raster_files = [
    'SO2_2022_01.tif', 'SO2_2022_02.tif', 'SO2_2022_03.tif',
    'SO2_2022_04.tif', 'SO2_2022_05.tif', 'SO2_2022_06.tif',
    'SO2_2022_07.tif', 'SO2_2022_08.tif', 'SO2_2022_09.tif',
    'SO2_2022_10.tif', 'SO2_2022_11.tif', 'SO2_2022_12.tif',
    'SO2_2023_01.tif', 'SO2_2023_02.tif', 'SO2_2023_03.tif',
    'SO2_2023_04.tif', 'SO2_2023_05.tif', 'SO2_2023_06.tif',
    'SO2_2023_07.tif', 'SO2_2023_08.tif', 'SO2_2023_09.tif',
    'SO2_2023_10.tif', 'SO2_2023_11.tif', 'SO2_2023_12.tif',
    'SO2_2024_01.tif', 'SO2_2024_02.tif', 'SO2_2024_03.tif',
    'SO2_2024_04.tif', 'SO2_2024_05.tif', 'SO2_2024_06.tif',
    'SO2_2024_07.tif', 'SO2_2024_08.tif', 'SO2_2024_09.tif',
    'SO2_2024_10.tif', 'SO2_2024_11.tif', 'SO2_2024_12.tif'
]


# Inisialisasi list untuk menyimpan objek raster
raster_list = []

# Baca semua raster dan tambahkan ke list
for file in raster_files:
    file_path = os.path.join(input_dir, file)
    raster = rioxarray.open_rasterio(file_path)
    raster_list.append(raster)

# Stack semua raster menjadi satu dengan xarray.concat
stacked_raster = xr.concat(raster_list, dim='band')

# Simpan hasil stacking ke file baru menggunakan rioxarray
stacked_raster.rio.to_raster('/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_SO2_Monthly/Stacking Layer/SO2_Jakarta.tif')

print("Stacking selesai dan file disimpan.")

"""# LAND SURFACE TEMPERATURE (LST)
Data yang diambil dari satelit MODIS

**Akuisisi Citra**
"""

# -------------------------------
# 1. Parameter & Konfigurasi
# -------------------------------
SCALE_FACTOR = 0.02
LST_collection = ee.ImageCollection("MODIS/061/MOD11A2")


# -------------------------------
# 2. LST Rata-rata Bulanan (2012â€“2024)
# -------------------------------
start_date = datetime(2012, 1, 1)
end_date = datetime(2024, 12, 31)

ym_list = []
current = start_date
while current <= end_date:
    ym_list.append((current.year, current.month))
    current += relativedelta(months=1)

LST_monthly_images = []

for y, m in ym_list:
    LST_filtered = LST_collection \
        .filter(ee.Filter.calendarRange(y, y, 'year')) \
        .filter(ee.Filter.calendarRange(m, m, 'month'))

    LST_monthly_mean_celsius = LST_filtered.select('LST_Day_1km') \
        .mean() \
        .multiply(SCALE_FACTOR) \
        .subtract(273.15) \
        .rename('LST_Celsius') \
        .clip(AOI) \
        .set('year', y) \
        .set('month', m) \
        .set('system:time_start', ee.Date.fromYMD(y, m, 1)) \
        .set('label', f"LST_Celsius_{y:04d}_{m:02d}")

    LST_monthly_images.append(LST_monthly_mean_celsius)

LST_monthly_collection = ee.ImageCollection(LST_monthly_images)

# -------------------------------
# 3. Rata-rata Tiap Bulan (lintas tahun)
# -------------------------------
monthly_avg_images = []


for month in range(1, 13):
    monthly_filtered = LST_monthly_collection.filter(ee.Filter.eq('month', month))

    # Rata-rata
    monthly_avg = monthly_filtered.mean() \
        .set('month', month) \
        .set('label', f"LST_MonthlyAvg_{month:02d}") \
        .rename('LST_MonthlyAvg_Celsius')


    monthly_avg_images.append(monthly_avg)

LST_monthly_avg_collection = ee.ImageCollection(monthly_avg_images)

for i in range(LST_monthly_avg_collection.size().getInfo()):
    image = LST_monthly_avg_collection.toList(LST_monthly_avg_collection.size()).get(i)
    label = ee.Image(image).get('label').getInfo()  # Ambil nama label, misalnya: 'LST_Celsius_2023_05'
    task = ee.batch.Export.image.toDrive(
        image=ee.Image(image),
        description=label,
        folder='LST_20122024',
        fileNamePrefix=label,
        scale=1000,  # Resolusi MODIS (meter)
        region=AOI,
        crs='EPSG:32748',  # UTM Zone 48S (bisa disesuaikan)
        maxPixels=1e13
    )
    task.start()
    print(f"Tugas ekspor '{label}' telah dimulai.")

# Direktori file raster dan shapefile
input_dir = '/content/drive/MyDrive/LST_Average (2)'
shapefile_path = '/content/drive/MyDrive/PENGOLAHAN/DKI Jakarta/DKI Jakarta.shp'  # Ganti dengan path shapefile kamu

# Baca shapefile menggunakan GeoPandas
gdf = gpd.read_file(shapefile_path)

# Proyeksikan shapefile ke CRS raster
raster_files = sorted(glob.glob(os.path.join(input_dir, '*.tif')))

for file in raster_files:
    with rasterio.open(file) as src:
        lst_data = src.read(1)
        crs = src.crs
        bounds = src.bounds

        # Proyeksikan shapefile jika CRS tidak cocok
        if gdf.crs != src.crs:
            gdf = gdf.to_crs(src.crs)

        # Plot raster dan shapefile overlay
        fig, ax = plt.subplots(figsize=(10, 8))
        show(lst_data, transform=src.transform, cmap='inferno', ax=ax)
        gdf.boundary.plot(ax=ax, edgecolor='cyan', linewidth=1.5)

        # Tambahan elemen visual
        plt.title(f'Rata-rata LST - {os.path.basename(file)}', fontsize=14)
        plt.xlabel('Longitude')
        plt.ylabel('Latitude')
        plt.colorbar(ax.images[0], label='Land Surface Temperature (Â°C)')

# -------------------------------
# 1. Parameter & Konfigurasi
# -------------------------------

# Konstanta: Faktor konversi skala MODIS LST
SCALE_FACTOR = 0.02

# Koleksi MODIS LST
LST_collection = ee.ImageCollection("MODIS/061/MOD11A2")

# Area of Interest (pastikan AOI sudah didefinisikan sebelumnya)
# Contoh: AOI = ee.FeatureCollection("USDOS/LSIB_SIMPLE/2017").filter(ee.Filter.eq('country_na', 'Indonesia'))

# -------------------------------
# 2. LST Rata-rata Bulanan
# -------------------------------

from datetime import datetime
from dateutil.relativedelta import relativedelta

# Rentang waktu: Oktober 2021 - Maret 2025
start_date = datetime(2019, 1, 1)
end_date = datetime(2024, 12, 31)

# Buat list pasangan (tahun, bulan)
ym_list = []
current = start_date
while current <= end_date:
    ym_list.append((current.year, current.month))
    current += relativedelta(months=1)

# List untuk menyimpan hasil LST bulanan
LST_monthly_images = []

# Loop untuk membuat citra rata-rata bulanan
for y, m in ym_list:
    # Filter data berdasarkan tahun dan bulan
    LST_filtered = LST_collection \
        .filter(ee.Filter.calendarRange(y, y, 'year')) \
        .filter(ee.Filter.calendarRange(m, m, 'month'))

    # Ambil rata-rata LST dan konversi ke Celsius
    LST_monthly_mean_celsius = LST_filtered.select('LST_Day_1km') \
        .mean() \
        .multiply(SCALE_FACTOR) \
        .subtract(273.15) \
        .rename('LST_Celsius') \
        .clip(AOI) \
        .set('year', y) \
        .set('month', m) \
        .set('system:time_start', ee.Date.fromYMD(y, m, 1)) \
        .set('label', f"LST_Celsius_{y:04d}_{m:02d}")

    # Tambahkan ke list
    LST_monthly_images.append(LST_monthly_mean_celsius)

# Gabungkan menjadi ImageCollection
LST_monthly_collection = ee.ImageCollection(LST_monthly_images)

# Loop untuk ekspor setiap citra LST bulanan ke Google Drive
for i in range(LST_monthly_collection.size().getInfo()):
    image = LST_monthly_collection.toList(LST_monthly_collection.size()).get(i)
    label = ee.Image(image).get('label').getInfo()  # Ambil nama label, misalnya: 'LST_Celsius_2023_05'
    task = ee.batch.Export.image.toDrive(
        image=ee.Image(image),
        description=label,
        folder='LST_Bulanan',
        fileNamePrefix=label,
        scale=1000,  # Resolusi MODIS (meter)
        region=AOI,
        crs='EPSG:32748',  # UTM Zone 48S (bisa disesuaikan)
        maxPixels=1e13
    )
    task.start()
    print(f"Tugas ekspor '{label}' telah dimulai.")

"""**Gap-Filling**"""

# Path ke folder berisi citra LST dan klimatologi
lst_dir = '/content/drive/MyDrive/LST_Monthly'  # Folder untuk citra LST 2022-2024
climatology_dir = '/content/drive/MyDrive/LST_20122024'  # Folder untuk citra klimatologi bulanan

# Mendapatkan semua file citra LST 2022-2024
lst_files = sorted(glob.glob(os.path.join(lst_dir, 'LST_Celsius_2022_*.tif')) +
                   glob.glob(os.path.join(lst_dir, 'LST_Celsius_2023_*.tif')) +
                   glob.glob(os.path.join(lst_dir, 'LST_Celsius_2024_*.tif')))

# Mengisi nilai NaN di citra LST menggunakan citra Rata-rata Klimatologi Bulanan (2012-2024)
output_dir = '/content/drive/MyDrive/LST_Monthly/Missing Value Filled'
os.makedirs(output_dir, exist_ok=True)

for lst_file in lst_files:
    # Extract bulan dan tahun dari nama file (misal 'LST_2022_01.tif')
    filename = os.path.basename(lst_file)
    year, month = filename.split('_')[2], filename.split('_')[3].split('.')[0]

    # Load citra LST 2022-2024
    with rasterio.open(lst_file) as src:
        lst_data = src.read(1)
        profile = src.profile
        lst_data[lst_data == src.nodata] = np.nan  # Menganggap nilai NoData adalah NaN

    # Load citra Rata-rata Klimatologi Bulanan
    climatology_file = os.path.join(climatology_dir, f'LST_MonthlyAvg_{month}.tif')
    with rasterio.open(climatology_file) as src_clim:
        climatology_data = src_clim.read(1)

    # Isi NaN di LST dengan rata-rata klimatologi
    missing_mask = np.isnan(lst_data)
    lst_data[missing_mask] = climatology_data[missing_mask]

    # Simpan citra LST yang telah diisi
    output_path = os.path.join(output_dir, f'LST_{year}_{month}.tif')
    with rasterio.open(output_path, 'w', **profile) as dst:
        dst.write(lst_data.astype(profile['dtype']), 1)

    print(f"Processed and saved: {output_path}")

# Direktori file raster dan shapefile
input_dir = '/content/drive/MyDrive/LST_Monthly/Missing Value Filled'
shapefile_path = '/content/drive/MyDrive/PENGOLAHAN/DKI Jakarta/DKI Jakarta.shp'  # Ganti dengan path shapefile kamu

# Baca shapefile menggunakan GeoPandas
gdf = gpd.read_file(shapefile_path)

# Proyeksikan shapefile ke CRS raster
raster_files = sorted(glob.glob(os.path.join(input_dir, '*.tif')))

for file in raster_files:
    with rasterio.open(file) as src:
        lst_data = src.read(1)
        crs = src.crs
        bounds = src.bounds

        # Proyeksikan shapefile jika CRS tidak cocok
        if gdf.crs != src.crs:
            gdf = gdf.to_crs(src.crs)

        # Plot raster dan shapefile overlay
        fig, ax = plt.subplots(figsize=(10, 8))
        show(lst_data, transform=src.transform, cmap='inferno', ax=ax)
        gdf.boundary.plot(ax=ax, edgecolor='cyan', linewidth=1.5)

        # Tambahan elemen visual
        plt.title(f'LST - {os.path.basename(file)}', fontsize=14)
        plt.xlabel('Longitude')
        plt.ylabel('Latitude')
        plt.colorbar(ax.images[0], label='Land Surface Temperature (Â°C)')

"""**Interpolasi**"""

# === PATH SETTING ===
input_folder = "/content/drive/MyDrive/LST_Monthly/Missing Value Filled"  # Ganti dengan folder data NO2 Anda
shapefile_path = "/content/drive/MyDrive/JABODETABEK/JABODETABEK.shp"
output_folder = "/content/drive/MyDrive/LST_Monthly/output_interpolasi"
os.makedirs(output_folder, exist_ok=True)

# === LOAD SHAPEFILE DARATAN SEKALI SAJA ===
gdf = gpd.read_file(shapefile_path)

# === LOOP MULTIPLE RASTER ===
raster_files = glob.glob(os.path.join(input_folder, "*.tif"))

for raster_file in raster_files:
    print(f"Processing: {os.path.basename(raster_file)}")

    with rasterio.open(raster_file) as src:
        lst = src.read(1).astype(float)
        lst[lst < 0] = np.nan  # Sentinel-5P biasanya menyimpan nilai tidak valid < 0
        transform = src.transform
        crs = src.crs
        shape = src.shape

        # Reproject shapefile ke CRS raster
        gdf_raster_crs = gdf.to_crs(crs)

        # === Rasterize shapefile daratan ===
        mask = features.rasterize(
            ((geom, 1) for geom in gdf_raster_crs.geometry),
            out_shape=shape,
            transform=transform,
            fill=0,
            dtype='uint8'
        )

        # === Interpolasi hanya di daratan ===
        x = np.arange(shape[1])
        y = np.arange(shape[0])
        xv, yv = np.meshgrid(x, y)

        x_flat = xv.flatten()
        y_flat = yv.flatten()
        z_flat = lst.flatten()
        mask_flat = mask.flatten()

        valid = ~np.isnan(z_flat) & (mask_flat == 1)
        x_valid = x_flat[valid]
        y_valid = y_flat[valid]
        z_valid = z_flat[valid]

        # Linear interpolation
        z_interp = griddata(
            (x_valid, y_valid), z_valid, (xv, yv), method='linear'
        )

        # Gabungkan hasil interpolasi hanya di area daratan
        lst_filled = np.where((np.isnan(lst)) & (mask == 1), z_interp, lst)

        # === Save output ===
        output_path = os.path.join(output_folder, os.path.basename(raster_file))

        with rasterio.open(
            output_path, "w",
            driver="GTiff",
            height=shape[0],
            width=shape[1],
            count=1,
            dtype="float32",
            crs=crs,
            transform=transform
        ) as dst:
            dst.write(lst_filled.astype("float32"), 1)

        # === Visualization ===
        fig, axs = plt.subplots(1, 2, figsize=(12, 5))
        cmap = 'viridis'

        im1 = axs[0].imshow(lst, cmap=cmap)
        axs[0].set_title("Sebelum Interpolasi")
        plt.colorbar(im1, ax=axs[0], orientation="vertical", fraction=0.05)

        im2 = axs[1].imshow(lst_filled, cmap=cmap)
        axs[1].set_title("Setelah Interpolasi")
        plt.colorbar(im2, ax=axs[1], orientation="vertical", fraction=0.05)

        plt.suptitle(os.path.basename(raster_file))
        plt.tight_layout()
        plt.show()

print("\nâœ… Semua raster LSTâ‚‚ berhasil diisi dan divisualisasikan.")

"""**Layer Stacking**"""

# Direktori tempat file raster NO2 disimpan
input_dir = '/content/drive/MyDrive/LST_Monthly/output_interpolasi'  # Ganti dengan direktori sebenarnya

# Daftar file raster NO2 per bulan (misalnya NO2_Jan2022.tif, NO2_Feb2022.tif, dll)
raster_files = [
    'LST_2022_01.tif', 'LST_2022_02.tif', 'LST_2022_03.tif',
    'LST_2022_04.tif', 'LST_2022_05.tif', 'LST_2022_06.tif',
    'LST_2022_07.tif', 'LST_2022_08.tif', 'LST_2022_09.tif',
    'LST_2022_10.tif', 'LST_2022_11.tif', 'LST_2022_12.tif',
    'LST_2023_01.tif', 'LST_2023_02.tif', 'LST_2023_03.tif',
    'LST_2023_04.tif', 'LST_2023_05.tif', 'LST_2023_06.tif',
    'LST_2023_07.tif', 'LST_2023_08.tif', 'LST_2023_09.tif',
    'LST_2023_10.tif', 'LST_2023_11.tif', 'LST_2023_12.tif',
    'LST_2024_01.tif', 'LST_2024_02.tif', 'LST_2024_03.tif',
    'LST_2024_04.tif', 'LST_2024_05.tif', 'LST_2024_06.tif',
    'LST_2024_07.tif', 'LST_2024_08.tif', 'LST_2024_09.tif',
    'LST_2024_10.tif', 'LST_2024_11.tif', 'LST_2024_12.tif'
]


# Inisialisasi list untuk menyimpan objek raster
raster_list = []

# Baca semua raster dan tambahkan ke list
for file in raster_files:
    file_path = os.path.join(input_dir, file)
    raster = rioxarray.open_rasterio(file_path)
    raster_list.append(raster)

# Stack semua raster menjadi satu dengan xarray.concat
stacked_raster = xr.concat(raster_list, dim='band')

# Simpan hasil stacking ke file baru menggunakan rioxarray
stacked_raster.rio.to_raster('/content/drive/MyDrive/LST_Monthly/Stack Layer/LST_Jakarta.tif')

print("Stacking selesai dan file disimpan.")

"""# NPP-VIIRS

**Akuisisi Citra**
"""

# -------------------------------
# 1. Parameter & Konfigurasi
# -------------------------------
VIIRS_collection = ee.ImageCollection("NOAA/VIIRS/DNB/MONTHLY_V1/VCMCFG") \
    .filterBounds(AOI) \
    .select('avg_rad')  # Nighttime light band

# -------------------------------
# 2. Buat List Tahun & Bulan
# -------------------------------
start_date = datetime(2018, 1, 1)
end_date = datetime(2024, 12, 31)

ym_list = []
current = start_date
while current <= end_date:
    ym_list.append((current.year, current.month))
    current += relativedelta(months=1)

VIIRS_monthly_images = []

# -------------------------------
# 3. Buat Koleksi Bulanan
# -------------------------------
for y, m in ym_list:
    VIIRS_filtered = VIIRS_collection \
        .filter(ee.Filter.calendarRange(y, y, 'year')) \
        .filter(ee.Filter.calendarRange(m, m, 'month'))

    VIIRS_monthly_mean = VIIRS_filtered.mean() \
        .clip(AOI) \
        .set('year', y) \
        .set('month', m) \
        .set('system:time_start', ee.Date.fromYMD(y, m, 1)) \
        .set('label', f"VIIRS_avg_rad_{y:04d}_{m:02d}") \
        .rename('NTL')

    VIIRS_monthly_images.append(VIIRS_monthly_mean)

VIIRS_monthly_collection = ee.ImageCollection(VIIRS_monthly_images)

# -------------------------------
# 4. Rata-rata (Lintas Tahun)
# -------------------------------
monthly_avg_images = []

for month in range(1, 13):
    monthly_filtered = VIIRS_monthly_collection.filter(ee.Filter.eq('month', month))

    # Rata-rata
    monthly_avg = monthly_filtered.mean() \
        .set('month', month) \
        .set('label', f"NTL_MonthlyAvg_{month:02d}") \
        .rename('NTL_MonthlyAvg')

    monthly_avg_images.append(monthly_avg)

NTL_monthly_avg_collection = ee.ImageCollection(monthly_avg_images)

for i in range(NTL_monthly_avg_collection.size().getInfo()):
    image = NTL_monthly_avg_collection.toList(NTL_monthly_avg_collection.size()).get(i)
    label = ee.Image(image).get('label').getInfo()  # Ambil nama label, misalnya: 'LST_Celsius_2023_05'
    task = ee.batch.Export.image.toDrive(
        image=ee.Image(image),
        description=label,
        folder='NTL_20182024',
        fileNamePrefix=label,
        scale=463.83,  # Resolusi MODIS (meter)
        region=AOI,
        crs='EPSG:32748',  # UTM Zone 48S (bisa disesuaikan)
        maxPixels=1e13
    )
    task.start()
    print(f"Tugas ekspor '{label}' telah dimulai.")

# Direktori file raster dan shapefile
input_dir = '/content/drive/MyDrive/PENGOLAHAN/DATA/NTL-VIIRS_22&24/VIIRS_Monthly/NTL_20182024/NTL_MonthlyAvg_01.tif'
shapefile_path = '/content/drive/MyDrive/PENGOLAHAN/DKI Jakarta/DKI Jakarta.shp'  # Ganti dengan path shapefile kamu

# Baca shapefile menggunakan GeoPandas
gdf = gpd.read_file(shapefile_path)

# Proyeksikan shapefile ke CRS raster
raster_files = sorted(glob.glob(os.path.join(input_dir, '*.tif')))

for file in raster_files:
    with rasterio.open(file) as src:
        lst_data = src.read(1)
        crs = src.crs
        bounds = src.bounds

        # Proyeksikan shapefile jika CRS tidak cocok
        if gdf.crs != src.crs:
            gdf = gdf.to_crs(src.crs)

        # Plot raster dan shapefile overlay
        fig, ax = plt.subplots(figsize=(10, 8))
        show(lst_data, transform=src.transform, cmap='viridis', ax=ax)
        gdf.boundary.plot(ax=ax, edgecolor='cyan', linewidth=1.5)

        # Tambahan elemen visual
        plt.title(f'Rata-rata NTL - {os.path.basename(file)}', fontsize=14)
        plt.xlabel('Longitude')
        plt.ylabel('Latitude')
        plt.colorbar(ax.images[0], label='Nighttime Light')

# Parameter waktu
months = list(range(1, 13))
years = list(range(2022, 2025))

# Dataset VIIRS DNB Monthly Composite
VIIRS = ee.ImageCollection('NOAA/VIIRS/DNB/MONTHLY_V1/VCMCFG') \
    .filterBounds(AOI) \
    .select('avg_rad')

# Loop untuk ekspor tiap bulan
for year in years:
    for month in months:
        image = VIIRS \
            .filter(ee.Filter.calendarRange(year, year, 'year')) \
            .filter(ee.Filter.calendarRange(month, month, 'month')) \
            .first()

        if image:
            reprojected = image \
                .clip(AOI) \
                .set('year', year) \
                .set('month', month)

            label = f'VIIRS_{year}_{month:02d}'

            task = ee.batch.Export.image.toDrive(
                image=reprojected,
                description=label,
                folder='VIIRS_Monthly',
                fileNamePrefix=label,
                region=AOI,
                scale=463.83,
                crs='EPSG:32748',
                maxPixels=1e13
            )
            task.start()
            print(f"ðŸŸ¢ Ekspor dimulai: {label}")

# Folder hasil ekspor
folder_path = '/content/drive/MyDrive/PENGOLAHAN/DATA/NTL-VIIRS_22&24/VIIRS_Monthly'

# Ambil semua file GeoTIFF
tif_files = [f for f in os.listdir(folder_path) if f.endswith('.tif')]

# Tentukan layout plot (misalnya 3 kolom)
cols = 3
rows = (len(tif_files) + cols - 1) // cols
fig, axs = plt.subplots(rows, cols, figsize=(15, 5 * rows))

# Flatten axes untuk loop
axs = axs.flatten()

# Plot semua citra
for idx, tif_file in enumerate(tif_files):
    with rasterio.open(os.path.join(folder_path, tif_file)) as src:
        img = src.read(1)  # Ambil band pertama
        axs[idx].imshow(img, cmap='viridis')
        axs[idx].set_title(tif_file.replace('.tif', ''))
        axs[idx].axis('off')

# Sembunyikan subplot kosong jika ada
for ax in axs[len(tif_files):]:
    ax.axis('off')

plt.tight_layout()
plt.show()

"""**GAP-FILLING**"""

# Folder berisi NTL bulanan 2022-2024 dan rata-rata bulanan 2018â€“2020
path_ntl = '/content/drive/MyDrive/VIIRS_Monthly'
path_mean = '/content/drive/MyDrive/NTL_20182024'
path_output = '/content/drive/MyDrive/VIIRS_Monthly/NTL'

os.makedirs(path_output, exist_ok=True)

# Buat dictionary mean bulanan multiyear {01: path_to_mean_jan.tif, ..., 12: path_to_mean_dec.tif}
mean_monthly = {
    f'{i:02d}': glob.glob(os.path.join(path_mean, f'*_{i:02d}.tif'))[0]
    for i in range(1, 13)
}

# Loop semua file NTL bulanan 2022â€“2024
for filepath in sorted(glob.glob(os.path.join(path_ntl, '*.tif'))):
    filename = os.path.basename(filepath)
    # Ambil bulan dari nama file, misalnya 'VIIRS_2023_01.tif' â†’ '01'
    month = filename.split('_')[-1].split('.')[0]

    with rasterio.open(filepath) as src:
        ntl_data = src.read(1)
        profile = src.profile

    with rasterio.open(mean_monthly[month]) as mean_src:
        mean_data = mean_src.read(1)

    # Ganti nilai 0 di ntl_data dengan nilai dari mean_data
    ntl_filled = np.where(ntl_data == 0, mean_data, ntl_data)

    # Simpan ke file baru
    output_path = os.path.join(path_output, filename)
    with rasterio.open(output_path, 'w', **profile) as dst:
        dst.write(ntl_filled, 1)

    print(f"âœ… Selesai isi: {filename}")

# Direktori file raster dan shapefile
input_dir = '/content/drive/MyDrive/VIIRS_Monthly/NTL'
shapefile_path = '/content/drive/MyDrive/PENGOLAHAN/DKI Jakarta/DKI Jakarta.shp'  # Ganti dengan path shapefile kamu

# Baca shapefile menggunakan GeoPandas
gdf = gpd.read_file(shapefile_path)

# Proyeksikan shapefile ke CRS raster
raster_files = sorted(glob.glob(os.path.join(input_dir, '*.tif')))

for file in raster_files:
    with rasterio.open(file) as src:
        lst_data = src.read(1)
        crs = src.crs
        bounds = src.bounds

        # Proyeksikan shapefile jika CRS tidak cocok
        if gdf.crs != src.crs:
            gdf = gdf.to_crs(src.crs)

        # Plot raster dan shapefile overlay
        fig, ax = plt.subplots(figsize=(10, 8))
        show(lst_data, transform=src.transform, cmap='viridis', ax=ax)
        gdf.boundary.plot(ax=ax, edgecolor='cyan', linewidth=1.5)

        # Tambahan elemen visual
        plt.title(f'Rata-rata LST - {os.path.basename(file)}', fontsize=14)
        plt.xlabel('Longitude')
        plt.ylabel('Latitude')
        plt.colorbar(ax.images[0], label='Land Surface Temperature (Â°C)')

"""**UPSCALING**"""

def visualize_comparison(before_array, after_array, title):
    fig, axs = plt.subplots(1, 2, figsize=(12, 5))
    cmap = 'viridis'

    vmin = min(np.nanmin(before_array), np.nanmin(after_array))
    vmax = max(np.nanmax(before_array), np.nanmax(after_array))

    im1 = axs[0].imshow(before_array, cmap=cmap, vmin=vmin, vmax=vmax)
    axs[0].set_title("Sebelum Resampling")
    axs[0].set_xlabel("Kolom")
    axs[0].set_ylabel("Baris")
    plt.colorbar(im1, ax=axs[0], orientation="vertical", fraction=0.05)

    im2 = axs[1].imshow(after_array, cmap=cmap, vmin=vmin, vmax=vmax)
    axs[1].set_title("Setelah Resampling (1000m)")
    axs[1].set_xlabel("Kolom")
    axs[1].set_ylabel("Baris")
    plt.colorbar(im2, ax=axs[1], orientation="vertical", fraction=0.05)

    plt.suptitle(title, fontsize=14)
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

def resample_raster_to_1km(input_path, output_path, target_resolution=1000, visualize=True):
    with rasterio.open(input_path) as src:
        src_array = src.read(1)
        src_transform = src.transform
        src_crs = src.crs
        src_bounds = src.bounds

        dst_transform, width, height = calculate_default_transform(
            src_crs, src_crs, src.width, src.height, *src_bounds, resolution=target_resolution
        )

        kwargs = src.meta.copy()
        kwargs.update({
            'crs': src_crs,
            'transform': dst_transform,
            'width': width,
            'height': height
        })

        with rasterio.open(output_path, 'w', **kwargs) as dst:
            dst_array = np.empty((height, width), dtype=src.dtypes[0])
            reproject(
                source=src_array,
                destination=dst_array,
                src_transform=src_transform,
                src_crs=src_crs,
                dst_transform=dst_transform,
                dst_crs=src_crs,
                resampling=Resampling.bilinear,
                dst_nodata=np.nan,
                src_nodata=np.nan
            )
            dst.write(dst_array, 1)

    print(f"âœ… {os.path.basename(input_path)} berhasil di-resample ke 1000m")

    if visualize:
        visualize_comparison(src_array, dst_array, os.path.basename(input_path))

# === Batch Processing ===
input_folder = "/content/drive/MyDrive/VIIRS_Monthly/NTL"
output_folder = "/content/drive/MyDrive/VIIRS_Monthly/output_resampling_VIIRS"
os.makedirs(output_folder, exist_ok=True)

raster_files = glob(os.path.join(input_folder, "*.tif"))

for raster_file in raster_files:
    filename = os.path.basename(raster_file)
    output_path = os.path.join(output_folder, f"{os.path.splitext(filename)[0]}.tif")
    resample_raster_to_1km(raster_file, output_path, visualize=True)

def evaluate_resampling_accuracy(original_path, resampled_path):
    with rasterio.open(original_path) as src1, rasterio.open(resampled_path) as src2:
        original = src1.read(1)
        resampled = src2.read(1)

        # Upscale hasil resampling ke dimensi asli
        zoom_factors = (
            original.shape[0] / resampled.shape[0],
            original.shape[1] / resampled.shape[1]
        )
        resampled_upscaled = zoom(resampled, zoom_factors, order=1)  # bilinear interpolation

        # Mask untuk membandingkan hanya nilai valid (bukan NaN)
        mask = ~np.isnan(original) & ~np.isnan(resampled_upscaled)
        y_true = original[mask]
        y_pred = resampled_upscaled[mask]

        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)

        return {
            "filename": os.path.basename(original_path),
            "RMSE": rmse,
            "MAE": mae,
            "MSE": mse,
            "R2": r2,
        }

# === Batch Evaluasi ===
original_folder = "/content/drive/MyDrive/VIIRS_Monthly/NTL"
resampled_folder = "/content/drive/MyDrive/VIIRS_Monthly/output_resampling_VIIRS"

original_files = sorted(glob(os.path.join(original_folder, "*.tif")))
resampled_files = sorted(glob(os.path.join(resampled_folder, "*.tif")))

results = []
for orig, resamp in zip(original_files, resampled_files):
    res = evaluate_resampling_accuracy(orig, resamp)
    print(f"ðŸ“Š {res['filename']}: RMSE={res['RMSE']:.2e}, MAE={res['MAE']:.2e}, MSE={res['MSE']:.2e}, R2={res['R2']:.4f}")
    results.append(res)

"""**LAYER STACKING**"""

# Direktori tempat file raster NO2 disimpan
input_dir = '/content/drive/MyDrive/VIIRS_Monthly/output_resampling_VIIRS'  # Ganti dengan direktori sebenarnya

# Daftar file raster NO2 per bulan (misalnya NO2_Jan2022.tif, NO2_Feb2022.tif, dll)
raster_files = [
    'VIIRS_2022_01.tif', 'VIIRS_2022_02.tif', 'VIIRS_2022_03.tif',
    'VIIRS_2022_04.tif', 'VIIRS_2022_05.tif', 'VIIRS_2022_06.tif',
    'VIIRS_2022_07.tif', 'VIIRS_2022_08.tif', 'VIIRS_2022_09.tif',
    'VIIRS_2022_10.tif', 'VIIRS_2022_11.tif', 'VIIRS_2022_12.tif',
    'VIIRS_2023_01.tif', 'VIIRS_2023_02.tif', 'VIIRS_2023_03.tif',
    'VIIRS_2023_04.tif', 'VIIRS_2023_05.tif', 'VIIRS_2023_06.tif',
    'VIIRS_2023_07.tif', 'VIIRS_2023_08.tif', 'VIIRS_2023_09.tif',
    'VIIRS_2023_10.tif', 'VIIRS_2023_11.tif', 'VIIRS_2023_12.tif',
    'VIIRS_2024_01.tif', 'VIIRS_2024_02.tif', 'VIIRS_2024_03.tif',
    'VIIRS_2024_04.tif', 'VIIRS_2024_05.tif', 'VIIRS_2024_06.tif',
    'VIIRS_2024_07.tif', 'VIIRS_2024_08.tif', 'VIIRS_2024_09.tif',
    'VIIRS_2024_10.tif', 'VIIRS_2024_11.tif', 'VIIRS_2024_12.tif'
]


# Inisialisasi list untuk menyimpan objek raster
raster_list = []

# Baca semua raster dan tambahkan ke list
for file in raster_files:
    file_path = os.path.join(input_dir, file)
    raster = rioxarray.open_rasterio(file_path)
    raster_list.append(raster)

# Stack semua raster menjadi satu dengan xarray.concat
stacked_raster = xr.concat(raster_list, dim='band')

# Simpan hasil stacking ke file baru menggunakan rioxarray
stacked_raster.rio.to_raster('/content/drive/MyDrive/VIIRS_Monthly/Stacking Layer/VIIRS_Jakarta.tif')

print("Stacking selesai dan file disimpan.")

"""# Ekstraksi Pixels Value

**RASTERISASI GRID**
"""

# 1. Baca shapefile grid 1 km
grid_shp_path = "/content/drive/MyDrive/PENGOLAHAN/DATA/Grid Jakarta/Jakarta_grid.shp"
grid_gdf = gpd.read_file(grid_shp_path)

# 2. Tentukan resolusi dan ukuran grid (disesuaikan dengan CRS kamu, misalnya meter)
resolution = 1000  # 1 km
bounds = grid_gdf.total_bounds  # xmin, ymin, xmax, ymax

# 3. Hitung ukuran raster
width = int((bounds[2] - bounds[0]) / resolution)
height = int((bounds[3] - bounds[1]) / resolution)
transform = from_origin(bounds[0], bounds[3], resolution, resolution)

# 4. Rasterisasi
out_shape = (height, width)
rasterized = rasterize(
    [(geom, 1) for geom in grid_gdf.geometry],
    out_shape=out_shape,
    transform=transform,
    fill=0,
    dtype='uint8'
)

# 5. Simpan sebagai raster (GeoTIFF)
raster_ref_path = "/content/drive/MyDrive/PENGOLAHAN/DATA/Grid Jakarta/GRID_4ALIGN.tif"
with rasterio.open(
    raster_ref_path, "w",
    driver="GTiff",
    height=height,
    width=width,
    count=1,
    dtype=rasterized.dtype,
    crs=grid_gdf.crs,
    transform=transform
) as dst:
    dst.write(rasterized, 1)

print("âœ“ Grid 1km berhasil dirasterisasi.")

"""**ALIGN TO GRID**"""

# Path referensi (gunakan LST sebagai referensi)
ref_path = "/content/drive/MyDrive/PENGOLAHAN/DATA/Grid Jakarta/GRID_4ALIGN.tif"
ref = rxr.open_rasterio(ref_path, masked=True)

# Raster lainnya
raster_files = {
    "NO2": "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_NO2_Monthly/Stacking Layer/NO2_Jakarta.tif",
    "HCHO": "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_HCHO_Monthly/Stacking Layer/HCHO_Jakarta.tif",
    "CO": "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_CO_Monthly/Stacking Layer/CO_Jakarta.tif",
    "SO2": "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_SO2_Monthly/Stacking Layer/SO2_Jakarta.tif",
    "O3": "/content/drive/MyDrive/PENGOLAHAN/DATA/PrekusorO3-Sentinel5P_22&24/Tropomi_O3_Monthly/Stacking Layer/TrO3_Jakarta.tif",
    "EVI": "/content/drive/MyDrive/PENGOLAHAN/DATA/DATA NON CLIP/Salinan EVI_Stack_22-24.tif",
    "LST":"/content/drive/MyDrive/PENGOLAHAN/DATA/LSTEVI-MODIS_22&24/LST_Monthly/Stack Layer/LST_Jakarta.tif",
    "U10":"/content/drive/MyDrive/PENGOLAHAN/DATA/DATA NON CLIP/Salinan ERA5_10u_Monthly_2022_2024_NaN_Interpolated_1km.tif",
    "NTL": "/content/drive/MyDrive/PENGOLAHAN/DATA/NTL-VIIRS_22&24/VIIRS_Monthly/Stacking Layer/VIIRS_Jakarta.tif",
    "V10": "/content/drive/MyDrive/PENGOLAHAN/DATA/DATA NON CLIP/Salinan ERA5_10v_Monthly_2022_2024_NaN_Interpolated_1km.tif",
    "SP": "/content/drive/MyDrive/PENGOLAHAN/DATA/DATA NON CLIP/Salinan ERA5_SP_Monthly_2022_2024_NaN_Interpolated_1km.tif",
    "TP": "/content/drive/MyDrive/PENGOLAHAN/DATA/DATA NON CLIP/Salinan ERA5_TP_Monthly_2022_2024_NaN_Interpolated_1km.tif",
    "E": "/content/drive/MyDrive/PENGOLAHAN/DATA/DATA NON CLIP/Salinan ERA5_e_Monthly_2022_2024_NaN_Interpolated_1km.tif",
    "T2M": "/content/drive/MyDrive/PENGOLAHAN/DATA/DATA NON CLIP/Salinan ERA5_T2M_Monthly_2022_2024_NaN_Interpolated_1km.tif",
    "SSR": "/content/drive/MyDrive/PENGOLAHAN/DATA/DATA NON CLIP/Salinan ERA5_SSR_Monthly_2022_2024_NaN_Interpolated_1km.tif"
}

# Output folder (sesuai dengan folder yang kamu tentukan)
output_dir = "/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/ALIGNED RASTER"
os.makedirs(output_dir, exist_ok=True)

# Proses align setiap raster ke LST
for var, path in raster_files.items():
    try:
        ds = rxr.open_rasterio(path, masked=True)
        ds_aligned = ds.rio.reproject_match(ref)
        output_path = os.path.join(output_dir, f"{var}_aligned.tif")
        ds_aligned.rio.to_raster(output_path)
        print(f"âœ“ {var} aligned and saved to {output_path}")
    except Exception as e:
        print(f"âš ï¸ Failed to align {var}: {e}")

# Buka referensi dan beberapa hasil aligned untuk dicek overlay-nya
lst = rxr.open_rasterio("/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/ALIGNED RASTER/LST_aligned.tif", masked=True).squeeze()
no2 = rxr.open_rasterio("/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/ALIGNED RASTER/NO2_aligned.tif", masked=True).squeeze()
viirs = rxr.open_rasterio("/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/ALIGNED RASTER/NTL_aligned.tif", masked=True).squeeze()

# Select the first band for display
lst_band = lst[0]  # Assuming you want the first band of LST
no2_band = no2[0]  # Assuming you want the first band of NO2
viirs_band = viirs[0]  # Assuming you want the first band of VIIRS

# Plot 3 lapisan sebagai overlay (gunakan alpha transparan)
plt.figure(figsize=(10, 8))

plt.imshow(lst_band, cmap="Greys", alpha=1.0)       # LST (referensi)
plt.imshow(no2_band, cmap="Reds", alpha=0.5)        # NO2 (overlay merah)
plt.imshow(viirs_band, cmap="Blues", alpha=0.5)     # VIIRS (overlay biru)

plt.title("Overlay LST (grey), NOâ‚‚ (red), VIIRS (blue)")
plt.axis("off")
plt.show()

"""CLIP DATA"""

# Shapefile batas wilayah (pastikan sudah dalam CRS UTM 48S atau sama dengan raster)
shp_path = "/content/drive/MyDrive/PENGOLAHAN/DATA/Grid Jakarta/Grid Jakarta.shp"
gdf = gpd.read_file(shp_path)
gdf = gdf.to_crs("EPSG:32748")  # Pastikan CRS sama

# Folder input aligned rasters
input_dir = "/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/ALIGNED RASTER"

# Folder output hasil crop
output_dir = "/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/CROPPED"
os.makedirs(output_dir, exist_ok=True)

# Daftar file TIFF hasil aligned
tif_files = [f for f in os.listdir(input_dir) if f.endswith(".tif")]

# Proses crop
for tif_file in tif_files:
    try:
        # Load raster
        raster_path = os.path.join(input_dir, tif_file)
        raster = rxr.open_rasterio(raster_path, masked=True)

        # Crop ke shapefile
        raster_cropped = raster.rio.clip(gdf.geometry, gdf.crs, drop=True, invert=False)
        raster_cropped = raster_cropped.squeeze()  # Hilangkan dimensi ekstra

        # Simpan hasil crop
        out_path = os.path.join(output_dir, tif_file.replace("_aligned", "_JAKARTA"))
        raster_cropped.rio.to_raster(out_path, compress="deflate")

        print(f"âœ“ Cropped and saved: {out_path}")
    except Exception as e:
        print(f"âš ï¸ Gagal crop {tif_file}: {e}")

# Folder hasil crop
cropped_dir = "/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/CROPPED"

# Ambil semua file hasil crop
tif_files = sorted([f for f in os.listdir(cropped_dir) if f.endswith(".tif")])

# Tentukan jumlah kolom dan baris untuk subplot
ncols = 4
nrows = -(-len(tif_files) // ncols)  # Ceiling division

# Ukuran plot
fig, axs = plt.subplots(nrows, ncols, figsize=(18, 4 * nrows))
axs = axs.flatten()

# Plot setiap raster
for i, tif_file in enumerate(tif_files):
    path = os.path.join(cropped_dir, tif_file)
    data = rxr.open_rasterio(path, masked=True).squeeze()

    # Select the first band for display if data has multiple bands
    if data.ndim == 3:
        data = data[0]  # or data.isel(band=0)

    ax = axs[i]
    im = ax.imshow(data, cmap="viridis")
    ax.set_title(tif_file.replace("_cropped.tif", ""), fontsize=10)
    ax.axis("off")

    # Tambahkan colorbar
    cbar = plt.colorbar(im, ax=ax, shrink=0.7)
    cbar.ax.tick_params(labelsize=8)

# Hilangkan subplot kosong
for j in range(i + 1, len(axs)):
    axs[j].axis("off")

plt.tight_layout()
plt.suptitle("Hasil Crop Raster", fontsize=16, y=1.02)
plt.show()

"""ekstrak nilai"""

# === DICTIONARY FILE RASTER ===
raster_files_dir = "/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/CROPPED"  # Directory containing raster files
raster_files = {
    os.path.splitext(os.path.basename(file))[0]: file  # Extract filename (without extension) as key
    for file in glob.glob(os.path.join(raster_files_dir, "*.tif"))  # Get all .tif files in the directory
}

start_date = "2022-01"
output_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/OUTER"
os.makedirs(output_folder, exist_ok=True)

# === BACA & PROSES ===
data_per_bulan = {}

for var, path in raster_files.items():
    print(f"Memproses: {var}")

    stack = rxr.open_rasterio(path, masked=True)
    stack = stack.rio.reproject("EPSG:32748")
    stack = stack.squeeze()

    time_range = pd.date_range(start=start_date, periods=stack.shape[0], freq="MS").strftime("%Y-%m").tolist()

    for i, waktu in enumerate(time_range):
        layer = stack.isel(band=i)
        df = layer.to_dataframe(name=var).reset_index().drop(columns=["band", "spatial_ref"], errors="ignore")
        df["x"] = df["x"].round(5)
        df["y"] = df["y"].round(5)
        df = df.dropna(subset=[var])

        if waktu not in data_per_bulan:
            data_per_bulan[waktu] = df
        else:
            data_per_bulan[waktu] = data_per_bulan[waktu].merge(df, on=["x", "y"], how="outer")

# === GABUNGKAN & SIMPAN PER TAHUN ===
data_per_tahun = {}

for waktu, df in data_per_bulan.items():
    df = df.dropna(thresh=5)
    df = df.rename(columns={"x": "Lon", "y": "Lat"})
    df["Waktu"] = waktu
    tahun = waktu.split("-")[0]

    if tahun not in data_per_tahun:
        data_per_tahun[tahun] = [df]
    else:
        data_per_tahun[tahun].append(df)

for tahun, list_df in data_per_tahun.items():
    gabung_df = pd.concat(list_df, ignore_index=True)
    gabung_df.to_csv(os.path.join(output_folder, f"Ekstraksi_{tahun}.csv"), index=False)

print("âœ“ Ekstraksi selesai dan file CSV per tahun telah disimpan.")

# 1. Baca file CSV hasil ekstraksi
csv_path = '/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/OUTER/Ekstraksi_2022.csv'
df = pd.read_csv(csv_path)

# 2. Cek jumlah NaN di tiap kolom
print("Jumlah NaN:")
print(df.isna().sum())

print("Jumlah Data:", len(df))

"""**Missing Value Filling**"""

df = pd.read_csv('/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/OUTER/Ekstraksi_2022.csv')

# Mengisi NaN dengan median per kolom
df_filled = df.fillna(df.median(numeric_only=True))

# Cek ulang setelah pengisian
print("\nJumlah NaN setelah diisi:")
print(df_filled.isna().sum())

# Buat direktori jika belum ada
output_dir = "/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/OUTER/Missing Value Filled"
os.makedirs(output_dir, exist_ok=True)  # This line creates the directory

# Simpan hasilnya
df_filled.to_csv(os.path.join(output_dir, "Data_2022.csv"), index=False)
print("\nâœ“ Data berhasil disimpan")

"""**Cek Missing Value**"""

# 1. Baca file CSV hasil ekstraksi
csv_path = '/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/OUTER/Ekstraksi_2023.csv'
df = pd.read_csv(csv_path)

# 2. Cek jumlah NaN di tiap kolom
print("Jumlah NaN:")
print(df.isna().sum())

print("Jumlah Data:", len(df))

df = pd.read_csv('/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/OUTER/Ekstraksi_2023.csv')

# Mengisi NaN dengan median per kolom
df_filled = df.fillna(df.median(numeric_only=True))

# Cek ulang setelah pengisian
print("\nJumlah NaN setelah diisi:")
print(df_filled.isna().sum())

# Buat direktori jika belum ada
output_dir = "/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/OUTER/Missing Value Filled"
os.makedirs(output_dir, exist_ok=True)  # This line creates the directory

# Simpan hasilnya
df_filled.to_csv(os.path.join(output_dir, "Data_2023.csv"), index=False)
print("\nâœ“ Data berhasil disimpan")

import pandas as pd

# 1. Baca file CSV hasil ekstraksi
csv_path = '/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/OUTER/Ekstraksi_2024.csv'
df = pd.read_csv(csv_path)

# 2. Cek jumlah NaN di tiap kolom
print("Jumlah NaN:")
print(df.isna().sum())

print("Jumlah Data:", len(df))

import pandas as pd
import os

df = pd.read_csv('/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/OUTER/Ekstraksi_2024.csv')

# Mengisi NaN dengan median per kolom
df_filled = df.fillna(df.median(numeric_only=True))

# Cek ulang setelah pengisian
print("\nJumlah NaN setelah diisi:")
print(df_filled.isna().sum())

# Buat direktori jika belum ada
output_dir = "/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/OUTER/Missing Value Filled"
os.makedirs(output_dir, exist_ok=True)  # This line creates the directory

# Simpan hasilnya
df_filled.to_csv(os.path.join(output_dir, "Data_2024.csv"), index=False)
print("\nâœ“ Data berhasil disimpan")

"""**Ekstraksi DI LOKASI STASIUN**"""

### EKSTRAKSI DI LOKASI STASIUN ###


# === PATH ===
# raster_files = "/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/CROPPED"
raster_files_dir = "/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/CROPPED"  # Directory containing raster files
raster_files = {
    os.path.splitext(os.path.basename(file))[0]: file  # Extract filename (without extension) as key
    for file in glob.glob(os.path.join(raster_files_dir, "*.tif"))  # Get all .tif files in the directory
}


shapefile_stasiun = "/content/drive/MyDrive/PENGOLAHAN/DATA/SKPU DKI JAKARTA/Lokasi_SKPU_Jakarta.shp"
output_folder = "/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/Ekstraksi Stasiun"
os.makedirs(output_folder, exist_ok=True)

start_date = "2022-01"

# === BACA KOORDINAT STASIUN ===
gdf_stasiun = gpd.read_file(shapefile_stasiun)  # pastikan shapefile berisi titik dengan kolom Lat, Lon atau Geometry
gdf_stasiun = gdf_stasiun.to_crs("EPSG:32748")  # sesuaikan dengan CRS raster (misal EPSG:32748)

# === INISIASI DATA PER WAKTU ===
data_per_bulan = {}

# === EKSTRAKSI ===
for var, path in raster_files.items(): # Now raster_files is a dictionary and has the items() method
    print(f"Memproses: {var}")

    stack = rxr.open_rasterio(path, masked=True)
    stack = stack.rio.reproject("EPSG:32748")
    stack = stack.squeeze()

    time_range = pd.date_range(start=start_date, periods=stack.shape[0], freq="MS").strftime("%Y-%m").tolist()

    for i, waktu in enumerate(time_range):
        band = stack.isel(band=i)
        df_extract = gdf_stasiun.copy()

        # Ekstraksi nilai untuk setiap stasiun
        df_extract[var] = [band.sel(x=pt.x, y=pt.y, method="nearest").item() for pt in df_extract.geometry]
        df_extract["Waktu"] = waktu

        # Menyimpan data ekstraksi per bulan
        if waktu not in data_per_bulan:
            data_per_bulan[waktu] = df_extract[["Station_ID", "geometry", "Waktu", var]]
        else:
            data_per_bulan[waktu] = data_per_bulan[waktu].merge(
                df_extract[["Station_ID", "Waktu", var]],
                on=["Station_ID", "Waktu"],
                how="left"
            )

# === GABUNG PER TAHUN & SIMPAN ===
data_per_tahun = {}

for waktu, df in data_per_bulan.items():
    tahun = waktu.split("-")[0]
    if tahun not in data_per_tahun:
        data_per_tahun[tahun] = [df]
    else:
        data_per_tahun[tahun].append(df)

for tahun, list_df in data_per_tahun.items():
    df_final = pd.concat(list_df, ignore_index=True)
    df_final.to_csv(os.path.join(output_folder, f"Ekstraksi_Stasiun_{tahun}.csv"), index=False)

print("âœ“ Ekstraksi per stasiun selesai dan disimpan per tahun.")

# Setelah ekstraksi selesai
df = pd.read_csv('/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/Ekstraksi Stasiun/Ekstraksi_Stasiun_2022.csv',sep=';')

# Set agar semua baris tampil
pd.set_option('display.max_rows', None)

# Print semua hasil
print(df)

# Baca file hasil ekstraksi
df = pd.read_csv('/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/Ekstraksi Stasiun/Ekstraksi_Stasiun_2022.csv',sep=';')

# Pastikan kolom 'Waktu' dalam format datetime
df['Waktu'] = pd.to_datetime(df['Waktu'])

# Ambil hanya kolom numerik (variabel hasil ekstraksi)
variabel_numerik = df.select_dtypes(include='number').columns.tolist()
variabel_numerik = [col for col in variabel_numerik if col not in ['Station_ID']]  # Exclude ID

# Visualisasi setiap variabel
for var in variabel_numerik:
    plt.figure(figsize=(12, 6))
    sns.lineplot(data=df, x='Waktu', y=var, hue='Station_ID', marker='o')
    plt.title(f'{var} per Bulan per Stasiun')
    plt.xlabel('Bulan')
    plt.ylabel(var)
    plt.xticks(rotation=45)
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Setelah ekstraksi selesai
df = pd.read_csv('/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/Ekstraksi Stasiun/Ekstraksi_Stasiun_2023.csv',sep=';')

# Set agar semua baris tampil
pd.set_option('display.max_rows', None)

# Print semua hasil
print(df)

# Baca file hasil ekstraksi
df = pd.read_csv('/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/Ekstraksi Stasiun/Ekstraksi_Stasiun_2023.csv',sep=';')

# Pastikan kolom 'Waktu' dalam format datetime
df['Waktu'] = pd.to_datetime(df['Waktu'])

# Ambil hanya kolom numerik (variabel hasil ekstraksi)
variabel_numerik = df.select_dtypes(include='number').columns.tolist()
variabel_numerik = [col for col in variabel_numerik if col not in ['Station_ID']]  # Exclude ID

# Visualisasi setiap variabel
for var in variabel_numerik:
    plt.figure(figsize=(12, 6))
    sns.lineplot(data=df, x='Waktu', y=var, hue='Station_ID', marker='o')
    plt.title(f'{var} per Bulan per Stasiun')
    plt.xlabel('Bulan')
    plt.ylabel(var)
    plt.xticks(rotation=45)
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Setelah ekstraksi selesai
df = pd.read_csv('/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/Ekstraksi Stasiun/Ekstraksi_Stasiun_2024.csv',sep=';')

# Set agar semua baris tampil
pd.set_option('display.max_rows', None)

# Print semua hasil
print(df)

# Baca file hasil ekstraksi
df = pd.read_csv('/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/Ekstraksi Stasiun/Ekstraksi_Stasiun_2024.csv',sep=';')

# Pastikan kolom 'Waktu' dalam format datetime
df['Waktu'] = pd.to_datetime(df['Waktu'])

# Ambil hanya kolom numerik (variabel hasil ekstraksi)
variabel_numerik = df.select_dtypes(include='number').columns.tolist()
variabel_numerik = [col for col in variabel_numerik if col not in ['Station_ID']]  # Exclude ID

# Visualisasi setiap variabel
for var in variabel_numerik:
    plt.figure(figsize=(12, 6))
    sns.lineplot(data=df, x='Waktu', y=var, hue='Station_ID', marker='o')
    plt.title(f'{var} per Bulan per Stasiun')
    plt.xlabel('Bulan')
    plt.ylabel(var)
    plt.xticks(rotation=45)
    plt.grid(True)
    plt.tight_layout()
    plt.show()

"""# Feature Engineering"""

import pandas as pd
import geopandas as gpd
from shapely import wkt
from sklearn.preprocessing import LabelEncoder
import glob
import os

# === 1. Baca semua file CSV dari folder ===
folder_path = '/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/Ekstraksi Stasiun'
csv_files = glob.glob(os.path.join(folder_path, '*.csv'))

# Gabungkan semua file
df = pd.concat([pd.read_csv(f, sep=';') for f in csv_files], ignore_index=True)

# === 2. Konversi kolom 'Waktu' ke datetime ===
df['Waktu'] = pd.to_datetime(df['Waktu'], errors='coerce')

# === 3. Ekstrak bulan dan tahun dari kolom waktu ===
df['Bulan'] = df['Waktu'].dt.month
df['Tahun'] = df['Waktu'].dt.year

# === 4. Label Encoding untuk Station_ID ===
le = LabelEncoder()
df['Station_ID'] = le.fit_transform(df['Station_ID'].astype(str)) + 1

# === 5. Ubah kolom geometry WKT jadi shapely Point ===
df['geometry'] = df['geometry'].apply(wkt.loads)

# === 6. Ubah ke GeoDataFrame dan tetapkan CRS UTM Zone 48S ===
gdf = gpd.GeoDataFrame(df, geometry='geometry')
gdf.set_crs(epsg=32748, inplace=True)

# === 7. Tambahkan kolom koordinat UTM ===
gdf['Easting'] = gdf.geometry.x
gdf['Northing'] = gdf.geometry.y

# === 8. Hapus kolom geometry ===
gdf = gdf.drop(columns='geometry')

# === 9. Urutkan berdasarkan Tahun dan Bulan ===
gdf = gdf.sort_values(by=['Tahun', 'Bulan'], ascending=[True, True])

# === 10. Simpan ke CSV baru ===
output_path = '/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/Ekstraksi Stasiun/Data_TrainTest_20222024.csv'
gdf.to_csv(output_path, index=False)

print(f'Hasil berhasil disimpan ke: {output_path}')
print(gdf.head())

"""# Exploratory Data Analysis"""

# === 1. Path File Input ===
file_path = '/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/Ekstraksi Stasiun/Data_TrainTest_20222024.csv'  # Ganti dengan path file CSV kamu
numerical_columns = ['NO2', 'HCHO', 'CO', 'SO2', 'TropomiO3', 'U10', 'V10', 'SP', 'TP', 'E', 'T2M', 'SSR', 'EVI', 'LST', 'NTL', 'StasiunO3']


df = pd.read_csv(file_path)

df.shape
df.info()

# === 2. Statistik Deskriptif ===
df.describe().T.style.bar(subset=['mean'])

# === 3. Visualisasi Histogram Distribusi Data ===
_ = df.hist(bins=20, figsize=(20, 15))

sns.histplot(df["SO2"])

sns.histplot(df["SSR"])

# === Cek Missing Values ===
df.isnull().sum()

# === Cek Duplicate Values ===
df[df.duplicated()]

# === Cek Jumlah Nilai Unik ===
df.nunique()

# === 6. Boxplot ===
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 6))  # Lebar diperbesar untuk side-by-side
sns.boxplot(data=df[numerical_columns], palette='pastel')
plt.title("Boxplot")
plt.xticks(rotation=45)
plt.grid(True, axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# === 7. Handling Outlier Data ===
def clean_outliers(frame, feature):
    column_data = frame[feature]
    column_data = column_data[~np.isnan(column_data)]

    mean, std = np.mean(column_data), np.std(column_data)

    lower_bound = mean - 2 * std
    upper_bound = mean + 2 * std

    # Ganti nilai outlier dengan NaN
    frame.loc[(frame[feature] < lower_bound) | (frame[feature] > upper_bound), feature] = np.nan
    return frame

def clean_data(frame, is_test=False):
    for f in numerical_columns:
        # Lewati kolom target saat is_test = True
        if is_test and f == "StasiunO3":
            continue

        # Ganti nilai anomali khusus dengan NaN
        frame.loc[frame[f] == -99.0, f] = np.nan
        frame.loc[frame[f] == 99.0, f] = np.nan
        frame.loc[frame[f] == -999.0, f] = np.nan
        frame.loc[frame[f] == 999.0, f] = np.nan

        # Bersihkan outlier
        frame = clean_outliers(frame, f)

    # Imputasi nilai NaN
    for f in frame.columns:
        if is_test and f == "StasiunO3":
            continue
        if f in numerical_columns:
            frame[f] = frame[f].fillna(frame[f].median())
        else:
            frame[f] = frame[f].fillna(frame[f].mode()[0])

    return frame

# Panggil fungsi pembersih data
df_clean = clean_data(df)

# === 8. Statistik Deskriptif Setelah Outlier ===
df_clean.describe().T.style.bar(subset=['mean'])

# === 9. Visualisasi Histogram Distribusi Data Setelah Outlier ===
_ = df_clean.hist(bins=20, figsize=(20, 15))

# === 10. Boxplot Setelah Outlier ===
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 6))
sns.boxplot(data=df_clean[numerical_columns], palette='pastel')
plt.title("Boxplot Setelah Outlier")
plt.xticks(rotation=45)
plt.grid(True, axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# === 11. Korelasi Antar Variabel ===
plt.figure(figsize=(12,10))
sns.heatmap(df_clean[numerical_columns].corr(method="spearman"), annot=True, fmt='.2f', cmap='coolwarm')
plt.title('Correlation Heatmap', fontsize=16)
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

# Simpan heatmap ke file
#output_corr_path = '/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/Ekstraksi Stasiun/Korelasi_Data.png'  # Ganti dengan path untuk menyimpan
#plt.savefig(output_corr_path)
#plt.show()

# Direktori untuk menyimpan hasil outlier handling
output_outlier_dir = "/content/drive/MyDrive/PENGOLAHAN/HASIL/EDA/Outlier_Handled"
os.makedirs(output_outlier_dir, exist_ok=True)

# Simpan DataFrame setelah outlier handling
output_file_path = os.path.join(output_outlier_dir, "Data_20222024_OutlierHandled.csv")
df_clean.to_csv(output_file_path, index=False)

print(f"âœ… Hasil outlier handling berhasil disimpan ke: {output_file_path}")

"""# Modeling With Easting & Northing"""

import joblib
import lightgbm as lgb
import matplotlib.pyplot as plt
import numpy as np
import optuna
import pandas as pd
import seaborn as sns
from sklearn.model_selection import KFold, GroupKFold, cross_val_score, cross_validate
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from lightgbm import LGBMRegressor
from sklearn.metrics import make_scorer
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import warnings

warnings.filterwarnings("ignore", category=FutureWarning)

#Load Dataset
ozone = pd.read_csv("/content/drive/MyDrive/PENGOLAHAN/HASIL/EDA/Outlier_Handled/Data_20222024_OutlierHandled.csv")

print (ozone)

# Define features & target
features = [col for col in ozone.columns if col not in ['StasiunO3', 'Station_ID', 'Waktu']]
target = 'StasiunO3'
X = ozone[features]
y = ozone[target]
groups = ozone['Station_ID']

"""Model Selelction"""

# KFold
cv = KFold(n_splits=10, shuffle=True, random_state=42)

# Model pipelines tanpa scaler
pipelines = {
    'LinearRegression': LinearRegression(),
    'RandomForest': RandomForestRegressor(
        n_estimators=28,
        max_depth=30,
        random_state=42
    ),
    'LightGBM': LGBMRegressor(force_row_wise=True)
}

# Evaluasi dengan cross_validate
scoring = {
    'rmse': 'neg_root_mean_squared_error',
    'mae': 'neg_mean_absolute_error',
    'r2': 'r2'
}

results = {}

for name, model in pipelines.items():
    scores = cross_validate(model, X, y, cv=cv, scoring=scoring, return_train_score=False)

    results[name] = {
        'RMSE': -np.mean(scores['test_rmse']),
        'MAE': -np.mean(scores['test_mae']),
        'RÂ²': np.mean(scores['test_r2'])
    }

results_df = pd.DataFrame(results).T
print(results_df)

"""Parameter Optimization"""

# Fungsi Hyperparameter
def objective(trial):
    # Hyperparameter space
    boosting_type = trial.suggest_categorical("boosting_type", ["dart", "gbdt"])
    lambda_l1 = trial.suggest_float("lambda_l1", 1e-8, 10.0, log=True)
    lambda_l2 = trial.suggest_float("lambda_l2", 1e-8, 10.0, log=True)
    num_leaves = trial.suggest_int("num_leaves", 2, 256)
    feature_fraction = trial.suggest_float("feature_fraction", 0.4, 1.0)
    bagging_fraction = trial.suggest_float("bagging_fraction", 0.4, 1.0)
    bagging_freq = trial.suggest_int("bagging_freq", 1, 7)
    min_child_samples = trial.suggest_int("min_child_samples", 5, 100)
    learning_rate = trial.suggest_float("learning_rate", 0.0001, 0.5, log=True)
    max_bin = trial.suggest_int("max_bin", 128, 512, step=32)
    n_estimators = trial.suggest_int("n_estimators", 40, 400, step=20)

    # LightGBM model
    model = lgb.LGBMRegressor(
        boosting_type=boosting_type,
        n_estimators=n_estimators,
        lambda_l1=lambda_l1,
        lambda_l2=lambda_l2,
        num_leaves=num_leaves,
        feature_fraction=feature_fraction,
        bagging_fraction=bagging_fraction,
        bagging_freq=bagging_freq,
        min_child_samples=min_child_samples,
        learning_rate=learning_rate,
        max_bin=max_bin,
        force_row_wise=True,
        random_state=42,
        verbose=-1
    )

    # K-Fold CV
    kf = KFold(n_splits=10, shuffle=True, random_state=42)
    scores = cross_val_score(model, X, y, scoring="neg_mean_squared_error", cv=kf)

    return -scores.mean()

# Setup study
sampler = optuna.samplers.TPESampler(seed=42)
pruner = optuna.pruners.HyperbandPruner(min_resource=20, max_resource=1000, reduction_factor=3)

study = optuna.create_study(
    direction='minimize',
    sampler=sampler,
    pruner=pruner,
    study_name="lgbm_kfold_wo_scaler"
)

study.optimize(objective, n_trials=200, gc_after_trial=True, n_jobs=1)

# Output
print("Best Score (MSE):", study.best_value)
print("Best Parameters:")
for key, value in study.best_params.items():
    print(f"  {key}: {value}")

"""Train Model Using Best Params"""

import lightgbm as lgb
import joblib

# Buat model dengan best_params
model = lgb.LGBMRegressor(**study.best_params, force_row_wise=True, verbose=-1)

# Fit model ke seluruh data
model.fit(X, y)

"""Variable Importance"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Ambil feature importance mentah dari model
importances = model.feature_importances_
variable = X.columns  # Kolom fitur

# Normalisasi ke 0â€“1
importance_normalized = importances / importances.sum()



# Buat DataFrame untuk visualisasi
importance_df = pd.DataFrame({
    'Variable': variable,
    'Importance': importances
})

importance_df['Importance (%)'] = 100 * importance_df['Importance'] / importance_df['Importance'].sum()
importance_df = importance_df.sort_values(by='Importance (%)', ascending=False).reset_index(drop=True)

# Tampilkan 10 fitur teratas
print("\nðŸ“Œ Top 20 Feature Importance:")
print(importance_df.head(20))

# Plot
# Plot horizontal bar chart
plt.figure(figsize=(10, 8))
sns.barplot(data=importance_df, x='Importance (%)', y='Variable', palette='viridis')

# Tambahkan label persentase pada tiap bar
for i, (value, name) in enumerate(zip(importance_df['Importance (%)'], importance_df['Variable'])):
    plt.text(value + 0.3, i, f"{value:.2f}%", va='center', fontsize=9)

# Label dan judul
plt.xlabel('Importance (%)')
plt.ylabel('')
plt.title('Variable Importance (LightGBM)')

# Simpan dan tampilkan
plt.tight_layout()
plt.savefig('/content/drive/MyDrive/PENGOLAHAN/HASIL/VARIABLE IMPORTANCE/Variable_Importance_plot.png', dpi=300)
plt.show()

"""K-Fold Cross Validation"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import KFold
import lightgbm as lgb
import numpy as np
import pandas as pd

best_params = study.best_params
kf = KFold(n_splits=10, shuffle=True, random_state=42)
results_sample = []

# Untuk menyimpan semua hasil prediksi dan observasi
y_true_kfold_all = []
y_pred_kfold_all = []

for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Tidak menggunakan scaler, langsung pakai data asli
    model = lgb.LGBMRegressor(**best_params, force_row_wise=True, verbose=-1)
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        eval_metric="mae",
        callbacks=[lgb.early_stopping(stopping_rounds=50)],
    )

    y_pred = model.predict(X_val)

    # Simpan hasil evaluasi per fold
    results_sample.append({
        'Fold': fold,
        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
        'MAE': mean_absolute_error(y_val, y_pred),
        'BIAS': np.mean(y_pred - y_val),
        'R2': r2_score(y_val, y_pred)
    })

    # Simpan semua nilai observasi dan prediksi (optional)
    y_true_kfold_all.extend(y_val)
    y_pred_kfold_all.extend(y_pred)

# Tampilkan hasil sample-based CV
df_sample = pd.DataFrame(results_sample)
print("ðŸ“Š Sample-based 10-Fold CV Results:")
print(df_sample)
print(df_sample[['RMSE', 'MAE','BIAS','R2']].agg(['mean', 'std']))

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Gunakan data hasil prediksi semua fold
y_true = np.array(y_true_kfold_all)
y_pred = np.array(y_pred_kfold_all)

# Hitung metrik evaluasi
r2 = df_sample['R2'].mean()
rmse = df_sample['RMSE'].mean()
mae = df_sample['MAE'].mean()
bias = df_sample['BIAS'].mean()
n = len(y_true)


# Mulai plot
plt.figure(figsize=(6.5, 6.5))

# Scatter density menggunakan hexbin
hb = plt.hexbin(
    y_true, y_pred,
    gridsize=100,
    cmap='jet',  # Sesuaikan dengan warna seperti contoh
    mincnt=1
)

# Garis 1:1 (referensi ideal)
plt.plot([y_true.min(), y_true.max()],
         [y_true.min(), y_true.max()],
         'k--', linewidth=1)

# Garis regresi linear (aktual vs prediksi)
coef = np.polyfit(y_true, y_pred, 1)
reg_line = np.poly1d(coef)
plt.plot(np.sort(y_true), reg_line(np.sort(y_true)),
         'k-', linewidth=1)

# Label sumbu
plt.xlabel("Measured Ozone (Âµg/mÂ³)", fontsize=11)
plt.ylabel("Predicted Ozone (Âµg/mÂ³)", fontsize=11)

# Colorbar frekuensi
cb = plt.colorbar(hb)
cb.set_label('Frequency')

# Metrik evaluasi ditampilkan di pojok kiri atas
plt.text(0.05, 0.95,
         f"N = {n}\n"
         f"$R^2$ = {r2:.4f}\n"
         f"RMSE = {rmse:.3f}\n"
         f"MAE = {mae:.3f}\n"
         f"BIAS = {bias:.3f}",
         transform=plt.gca().transAxes,
         fontsize=10,
         verticalalignment='top')

# Label plot sesuai
plt.text(0.5, 0.03, "(a) K-Fold CV", transform=plt.gca().transAxes,
         fontsize=11, ha='center')

plt.tight_layout()
plt.savefig("/content/drive/MyDrive/PENGOLAHAN/HASIL/SCATTER PLOT EVALUASI/Kfold_ScatterPlot_NE.png", dpi=300)
plt.show()

"""Site-Based Cross Validation"""

from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import lightgbm as lgb
import numpy as np
import pandas as pd

# Misal ini parameter terbaik hasil Optuna
best_params = study.best_params

# Setup GroupKFold (misalnya berdasarkan stasiun)
gkf = GroupKFold(n_splits=4)

# Untuk menyimpan hasil evaluasi tiap fold
results_group = []

# Untuk menyimpan semua hasil prediksi dan observasi (digunakan untuk scatter plot dan evaluasi global)
y_true_group_all = []
y_pred_group_all = []

for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups=groups), 1):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Inisialisasi model LightGBM
    model = lgb.LGBMRegressor(**best_params, force_row_wise=True, verbose=-1)

    # Training model
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        eval_metric="mae",
        callbacks=[lgb.early_stopping(stopping_rounds=50)]
    )

    # Prediksi
    y_pred = model.predict(X_val)

    # Simpan metrik evaluasi untuk setiap fold
    results_group.append({
        'Fold': fold,
        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
        'MAE': mean_absolute_error(y_val, y_pred),
        'BIAS': np.mean(y_pred - y_val),
        'R2': r2_score(y_val, y_pred)
    })

    # Simpan prediksi dan observasi untuk evaluasi global
    y_true_group_all.extend(y_val.tolist())
    y_pred_group_all.extend(y_pred.tolist())

# Konversi ke DataFrame
df_group = pd.DataFrame(results_group)

# Cetak hasil evaluasi per fold
print("\nðŸ“ GroupKFold (Out-of-Station) CV Results:")
print(df_group)

# Statistik ringkasan (rata-rata dan standar deviasi)
print("\nðŸ“Š Mean Â± Std of Metrics:")
print(df_group[['RMSE', 'MAE', 'BIAS', 'R2']].agg(['mean', 'std']))

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Gunakan hasil prediksi semua fold
y_true = np.array(y_true_group_all)
y_pred = np.array(y_pred_group_all)

# Hitung metrik evaluasi langsung dari seluruh data prediksi
r2 = df_group['R2'].mean()
rmse = df_group['RMSE'].mean()
mae = df_group['MAE'].mean()
bias = df_group['BIAS'].mean()
n = len(y_true)

# Plot hexbin scatter
plt.figure(figsize=(6.5, 6.5))
hb = plt.hexbin(
    y_true, y_pred,
    gridsize=100,
    cmap='jet',
    mincnt=1
)

# Garis 1:1 (perfect prediction line)
plt.plot(
    [y_true.min(), y_true.max()],
    [y_true.min(), y_true.max()],
    'k--', linewidth=1, label='1:1 Line'
)

# Garis regresi linear (fit antara y_true dan y_pred)
coef = np.polyfit(y_true, y_pred, 1)
reg_line = np.poly1d(coef)
plt.plot(
    np.sort(y_true),
    reg_line(np.sort(y_true)),
    'k-', linewidth=1, label='Regression Line'
)

# Label sumbu
plt.xlabel("Measured Ozone (Âµg/mÂ³)", fontsize=11)
plt.ylabel("Predicted Ozone (Âµg/mÂ³)", fontsize=11)

# Colorbar frekuensi
cb = plt.colorbar(hb)
cb.set_label('Frequency')

# Tampilkan metrik di dalam plot
plt.text(
    0.05, 0.95,
    f"N = {n}\n"
    f"$R^2$ = {r2:.4f}\n"
    f"RMSE = {rmse:.3f}\n"
    f"MAE = {mae:.3f}\n"
    f"BIAS = {bias:.3f}",
    transform=plt.gca().transAxes,
    fontsize=10,
    verticalalignment='top'
)

# Label subplot (jika digunakan dalam multi-panel)
plt.text(
    0.5, 0.03,
    "(b) Out of Station CV",
    transform=plt.gca().transAxes,
    fontsize=11,
    ha='center'
)

# Layout & simpan
plt.tight_layout()
plt.savefig("/content/drive/MyDrive/PENGOLAHAN/HASIL/SCATTER PLOT EVALUASI/Out_of_Station_ScatterPlot_EN.png", dpi=300)
plt.show()

"""Save Model"""

# Simpan model ke file .pkl
joblib.dump(model, '/content/drive/MyDrive/PENGOLAHAN/HASIL/MODEL LGBM/MODEL_LGBM_EN.pkl')

"""Estimasi Ozon Permukaan DKI Jakarta"""



"""# Modeling Without Easting & Northing"""

import joblib
import lightgbm as lgb
import matplotlib.pyplot as plt
import numpy as np
import optuna
import pandas as pd
import seaborn as sns
from sklearn.model_selection import KFold, GroupKFold, cross_val_score, cross_validate
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from lightgbm import LGBMRegressor
from sklearn.metrics import make_scorer
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import warnings

warnings.filterwarnings("ignore", category=FutureWarning)

#Load Dataset
ozone = pd.read_csv("/content/drive/MyDrive/PENGOLAHAN/HASIL/EDA/Outlier_Handled/Data_20222024_OutlierHandled.csv")

print (ozone)

# Define features & target
features = [col for col in ozone.columns if col not in ['StasiunO3', 'Station_ID', 'Waktu','Easting','Northing']]
target = 'StasiunO3'
X = ozone[features]
y = ozone[target]
groups = ozone['Station_ID']

"""Model Selection"""

# KFold
cv = KFold(n_splits=10, shuffle=True, random_state=42)

# Model pipelines tanpa scaler
pipelines = {
    'LinearRegression': LinearRegression(),
    'RandomForest': RandomForestRegressor(),
    'LightGBM': LGBMRegressor(force_row_wise=True)
}

# Evaluasi dengan cross_validate
scoring = {
    'rmse': 'neg_root_mean_squared_error',
    'mae': 'neg_mean_absolute_error',
    'r2': 'r2'
}

results = {}

for name, model in pipelines.items():
    scores = cross_validate(model, X, y, cv=cv, scoring=scoring, return_train_score=False)

    results[name] = {
        'RMSE': -np.mean(scores['test_rmse']),
        'MAE': -np.mean(scores['test_mae']),
        'RÂ²': np.mean(scores['test_r2'])
    }

results_df = pd.DataFrame(results).T
print(results_df)

"""parameter optimization"""

# Fungsi Hyperparameter
def objective(trial):
    # Hyperparameter space
    boosting_type = trial.suggest_categorical("boosting_type", ["dart", "gbdt"])
    lambda_l1 = trial.suggest_float("lambda_l1", 1e-8, 10.0, log=True)
    lambda_l2 = trial.suggest_float("lambda_l2", 1e-8, 10.0, log=True)
    num_leaves = trial.suggest_int("num_leaves", 2, 256)
    feature_fraction = trial.suggest_float("feature_fraction", 0.4, 1.0)
    bagging_fraction = trial.suggest_float("bagging_fraction", 0.4, 1.0)
    bagging_freq = trial.suggest_int("bagging_freq", 1, 7)
    min_child_samples = trial.suggest_int("min_child_samples", 5, 100)
    learning_rate = trial.suggest_float("learning_rate", 0.0001, 0.5, log=True)
    max_bin = trial.suggest_int("max_bin", 128, 512, step=32)
    n_estimators = trial.suggest_int("n_estimators", 40, 400, step=20)

    # LightGBM model
    model = lgb.LGBMRegressor(
        boosting_type=boosting_type,
        n_estimators=n_estimators,
        lambda_l1=lambda_l1,
        lambda_l2=lambda_l2,
        num_leaves=num_leaves,
        feature_fraction=feature_fraction,
        bagging_fraction=bagging_fraction,
        bagging_freq=bagging_freq,
        min_child_samples=min_child_samples,
        learning_rate=learning_rate,
        max_bin=max_bin,
        force_row_wise=True,
        random_state=42,
        verbose=-1
    )

    # K-Fold CV
    kf = KFold(n_splits=10, shuffle=True, random_state=42)
    scores = cross_val_score(model, X, y, scoring="neg_mean_squared_error", cv=kf)

    return -scores.mean()

# Setup study
sampler = optuna.samplers.TPESampler(seed=42)
pruner = optuna.pruners.HyperbandPruner(min_resource=20, max_resource=1000, reduction_factor=3)

study = optuna.create_study(
    direction='minimize',
    sampler=sampler,
    pruner=pruner,
    study_name="lgbm_kfold_wo_scaler"
)

study.optimize(objective, n_trials=200, gc_after_trial=True, n_jobs=1)

# Output
print("Best Score (MSE):", study.best_value)
print("Best Parameters:")
for key, value in study.best_params.items():
    print(f"  {key}: {value}")

"""**Train Model Using Best Params**"""

import lightgbm as lgb
import joblib

# Buat model dengan best_params
model = lgb.LGBMRegressor(**study.best_params, force_row_wise=True, verbose=-1)

# Fit model ke seluruh data
model.fit(X, y)

"""**Variable Importance**"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Ambil feature importance mentah dari model
importances = model.feature_importances_
variable = X.columns  # Kolom fitur

# Normalisasi ke 0â€“1
importance_normalized = importances / importances.sum()



# Buat DataFrame untuk visualisasi
importance_df = pd.DataFrame({
    'Variable': variable,
    'Importance': importances
})

importance_df['Importance (%)'] = 100 * importance_df['Importance'] / importance_df['Importance'].sum()
importance_df = importance_df.sort_values(by='Importance (%)', ascending=False).reset_index(drop=True)

# Tampilkan 10 fitur teratas
print("\nðŸ“Œ Top 20 Feature Importance:")
print(importance_df.head(20))

# Plot
# Plot horizontal bar chart
plt.figure(figsize=(10, 8))
sns.barplot(data=importance_df, x='Importance (%)', y='Variable', palette='viridis')

# Tambahkan label persentase pada tiap bar
for i, (value, name) in enumerate(zip(importance_df['Importance (%)'], importance_df['Variable'])):
    plt.text(value + 0.3, i, f"{value:.2f}%", va='center', fontsize=9)

# Label dan judul
plt.xlabel('Importance (%)')
plt.ylabel('')
plt.title('Variable Importance (LightGBM)')

# Simpan dan tampilkan
plt.tight_layout()
plt.savefig('/content/drive/MyDrive/PENGOLAHAN/HASIL/VARIABLE IMPORTANCE/Variable_Importance_plot.png', dpi=300)
plt.show()

# Simpan data
importance_df.to_csv('/content/drive/MyDrive/PENGOLAHAN/HASIL/VARIABLE IMPORTANCE/Variable_Importance_lgbm.csv', index=False)

"""**Model Evaluation Using K-fold CV**"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import KFold
import lightgbm as lgb
import numpy as np
import pandas as pd

best_params = study.best_params
kf = KFold(n_splits=10, shuffle=True, random_state=42)
results_sample = []

# Untuk menyimpan semua hasil prediksi dan observasi
y_true_kfold_all = []
y_pred_kfold_all = []

for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Tidak menggunakan scaler, langsung pakai data asli
    model = lgb.LGBMRegressor(**best_params, force_row_wise=True, verbose=-1)
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        eval_metric="mae",
        callbacks=[lgb.early_stopping(stopping_rounds=50)],
    )

    y_pred = model.predict(X_val)

    # Simpan hasil evaluasi per fold
    results_sample.append({
        'Fold': fold,
        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
        'MAE': mean_absolute_error(y_val, y_pred),
        'BIAS': np.mean(y_pred - y_val),
        'R2': r2_score(y_val, y_pred)
    })

    # Simpan semua nilai observasi dan prediksi (optional)
    y_true_kfold_all.extend(y_val)
    y_pred_kfold_all.extend(y_pred)

# Tampilkan hasil sample-based CV
df_sample = pd.DataFrame(results_sample)
print("ðŸ“Š Sample-based 10-Fold CV Results:")
print(df_sample)
print(df_sample[['RMSE', 'MAE','BIAS','R2']].agg(['mean', 'std']))

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Gunakan data hasil prediksi semua fold
y_true = np.array(y_true_kfold_all)
y_pred = np.array(y_pred_kfold_all)

# Hitung metrik evaluasi
r2 = df_sample['R2'].mean()
rmse = df_sample['RMSE'].mean()
mae = df_sample['MAE'].mean()
bias = df_sample['BIAS'].mean()
n = len(y_true)


# Mulai plot
plt.figure(figsize=(6.5, 6.5))

# Scatter density menggunakan hexbin
hb = plt.hexbin(
    y_true, y_pred,
    gridsize=100,
    cmap='jet',  # Sesuaikan dengan warna seperti contoh
    mincnt=1
)

# Garis 1:1 (referensi ideal)
plt.plot([y_true.min(), y_true.max()],
         [y_true.min(), y_true.max()],
         'k--', linewidth=1)

# Garis regresi linear (aktual vs prediksi)
coef = np.polyfit(y_true, y_pred, 1)
reg_line = np.poly1d(coef)
plt.plot(np.sort(y_true), reg_line(np.sort(y_true)),
         'k-', linewidth=1)

# Label sumbu
plt.xlabel("Measured Ozone (Âµg/mÂ³)", fontsize=11)
plt.ylabel("Predicted Ozone (Âµg/mÂ³)", fontsize=11)

# Colorbar frekuensi
cb = plt.colorbar(hb)
cb.set_label('Frequency')

# Metrik evaluasi ditampilkan di pojok kiri atas
plt.text(0.05, 0.95,
         f"N = {n}\n"
         f"$R^2$ = {r2:.4f}\n"
         f"RMSE = {rmse:.3f}\n"
         f"MAE = {mae:.3f}\n"
         f"BIAS = {bias:.3f}",
         transform=plt.gca().transAxes,
         fontsize=10,
         verticalalignment='top')

# Label plot sesuai
plt.text(0.5, 0.03, "(a) K-Fold CV", transform=plt.gca().transAxes,
         fontsize=11, ha='center')

plt.tight_layout()
plt.savefig("/content/drive/MyDrive/PENGOLAHAN/HASIL/SCATTER PLOT EVALUASI/Kfold_ScatterPlot.png", dpi=300)
plt.show()

"""**Model Evaluation Using Site-based CV**"""

from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import lightgbm as lgb
import numpy as np
import pandas as pd

# Misal ini parameter terbaik hasil Optuna
best_params = study.best_params

# Setup GroupKFold (misalnya berdasarkan stasiun)
gkf = GroupKFold(n_splits=4)

# Untuk menyimpan hasil evaluasi tiap fold
results_group = []

# Untuk menyimpan semua hasil prediksi dan observasi (digunakan untuk scatter plot dan evaluasi global)
y_true_group_all = []
y_pred_group_all = []

for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups=groups), 1):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Inisialisasi model LightGBM
    model = lgb.LGBMRegressor(**best_params, force_row_wise=True, verbose=-1)

    # Training model
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        eval_metric="mae",
        callbacks=[lgb.early_stopping(stopping_rounds=50)]
    )

    # Prediksi
    y_pred = model.predict(X_val)

    # Simpan metrik evaluasi untuk setiap fold
    results_group.append({
        'Fold': fold,
        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
        'MAE': mean_absolute_error(y_val, y_pred),
        'BIAS': np.mean(y_pred - y_val),
        'R2': r2_score(y_val, y_pred)
    })

    # Simpan prediksi dan observasi untuk evaluasi global
    y_true_group_all.extend(y_val.tolist())
    y_pred_group_all.extend(y_pred.tolist())

# Konversi ke DataFrame
df_group = pd.DataFrame(results_group)

# Cetak hasil evaluasi per fold
print("\nðŸ“ GroupKFold (Out-of-Station) CV Results:")
print(df_group)

# Statistik ringkasan (rata-rata dan standar deviasi)
print("\nðŸ“Š Mean Â± Std of Metrics:")
print(df_group[['RMSE', 'MAE', 'BIAS', 'R2']].agg(['mean', 'std']))

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Gunakan hasil prediksi semua fold
y_true = np.array(y_true_group_all)
y_pred = np.array(y_pred_group_all)

# Hitung metrik evaluasi langsung dari seluruh data prediksi
r2 = df_group['R2'].mean()
rmse = df_group['RMSE'].mean()
mae = df_group['MAE'].mean()
bias = df_group['BIAS'].mean()
n = len(y_true)

# Plot hexbin scatter
plt.figure(figsize=(6.5, 6.5))
hb = plt.hexbin(
    y_true, y_pred,
    gridsize=100,
    cmap='jet',
    mincnt=1
)

# Garis 1:1 (perfect prediction line)
plt.plot(
    [y_true.min(), y_true.max()],
    [y_true.min(), y_true.max()],
    'k--', linewidth=1, label='1:1 Line'
)

# Garis regresi linear (fit antara y_true dan y_pred)
coef = np.polyfit(y_true, y_pred, 1)
reg_line = np.poly1d(coef)
plt.plot(
    np.sort(y_true),
    reg_line(np.sort(y_true)),
    'k-', linewidth=1, label='Regression Line'
)

# Label sumbu
plt.xlabel("Measured Ozone (Âµg/mÂ³)", fontsize=11)
plt.ylabel("Predicted Ozone (Âµg/mÂ³)", fontsize=11)

# Colorbar frekuensi
cb = plt.colorbar(hb)
cb.set_label('Frequency')

# Tampilkan metrik di dalam plot
plt.text(
    0.05, 0.95,
    f"N = {n}\n"
    f"$R^2$ = {r2:.4f}\n"
    f"RMSE = {rmse:.3f}\n"
    f"MAE = {mae:.3f}\n"
    f"BIAS = {bias:.3f}",
    transform=plt.gca().transAxes,
    fontsize=10,
    verticalalignment='top'
)

# Label subplot (jika digunakan dalam multi-panel)
plt.text(
    0.5, 0.03,
    "(b) Out of Station CV",
    transform=plt.gca().transAxes,
    fontsize=11,
    ha='center'
)

# Layout & simpan
plt.tight_layout()
plt.savefig("/content/drive/MyDrive/PENGOLAHAN/HASIL/SCATTER PLOT EVALUASI/Out_of_Station_ScatterPlot.png", dpi=300)
plt.show()

"""**Menyimpan Model**"""

# Simpan model ke file .pkl
joblib.dump(model, '/content/drive/MyDrive/PENGOLAHAN/HASIL/MODEL LGBM/MODEL_LGBM_GLO.pkl')

"""# Train Model Tanpa Variable CO"""

# Define features & target
features = [col for col in ozone.columns if col not in ['StasiunO3', 'Station_ID', 'Waktu','Easting' ,'Northing','CO']]
target = 'StasiunO3'
X = ozone[features]
y = ozone[target]
groups = ozone['Station_ID']

from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import lightgbm as lgb
import numpy as np
import pandas as pd

best_params = study.best_params
kf = KFold(n_splits=10, shuffle=True, random_state=42)
results_sample = []

# Untuk menyimpan semua hasil prediksi dan observasi
y_true_kfold_all = []
y_pred_kfold_all = []

for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Tidak menggunakan scaler, langsung pakai data asli
    model = lgb.LGBMRegressor(**best_params, force_row_wise=True, verbose=-1)
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        eval_metric="mae",
        callbacks=[lgb.early_stopping(stopping_rounds=50)],
    )

    y_pred = model.predict(X_val)

    # Simpan hasil evaluasi per fold
    results_sample.append({
        'Fold': fold,
        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
        'MAE': mean_absolute_error(y_val, y_pred),
        'BIAS': np.mean(y_pred - y_val),
        'R2': r2_score(y_val, y_pred)
    })

    # Simpan semua nilai observasi dan prediksi (optional)
    y_true_kfold_all.extend(y_val)
    y_pred_kfold_all.extend(y_pred)

# Tampilkan hasil sample-based CV
df_sample = pd.DataFrame(results_sample)
print("ðŸ“Š Sample-based 10-Fold CV Results:")
print(df_sample)
print(df_sample[['RMSE', 'MAE','BIAS','R2']].agg(['mean', 'std']))

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import GroupKFold
import lightgbm as lgb
import numpy as np
import pandas as pd

gkf = GroupKFold(n_splits=4)  # misal 4 fold sesuai jumlah kelompok/stasiun
results_group = []

# Untuk menyimpan semua hasil prediksi dan observasi
y_true_group_all = []
y_pred_group_all = []

for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups=groups), 1):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Tidak pakai scaler, langsung pakai data asli
    model = lgb.LGBMRegressor(**best_params,force_row_wise=True, verbose=-1)
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        eval_metric="mae",
        callbacks=[lgb.early_stopping(stopping_rounds=50)],
    )

    y_pred = model.predict(X_val)

    # Simpan hasil evaluasi per fold
    results_group.append({
        'Fold': fold,
        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
        'MAE': mean_absolute_error(y_val, y_pred),
        'BIAS': np.mean(y_pred - y_val),
        'R2': r2_score(y_val, y_pred)
    })

    # Simpan semua nilai observasi dan prediksi (optional)
    y_true_group_all.extend(y_val)
    y_pred_group_all.extend(y_pred)

# Tampilkan hasil GroupKFold CV
df_group = pd.DataFrame(results_group)
print("\nðŸ“ GroupKFold (Out-of-Station) CV Results:")
print(df_group)
print(df_group[['RMSE', 'MAE', 'BIAS', 'R2']].agg(['mean', 'std']))

"""# Train Model Tanpa Bulan"""

# Define features & target
features = [col for col in ozone.columns if col not in ['StasiunO3', 'Station_ID', 'Waktu','Easting','Northing','Bulan']]
target = 'StasiunO3'
X = ozone[features]
y = ozone[target]
groups = ozone['Station_ID']

from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import lightgbm as lgb
import numpy as np
import pandas as pd

best_params = study.best_params
kf = KFold(n_splits=10, shuffle=True, random_state=42)
results_sample = []

# Untuk menyimpan semua hasil prediksi dan observasi
y_true_kfold_all = []
y_pred_kfold_all = []

for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Tidak menggunakan scaler, langsung pakai data asli
    model = lgb.LGBMRegressor(**best_params, force_row_wise=True, verbose=-1)
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        eval_metric="mae",
        callbacks=[lgb.early_stopping(stopping_rounds=50)],
    )

    y_pred = model.predict(X_val)

    # Simpan hasil evaluasi per fold
    results_sample.append({
        'Fold': fold,
        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
        'MAE': mean_absolute_error(y_val, y_pred),
        'BIAS': np.mean(y_pred - y_val),
        'R2': r2_score(y_val, y_pred)
    })

    # Simpan semua nilai observasi dan prediksi (optional)
    y_true_kfold_all.extend(y_val)
    y_pred_kfold_all.extend(y_pred)

# Tampilkan hasil sample-based CV
df_sample = pd.DataFrame(results_sample)
print("ðŸ“Š Sample-based 10-Fold CV Results:")
print(df_sample)
print(df_sample[['RMSE', 'MAE','BIAS','R2']].agg(['mean', 'std']))

from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import lightgbm as lgb
import numpy as np
import pandas as pd

gkf = GroupKFold(n_splits=4)  # misal 4 fold sesuai jumlah kelompok/stasiun
results_group = []

# Untuk menyimpan semua hasil prediksi dan observasi
y_true_group_all = []
y_pred_group_all = []

for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups=groups), 1):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Tidak pakai scaler, langsung pakai data asli
    model = lgb.LGBMRegressor(**best_params,force_row_wise=True, verbose=-1)
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        eval_metric="mae",
        callbacks=[lgb.early_stopping(stopping_rounds=50)],
    )

    y_pred = model.predict(X_val)

    # Simpan hasil evaluasi per fold
    results_group.append({
        'Fold': fold,
        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
        'MAE': mean_absolute_error(y_val, y_pred),
        'BIAS': np.mean(y_pred - y_val),
        'R2': r2_score(y_val, y_pred)
    })

    # Simpan semua nilai observasi dan prediksi (optional)
    y_true_group_all.extend(y_val)
    y_pred_group_all.extend(y_pred)

# Tampilkan hasil GroupKFold CV
df_group = pd.DataFrame(results_group)
print("\nðŸ“ GroupKFold (Out-of-Station) CV Results:")
print(df_group)
print(df_group[['RMSE', 'MAE', 'BIAS', 'R2']].agg(['mean', 'std']))

"""# Tran Model Tanpa CO dan Bulan"""

# Define features & target
features = [col for col in ozone.columns if col not in ['StasiunO3', 'Station_ID', 'Waktu','Northing','Easting','CO','Bulan']]
target = 'StasiunO3'
X = ozone[features]
y = ozone[target]
groups = ozone['Station_ID']

from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import lightgbm as lgb
import numpy as np
import pandas as pd

best_params = study.best_params
kf = KFold(n_splits=10, shuffle=True, random_state=42)
results_sample = []

# Untuk menyimpan semua hasil prediksi dan observasi
y_true_kfold_all = []
y_pred_kfold_all = []

for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Tidak menggunakan scaler, langsung pakai data asli
    model = lgb.LGBMRegressor(**best_params, force_row_wise=True, verbose=-1)
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        eval_metric="mae",
        callbacks=[lgb.early_stopping(stopping_rounds=50)],
    )

    y_pred = model.predict(X_val)

    # Simpan hasil evaluasi per fold
    results_sample.append({
        'Fold': fold,
        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
        'MAE': mean_absolute_error(y_val, y_pred),
        'BIAS': np.mean(y_pred - y_val),
        'R2': r2_score(y_val, y_pred)
    })

    # Simpan semua nilai observasi dan prediksi (optional)
    y_true_kfold_all.extend(y_val)
    y_pred_kfold_all.extend(y_pred)

# Tampilkan hasil sample-based CV
df_sample = pd.DataFrame(results_sample)
print("ðŸ“Š Sample-based 10-Fold CV Results:")
print(df_sample)
print(df_sample[['RMSE', 'MAE','BIAS','R2']].agg(['mean', 'std']))

from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import lightgbm as lgb
import numpy as np
import pandas as pd

gkf = GroupKFold(n_splits=4)  # misal 4 fold sesuai jumlah kelompok/stasiun
results_group = []

# Untuk menyimpan semua hasil prediksi dan observasi
y_true_group_all = []
y_pred_group_all = []

for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups=groups), 1):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Tidak pakai scaler, langsung pakai data asli
    model = lgb.LGBMRegressor(**best_params,force_row_wise=True, verbose=-1)
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        eval_metric="mae",
        callbacks=[lgb.early_stopping(stopping_rounds=50)],
    )

    y_pred = model.predict(X_val)

    # Simpan hasil evaluasi per fold
    results_group.append({
        'Fold': fold,
        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
        'MAE': mean_absolute_error(y_val, y_pred),
        'BIAS': np.mean(y_pred - y_val),
        'R2': r2_score(y_val, y_pred)
    })

    # Simpan semua nilai observasi dan prediksi (optional)
    y_true_group_all.extend(y_val)
    y_pred_group_all.extend(y_pred)

# Tampilkan hasil GroupKFold CV
df_group = pd.DataFrame(results_group)
print("\nðŸ“ GroupKFold (Out-of-Station) CV Results:")
print(df_group)
print(df_group[['RMSE', 'MAE', 'BIAS', 'R2']].agg(['mean', 'std']))

"""# Estimasi Ozon Jakarta Tanpa Easting dan Northing"""

import joblib
import pandas as pd
import numpy as np
import os
import glob
import rasterio
from rasterio.transform import from_origin

# ===== Step 1: Load model=====
model = joblib.load('/content/drive/MyDrive/PENGOLAHAN/HASIL/MODEL LGBM/MODEL_LGBM_GLO.pkl')

# Tampilkan nama-nama fitur yang digunakan saat pelatihan
print(model.feature_name_)

# ===== Step 2: Load data prediktor Jakarta =====
data_prediktor = '/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/OUTER/Missing Value Filled'
csv_files = sorted(glob.glob(os.path.join(data_prediktor, 'Data_*.csv')))
df_list = [pd.read_csv(file) for file in csv_files]
df_area_full = pd.concat(df_list, ignore_index=True)

df_area_full.columns = df_area_full.columns.str.replace('_JAKARTA', '', regex=False)

df_area_full['Waktu'] = pd.to_datetime(df_area_full['Waktu'], format='%Y-%m', errors='coerce')
df_area_full['Bulan'] = df_area_full['Waktu'].dt.month
df_area_full['Tahun'] = df_area_full['Waktu'].dt.year

df_area_full['latitude'] = df_area_full['Lat']
df_area_full['longitude'] = df_area_full['Lon']


# ===== Fitur yang digunakan untuk prediksi =====
features = ['NO2', 'HCHO', 'SO2', 'TropomiO3', 'U10', 'V10', 'SP', 'TP', 'E', 'T2M', 'SSR', 'EVI', 'LST', 'NTL', 'Bulan', 'Tahun']

df_area_full = df_area_full.dropna(subset=features)

# ===== STEP 3: Prediksi =====
X_pred = df_area_full[features]
df_area_full['Estimasi_O3'] = model.predict(X_pred)

# ===== STEP 4: Simpan CSV & TIFF =====
output_dir_tiff = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_OZON_TIFF'
output_dir_csv = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA//ESTIMASI_OZON_CSV'
os.makedirs(output_dir_tiff, exist_ok=True)
os.makedirs(output_dir_csv, exist_ok=True)

grouped = df_area_full.groupby(df_area_full['Waktu'])

for waktu, group in grouped:
    tahun = waktu.year
    bulan = waktu.month

    # Simpan CSV
    csv_path = os.path.join(output_dir_csv, f'Estimasi_O3_{tahun}_{bulan:02d}.csv')
    group[['Lat', 'Lon', 'Waktu', 'Estimasi_O3']].to_csv(csv_path, index=False)

    # Simpan TIFF
    lon = sorted(group['Lon'].unique())
    lat = sorted(group['Lat'].unique())[::-1]

    nrows = len(lat)
    ncols = len(lon)

    pred_grid = np.full((nrows, ncols), np.nan)
    for _, row in group.iterrows():
        row_idx = lat.index(row['Lat'])
        col_idx = lon.index(row['Lon'])
        pred_grid[row_idx, col_idx] = row['Estimasi_O3']

    res_x = round(abs(lon[1] - lon[0]), 5)
    res_y = round(abs(lat[1] - lat[0]), 5)
    transform = from_origin(min(lon), max(lat), res_x, res_y)

    tiff_path = os.path.join(output_dir_tiff, f'Estimasi_O3_{tahun}_{bulan:02d}.tif')
    with rasterio.open(
        tiff_path,
        'w',
        driver='GTiff',
        height=nrows,
        width=ncols,
        count=1,
        dtype='float32',
        crs='EPSG:32748',
        transform=transform,
        compress='lzw'
    ) as dst:
        dst.write(pred_grid.astype('float32'), 1)

    print(f"âœ… CSV disimpan:  {csv_path}")
    print(f"âœ… TIFF disimpan: {tiff_path}")

"""Visualisasi Per Bulan"""

# Direktori folder yang berisi raster
folder_path = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_OZON_TIFF' # Ganti dengan path folder kamu

# Cari semua file .tif di folder
tif_files = sorted(glob.glob(os.path.join(folder_path, '*.tif')))

if not tif_files:
    print(f"Tidak ada file .tif ditemukan di {folder_path}")
else:
    print(f"Jumlah file .tif ditemukan: {len(tif_files)}")

    # Tentukan nilai min dan max global dari semua raster
    global_min = float('inf')
    global_max = float('-inf')

    print("Mencari nilai min dan max global...")
    for tif_file in tif_files:
        try:
            with rasterio.open(tif_file) as src:
                img = src.read(1)
                # Filter out NaN and infinite values before finding min/max
                valid_data = img[np.isfinite(img)]
                if valid_data.size > 0:
                    local_min = np.min(valid_data)
                    local_max = np.max(valid_data)
                    global_min = min(global_min, local_min)
                    global_max = max(global_max, local_max)
                else:
                    print(f"Peringatan: File {tif_file} hanya berisi NaN atau nilai tak terhingga.")
        except Exception as e:
            print(f"Error saat membaca {tif_file}: {e}")

    # Jika tidak ada data valid ditemukan di semua raster
    if global_min == float('inf') or global_max == float('-inf'):
         print("Tidak ada data valid ditemukan untuk menentukan rentang legenda.")
    else:
        print(f"Nilai minimum global: {global_min:.2f}")
        print(f"Nilai maksimum global: {global_max:.2f}")

        # Tentukan layout plot (misalnya 4 kolom)
        cols = 4
        rows = (len(tif_files) + cols - 1) // cols

        fig, axs = plt.subplots(rows, cols, figsize=(18, 5 * rows))
        axs = axs.flatten()

        # Loop dan tampilkan setiap raster dengan rentang legenda yang sama
        print("\nMemulai visualisasi...")
        for idx, tif_file in enumerate(tif_files):
            try:
                with rasterio.open(tif_file) as src:
                    img = src.read(1)
                    # Handle potential NaN values if needed (imshow handles NaN by default)

                    im = axs[idx].imshow(img, cmap='jet', vmin=global_min, vmax=global_max) # Gunakan vmin & vmax global
                    axs[idx].set_title(os.path.basename(tif_file).replace('.tif', ''), fontsize=10)
                    axs[idx].axis('off')

            except Exception as e:
                print(f"Error saat memplot {tif_file}: {e}")
                axs[idx].set_title(f"Error: {os.path.basename(tif_file)}", fontsize=10)
                axs[idx].axis('off')


        # Sembunyikan subplot kosong jika ada
        for ax in axs[len(tif_files):]:
            ax.axis('off')

        # Tambahkan colorbar umum untuk semua subplot
        fig.colorbar(im, ax=axs.tolist(), orientation='vertical', fraction=0.02, pad=0.02, label='Estimasi Ozon Permukaan')

        plt.tight_layout(rect=[0, 0, 0.95, 1]) # Adjust layout to make space for the common colorbar
        plt.suptitle('Visualisasi Estimasi Ozon Permukaan (Legend Sama)', fontsize=16, y=1.02)
        plt.show()

"""**2022**"""

import os
import glob
import numpy as np
import rasterio
import matplotlib.pyplot as plt

# Direktori folder yang berisi raster
folder_path = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_OZON_TIFF' # Ganti dengan path folder kamu

# Cari semua file .tif yang mengandung '2022' di nama file
tif_files = sorted([f for f in glob.glob(os.path.join(folder_path, '*.tif')) if '2022' in os.path.basename(f)])

if not tif_files:
    print(f"Tidak ada file .tif tahun 2022 ditemukan di {folder_path}")
else:
    print(f"Jumlah file .tif tahun 2022 ditemukan: {len(tif_files)}")

    # Tentukan nilai min dan max global dari semua raster
    global_min = float('inf')
    global_max = float('-inf')

    print("Mencari nilai min dan max global...")
    for tif_file in tif_files:
        try:
            with rasterio.open(tif_file) as src:
                img = src.read(1)
                valid_data = img[np.isfinite(img)]
                if valid_data.size > 0:
                    local_min = np.min(valid_data)
                    local_max = np.max(valid_data)
                    global_min = min(global_min, local_min)
                    global_max = max(global_max, local_max)
                else:
                    print(f"Peringatan: File {tif_file} hanya berisi NaN atau nilai tak terhingga.")
        except Exception as e:
            print(f"Error saat membaca {tif_file}: {e}")

    if global_min == float('inf') or global_max == float('-inf'):
         print("Tidak ada data valid ditemukan untuk menentukan rentang legenda.")
    else:
        print(f"Nilai minimum global: {global_min:.2f}")
        print(f"Nilai maksimum global: {global_max:.2f}")

        # Tentukan layout plot (misalnya 4 kolom)
        cols = 4
        rows = (len(tif_files) + cols - 1) // cols

        fig, axs = plt.subplots(rows, cols, figsize=(18, 5 * rows))
        axs = axs.flatten()

        print("\nMemulai visualisasi...")
        for idx, tif_file in enumerate(tif_files):
            try:
                with rasterio.open(tif_file) as src:
                    img = src.read(1)
                    im = axs[idx].imshow(img, cmap='jet', vmin=global_min, vmax=global_max)
                    axs[idx].set_title(os.path.basename(tif_file).replace('.tif', ''), fontsize=10)
                    axs[idx].axis('off')
            except Exception as e:
                print(f"Error saat memplot {tif_file}: {e}")
                axs[idx].set_title(f"Error: {os.path.basename(tif_file)}", fontsize=10)
                axs[idx].axis('off')

        for ax in axs[len(tif_files):]:
            ax.axis('off')

        fig.colorbar(im, ax=axs.tolist(), orientation='vertical', fraction=0.02, pad=0.02, label='Estimasi Ozon Permukaan')

        plt.tight_layout(rect=[0, 0, 0.95, 1])
        plt.suptitle('Visualisasi Estimasi Ozon Permukaan Tahun 2022 (Legend Sama)', fontsize=16, y=1.02)
        plt.show()

"""2023"""

import os
import glob
import numpy as np
import rasterio
import matplotlib.pyplot as plt

# Direktori folder yang berisi raster
folder_path = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_OZON_TIFF' # Ganti dengan path folder kamu

# Cari semua file .tif yang mengandung '2023' di nama file
tif_files = sorted([f for f in glob.glob(os.path.join(folder_path, '*.tif')) if '2023' in os.path.basename(f)])

if not tif_files:
    print(f"Tidak ada file .tif tahun 2023 ditemukan di {folder_path}")
else:
    print(f"Jumlah file .tif tahun 2023 ditemukan: {len(tif_files)}")

    # Tentukan nilai min dan max global dari semua raster
    global_min = float('inf')
    global_max = float('-inf')

    print("Mencari nilai min dan max global...")
    for tif_file in tif_files:
        try:
            with rasterio.open(tif_file) as src:
                img = src.read(1)
                valid_data = img[np.isfinite(img)]
                if valid_data.size > 0:
                    local_min = np.min(valid_data)
                    local_max = np.max(valid_data)
                    global_min = min(global_min, local_min)
                    global_max = max(global_max, local_max)
                else:
                    print(f"Peringatan: File {tif_file} hanya berisi NaN atau nilai tak terhingga.")
        except Exception as e:
            print(f"Error saat membaca {tif_file}: {e}")

    if global_min == float('inf') or global_max == float('-inf'):
         print("Tidak ada data valid ditemukan untuk menentukan rentang legenda.")
    else:
        print(f"Nilai minimum global: {global_min:.2f}")
        print(f"Nilai maksimum global: {global_max:.2f}")

        # Tentukan layout plot (misalnya 4 kolom)
        cols = 4
        rows = (len(tif_files) + cols - 1) // cols

        fig, axs = plt.subplots(rows, cols, figsize=(18, 5 * rows))
        axs = axs.flatten()

        print("\nMemulai visualisasi...")
        for idx, tif_file in enumerate(tif_files):
            try:
                with rasterio.open(tif_file) as src:
                    img = src.read(1)
                    im = axs[idx].imshow(img, cmap='jet', vmin=global_min, vmax=global_max)
                    axs[idx].set_title(os.path.basename(tif_file).replace('.tif', ''), fontsize=10)
                    axs[idx].axis('off')
            except Exception as e:
                print(f"Error saat memplot {tif_file}: {e}")
                axs[idx].set_title(f"Error: {os.path.basename(tif_file)}", fontsize=10)
                axs[idx].axis('off')

        for ax in axs[len(tif_files):]:
            ax.axis('off')

        fig.colorbar(im, ax=axs.tolist(), orientation='vertical', fraction=0.02, pad=0.02, label='Estimasi Ozon Permukaan')

        plt.tight_layout(rect=[0, 0, 0.95, 1])
        plt.suptitle('Visualisasi Estimasi Ozon Permukaan Tahun 2023 (Legend Sama)', fontsize=16, y=1.02)
        plt.show()

"""2024"""

import os
import glob
import numpy as np
import rasterio
import matplotlib.pyplot as plt

# Direktori folder yang berisi raster
folder_path = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_OZON_TIFF' # Ganti dengan path folder kamu

# Cari semua file .tif yang mengandung '2023' di nama file
tif_files = sorted([f for f in glob.glob(os.path.join(folder_path, '*.tif')) if '2024' in os.path.basename(f)])

if not tif_files:
    print(f"Tidak ada file .tif tahun 2024 ditemukan di {folder_path}")
else:
    print(f"Jumlah file .tif tahun 2024 ditemukan: {len(tif_files)}")

    # Tentukan nilai min dan max global dari semua raster
    global_min = float('inf')
    global_max = float('-inf')

    print("Mencari nilai min dan max global...")
    for tif_file in tif_files:
        try:
            with rasterio.open(tif_file) as src:
                img = src.read(1)
                valid_data = img[np.isfinite(img)]
                if valid_data.size > 0:
                    local_min = np.min(valid_data)
                    local_max = np.max(valid_data)
                    global_min = min(global_min, local_min)
                    global_max = max(global_max, local_max)
                else:
                    print(f"Peringatan: File {tif_file} hanya berisi NaN atau nilai tak terhingga.")
        except Exception as e:
            print(f"Error saat membaca {tif_file}: {e}")

    if global_min == float('inf') or global_max == float('-inf'):
         print("Tidak ada data valid ditemukan untuk menentukan rentang legenda.")
    else:
        print(f"Nilai minimum global: {global_min:.2f}")
        print(f"Nilai maksimum global: {global_max:.2f}")

        # Tentukan layout plot (misalnya 4 kolom)
        cols = 4
        rows = (len(tif_files) + cols - 1) // cols

        fig, axs = plt.subplots(rows, cols, figsize=(18, 5 * rows))
        axs = axs.flatten()

        print("\nMemulai visualisasi...")
        for idx, tif_file in enumerate(tif_files):
            try:
                with rasterio.open(tif_file) as src:
                    img = src.read(1)
                    im = axs[idx].imshow(img, cmap='jet', vmin=global_min, vmax=global_max)
                    axs[idx].set_title(os.path.basename(tif_file).replace('.tif', ''), fontsize=10)
                    axs[idx].axis('off')
            except Exception as e:
                print(f"Error saat memplot {tif_file}: {e}")
                axs[idx].set_title(f"Error: {os.path.basename(tif_file)}", fontsize=10)
                axs[idx].axis('off')

        for ax in axs[len(tif_files):]:
            ax.axis('off')

        fig.colorbar(im, ax=axs.tolist(), orientation='vertical', fraction=0.02, pad=0.02, label='Estimasi Ozon Permukaan')

        plt.tight_layout(rect=[0, 0, 0.95, 1])
        plt.suptitle('Visualisasi Estimasi Ozon Permukaan Tahun 2024', fontsize=16, y=1.02)
        plt.show()

"""  Visualisasi Per Tahun"""

import os
import glob
import numpy as np
import rasterio
import matplotlib.pyplot as plt
from collections import defaultdict

# Folder raster
folder_path = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_OZON_TIFF'
tif_files = sorted(glob.glob(os.path.join(folder_path, '*.tif')))

if not tif_files:
    print("Tidak ada file ditemukan.")
    exit()

# Kelompokkan berdasarkan tahun
raster_by_year = defaultdict(list)
for tif_file in tif_files:
    filename = os.path.basename(tif_file)
    parts = filename.replace('.tif', '').split('_')
    for part in parts:
        if part.isdigit() and len(part) == 4:
            raster_by_year[part].append(tif_file)
            break

# Hitung rata-rata raster per tahun
mean_rasters = {}  # Dict {year: mean_raster_array}
yearly_avg_values = {}  # Dict {year: mean value of valid pixels}
global_min, global_max = float('inf'), float('-inf')

for year, files in sorted(raster_by_year.items()):
    raster_stack = []
    for tif_file in files:
        with rasterio.open(tif_file) as src:
            img = src.read(1).astype('float32')
            img[~np.isfinite(img)] = np.nan
            raster_stack.append(img)

    # Rata-rata citra per tahun (setiap piksel)
    stack_array = np.stack(raster_stack)
    mean_array = np.nanmean(stack_array, axis=0)
    mean_rasters[year] = mean_array

    # Rata-rata nilai seluruh piksel valid (satu angka per tahun)
    valid_pixels = mean_array[np.isfinite(mean_array)]
    yearly_mean = np.nan if valid_pixels.size == 0 else np.nanmean(valid_pixels)
    yearly_avg_values[year] = yearly_mean

    # Update rentang legenda global
    if valid_pixels.size > 0:
        global_min = min(global_min, np.min(valid_pixels))
        global_max = max(global_max, np.max(valid_pixels))

print(f"Global min: {global_min:.2f}, max: {global_max:.2f}")

# Visualisasikan rata-rata per tahun
years = sorted(mean_rasters.keys())
cols = 4
rows = (len(years) + cols - 1) // cols
fig, axs = plt.subplots(rows, cols, figsize=(18, 5 * rows))
axs = axs.flatten()

for idx, year in enumerate(years):
    img = mean_rasters[year]
    im = axs[idx].imshow(img, cmap='jet', vmin=global_min, vmax=global_max)
    mean_val = yearly_avg_values[year]
    axs[idx].set_title(f"{year}\nMean: {mean_val:.2f} Âµg/mÂ³", fontsize=10)
    axs[idx].axis('off')

# Kosongkan subplot sisa
for ax in axs[len(years):]:
    ax.axis('off')

# Tambahkan colorbar umum untuk semua subplot
fig.colorbar(im, ax=axs.tolist(), orientation='vertical', fraction=0.02, pad=0.02, label='Estimasi Ozon Permukaan (Âµg/mÂ³)')

# Tambahkan judul utama dengan jarak vertikal yang lebih tinggi
plt.suptitle('Rata-rata Estimasi Ozon Permukaan per Tahun', fontsize=18, y=1.05)

# Atur ulang tata letak agar tidak tabrakan
plt.tight_layout(rect=[0, 0, 1, 0.96])

plt.show()

# Folder output untuk menyimpan raster rerata
output_folder = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/RATA_RATA_TAHUNAN'
os.makedirs(output_folder, exist_ok=True)

for year, mean_array in mean_rasters.items():
    ref_file = raster_by_year[year][0]  # Gunakan file pertama sebagai referensi metadata
    with rasterio.open(ref_file) as src:
        meta = src.meta.copy()
        meta.update({
            'dtype': 'float32',
            'count': 1,
            'compress': 'lzw'
        })

    output_path = os.path.join(output_folder, f'ozon_mean_{year}.tif')
    with rasterio.open(output_path, 'w', **meta) as dst:
        dst.write(mean_array.astype('float32'), 1)

    print(f"Citra rerata tahunan untuk {year} disimpan di: {output_path}")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import glob
import os
import numpy as np
import matplotlib.patches as mpatches
import matplotlib.lines as mlines
from matplotlib.legend_handler import HandlerTuple # Import HandlerTuple

# === 1. Baca Semua File CSV dalam Folder ===
folder_path = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_OZON_CSV'
all_files = glob.glob(os.path.join(folder_path, "*.csv"))

if len(all_files) == 0:
    raise FileNotFoundError("Tidak ada file CSV ditemukan di folder tersebut!")

# Gabungkan semua file
df_list = []
for file in all_files:
    df = pd.read_csv(file)
    if not {'Waktu', 'Estimasi_O3'}.issubset(df.columns):
        raise ValueError(f"File {file} tidak mengandung kolom 'Waktu' atau 'Estimasi_O3'")
    df['Waktu'] = pd.to_datetime(df['Waktu'], errors='coerce')
    df = df.dropna(subset=['Waktu'])
    df['Bulan'] = df['Waktu'].dt.month
    df['Tahun'] = df['Waktu'].dt.year
    df_list.append(df)

df_all = pd.concat(df_list, ignore_index=True)

# === 2. Ubah Bulan Jadi Nama Bulan ===
bulan_map = {
    1: 'Januari', 2: 'Februari', 3: 'Maret', 4: 'April',
    5: 'Mei', 6: 'Juni', 7: 'Juli', 8: 'Agustus',
    9: 'September', 10: 'Oktober', 11: 'November', 12: 'Desember'
}
df_all['Bulan'] = df_all['Bulan'].map(bulan_map)

# === 3. Hitung Rata-rata Bulanan per Tahun ===
df_grouped = df_all.groupby(['Tahun', 'Bulan'], as_index=False)['Estimasi_O3'].mean()

# === 4. Urutkan Bulan ===
month_order = ['Januari', 'Februari', 'Maret', 'April', 'Mei', 'Juni',
               'Juli', 'Agustus', 'September', 'Oktober', 'November', 'Desember']
df_grouped['Bulan'] = pd.Categorical(df_grouped['Bulan'], categories=month_order, ordered=True)
df_grouped = df_grouped.sort_values(['Tahun', 'Bulan'])

# Buat pivot table untuk plot bar dan line
pivot_df = df_grouped.pivot(index='Bulan', columns='Tahun', values='Estimasi_O3').loc[month_order]


# === 6. Plot Bar dan Line secara bersamaan menggunakan matplotlib ===
fig, ax = plt.subplots(figsize=(12, 6))

x = np.arange(len(month_order))  # Posisi bulan
width = 0.15  # Lebar bar
colors = plt.cm.tab10.colors  # Palet warna

bars = []
lines = []

for i, year in enumerate(pivot_df.columns):
    bar = ax.bar(x + (i - 1) * width, pivot_df[year], width, color=colors[i % len(colors)])
    line, = ax.plot(x, pivot_df[year], marker='o', color=colors[i % len(colors)])
    bars.append(bar)
    lines.append(line)

ax.set_xticks(x)
ax.set_xticklabels(month_order, rotation=45)
ax.set_xlabel('Bulan', fontweight='bold')
ax.set_ylabel('Konsentrasi Bulanan (Âµg/mÂ³)', fontweight='bold')
ax.set_title("Tren Temporal Konsentrasi Ozon Permukaan", loc='center', fontsize=20, fontweight='bold')
ax.grid(False)

# Buat pasangan patch dan line sebagai proxy legend handles
proxy_handles = []
for i, year in enumerate(pivot_df.columns):
    patch = mpatches.Patch(color=colors[i % len(colors)])
    line = mlines.Line2D([], [], color=colors[i % len(colors)], marker='o', linestyle='-')
    proxy_handles.append((patch, line))  # tuple of handles

# Buat legend, gunakan HandlerTuple supaya tuple (patch,line) jadi satu simbol di legend
ax.legend(proxy_handles, [str(year) for year in pivot_df.columns], handler_map={tuple: HandlerTuple(ndivide=None)},  loc='best')

plt.tight_layout()
plt.show()

"""Tren Temporal"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import glob

# 1. Path ke folder berisi file prediksi per bulan
folder_path = "/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_OZON_CSV"  # ganti sesuai lokasi
all_files = glob.glob(os.path.join(folder_path, "Estimasi_O3_*.csv"))

# 2. Gabungkan semua file prediksi
list_df = []
for file in all_files:
    df_temp = pd.read_csv(file)
    list_df.append(df_temp)

df_pred = pd.concat(list_df, ignore_index=True)

# 3. Ubah kolom waktu ke datetime
df_pred['Waktu'] = pd.to_datetime(df_pred['Waktu'])

# 4. Load data aktual
df_aktual = pd.read_csv("/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/Ekstraksi Stasiun/Data_TrainTest_20222024.csv")
df_aktual['Waktu'] = pd.to_datetime(df_aktual['Waktu'])

# 5. Hitung rata-rata per bulan
pred_monthly = df_pred.groupby(df_pred['Waktu'].dt.to_period('M')).mean(numeric_only=True)
obs_monthly = df_aktual.groupby(df_aktual['Waktu'].dt.to_period('M')).mean(numeric_only=True)

# 6. Gabungkan berdasarkan Tahun dan Bulan
pred_monthly.index = pred_monthly.index.to_timestamp()
obs_monthly.index = obs_monthly.index.to_timestamp()

# 7. Buat plot
plt.figure(figsize=(14, 6))

# Tambah shading background tiap tahun
plt.axvspan(pd.to_datetime('2022-01-01'), pd.to_datetime('2022-12-31'), facecolor='#fff3e0', alpha=0.6)  # Krem terang
plt.axvspan(pd.to_datetime('2023-01-01'), pd.to_datetime('2023-12-31'), facecolor='#e3f2fd', alpha=0.6)  # Biru terang
plt.axvspan(pd.to_datetime('2024-01-01'), pd.to_datetime('2024-12-31'), facecolor='#f3e5f5', alpha=0.6)  # Ungu terang


# Plot Predicted Ozone
plt.plot(pred_monthly.index, pred_monthly['Estimasi_O3'], label='Predicted_Ozone',
         color='#f4a300', marker='s', linestyle='-', linewidth=2, markersize=5)

# Plot Measured Ozone
plt.plot(obs_monthly.index, obs_monthly['StasiunO3'], label='Measured_Ozone',
         color='#32cd32', marker='o', linestyle='-', linewidth=2, markersize=5)

# Label Tahun di tengah
for year in range(2022, 2025):
    plt.text(pd.to_datetime(f'{year}-06-15'), 150, str(year),
             fontsize=20, fontweight='bold', ha='center')

# Styling
plt.ylabel("Monthly Concentration (Âµg/mÂ³)", fontsize=12)
plt.xlabel("Study Period", fontsize=12)
plt.xticks(pd.date_range('2022-01', '2024-12', freq='3M'),
           labels=['Jan', 'Apr', 'Jul', 'Oct']*3, rotation=45)
plt.ylim(0, 160)
plt.grid(True, linestyle='--', alpha=0.5)

# Legend
plt.legend(loc='upper right', fontsize=10, frameon=False)

# Tampilkan
plt.tight_layout()
plt.show()

# ðŸ’¾ Simpan grafik sebagai PNG
plt.tight_layout()
plt.savefig('/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/grafik_perbandingan_ozon_2022_2024.png', dpi=300)
plt.show()

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Gabungkan data prediksi dan observasi berdasarkan waktu (inner join agar hanya data yang saling cocok)
df_eval = pd.merge(pred_monthly[['Estimasi_O3']], obs_monthly[['StasiunO3']],
                   left_index=True, right_index=True, how='inner')

# Hitung error metrics
rmse = np.sqrt(mean_squared_error(df_eval['StasiunO3'], df_eval['Estimasi_O3']))
mse = mean_squared_error(df_eval['StasiunO3'], df_eval['Estimasi_O3'])
mae = mean_absolute_error(df_eval['StasiunO3'], df_eval['Estimasi_O3'])
r2 = r2_score(df_eval['StasiunO3'], df_eval['Estimasi_O3'])

# Tampilkan hasil evaluasi
print("ðŸ“Š Evaluasi Prediksi Ozon (Bulanan):")
print(f"RMSE: {rmse:.3f}")
print(f"MSE : {mse:.3f}")
print(f"MAE : {mae:.3f}")
print(f"RÂ²  : {r2:.3f}")

"""# Estimasi Ozon Jakarta Dengan Easting dan Northing"""

import joblib
import pandas as pd
import numpy as np
import os
import glob
import rasterio
from rasterio.transform import from_origin

# ===== Step 1: Load model=====
model = joblib.load('/content/drive/MyDrive/PENGOLAHAN/HASIL/MODEL LGBM/MODEL_LGBM_EN.pkl')

# Tampilkan nama-nama fitur yang digunakan saat pelatihan
print(model.feature_name_)

# ===== Step 2: Load data prediktor Jakarta =====
data_prediktor = '/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/OUTER/Missing Value Filled'
csv_files = sorted(glob.glob(os.path.join(data_prediktor, 'Data_*.csv')))
df_list = [pd.read_csv(file) for file in csv_files]
df_area_full = pd.concat(df_list, ignore_index=True)

# Hapus akhiran '_JAKARTA' jika ada
df_area_full.columns = df_area_full.columns.str.replace('_JAKARTA', '', regex=False)

# Pastikan kolom waktu dalam datetime
df_area_full['Waktu'] = pd.to_datetime(df_area_full['Waktu'], format='%Y-%m', errors='coerce')
df_area_full['Bulan'] = df_area_full['Waktu'].dt.month
df_area_full['Tahun'] = df_area_full['Waktu'].dt.year

# Ubah koordinat Lat/Lon ke Easting/Northing (jika sudah UTM tinggal rename)
df_area_full['Northing'] = df_area_full['Lat']
df_area_full['Easting'] = df_area_full['Lon']

# Drop kolom yang tidak diperlukan
df_area_full.drop(columns=['Lat', 'Lon', 'latitude', 'longitude'], inplace=True, errors='ignore')

# ===== Fitur yang digunakan untuk prediksi =====
features = ['NO2', 'HCHO', 'CO', 'SO2', 'TropomiO3', 'U10', 'V10', 'SP', 'TP', 'E', 'T2M', 'SSR', 'EVI', 'LST', 'NTL', 'Bulan', 'Tahun', 'Easting', 'Northing']

# Hapus baris dengan nilai hilang di fitur prediktor
df_area_full = df_area_full.dropna(subset=features)

# ===== STEP 3: Prediksi =====
X_pred = df_area_full[features]
df_area_full['Estimasi_O3'] = model.predict(X_pred)

# ===== STEP 4: Simpan CSV & TIFF =====
output_dir_tiff = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_OZON_TIFF_EN'
output_dir_csv = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_OZON_CSV_EN'
os.makedirs(output_dir_tiff, exist_ok=True)
os.makedirs(output_dir_csv, exist_ok=True)

grouped = df_area_full.groupby(df_area_full['Waktu'])

for waktu, group in grouped:
    tahun = waktu.year
    bulan = waktu.month

    # Simpan CSV
    csv_path = os.path.join(output_dir_csv, f'Estimasi_O3_{tahun}_{bulan:02d}.csv')
    group[['Easting', 'Northing', 'Waktu', 'Estimasi_O3']].to_csv(csv_path, index=False)

    # Simpan TIFF
    x_coords = sorted(group['Easting'].unique())
    y_coords = sorted(group['Northing'].unique())[::-1]

    nrows = len(y_coords)
    ncols = len(x_coords)

    pred_grid = np.full((nrows, ncols), np.nan)
    for _, row in group.iterrows():
        row_idx = y_coords.index(row['Northing'])
        col_idx = x_coords.index(row['Easting'])
        pred_grid[row_idx, col_idx] = row['Estimasi_O3']

    # Resolusi grid (dalam meter, karena UTM)
    res_x = round(abs(x_coords[1] - x_coords[0]), 2)
    res_y = round(abs(y_coords[1] - y_coords[0]), 2)
    transform = from_origin(min(x_coords), max(y_coords), res_x, res_y)

    tiff_path = os.path.join(output_dir_tiff, f'Estimasi_O3_{tahun}_{bulan:02d}.tif')
    with rasterio.open(
        tiff_path,
        'w',
        driver='GTiff',
        height=nrows,
        width=ncols,
        count=1,
        dtype='float32',
        crs='EPSG:32748',  # UTM Zone 48S
        transform=transform,
        compress='lzw'
    ) as dst:
        dst.write(pred_grid.astype('float32'), 1)

    print(f"âœ… CSV disimpan:  {csv_path}")
    print(f"âœ… TIFF disimpan: {tiff_path}")

"""Visualisasi Bulanan"""

# Direktori folder yang berisi raster
folder_path = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_OZONE_TIFF_EN' # Ganti dengan path folder kamu

# Cari semua file .tif di folder
tif_files = sorted(glob.glob(os.path.join(folder_path, '*.tif')))

if not tif_files:
    print(f"Tidak ada file .tif ditemukan di {folder_path}")
else:
    print(f"Jumlah file .tif ditemukan: {len(tif_files)}")

    # Tentukan nilai min dan max global dari semua raster
    global_min = float('inf')
    global_max = float('-inf')

    print("Mencari nilai min dan max global...")
    for tif_file in tif_files:
        try:
            with rasterio.open(tif_file) as src:
                img = src.read(1)
                # Filter out NaN and infinite values before finding min/max
                valid_data = img[np.isfinite(img)]
                if valid_data.size > 0:
                    local_min = np.min(valid_data)
                    local_max = np.max(valid_data)
                    global_min = min(global_min, local_min)
                    global_max = max(global_max, local_max)
                else:
                    print(f"Peringatan: File {tif_file} hanya berisi NaN atau nilai tak terhingga.")
        except Exception as e:
            print(f"Error saat membaca {tif_file}: {e}")

    # Jika tidak ada data valid ditemukan di semua raster
    if global_min == float('inf') or global_max == float('-inf'):
         print("Tidak ada data valid ditemukan untuk menentukan rentang legenda.")
    else:
        print(f"Nilai minimum global: {global_min:.2f}")
        print(f"Nilai maksimum global: {global_max:.2f}")

        # Tentukan layout plot (misalnya 4 kolom)
        cols = 4
        rows = (len(tif_files) + cols - 1) // cols

        fig, axs = plt.subplots(rows, cols, figsize=(18, 5 * rows))
        axs = axs.flatten()

        # Loop dan tampilkan setiap raster dengan rentang legenda yang sama
        print("\nMemulai visualisasi...")
        for idx, tif_file in enumerate(tif_files):
            try:
                with rasterio.open(tif_file) as src:
                    img = src.read(1)
                    # Handle potential NaN values if needed (imshow handles NaN by default)

                    im = axs[idx].imshow(img, cmap='jet', vmin=global_min, vmax=global_max) # Gunakan vmin & vmax global
                    axs[idx].set_title(os.path.basename(tif_file).replace('.tif', ''), fontsize=10)
                    axs[idx].axis('off')

            except Exception as e:
                print(f"Error saat memplot {tif_file}: {e}")
                axs[idx].set_title(f"Error: {os.path.basename(tif_file)}", fontsize=10)
                axs[idx].axis('off')


        # Sembunyikan subplot kosong jika ada
        for ax in axs[len(tif_files):]:
            ax.axis('off')

        # Tambahkan colorbar umum untuk semua subplot
        fig.colorbar(im, ax=axs.tolist(), orientation='vertical', fraction=0.02, pad=0.02, label='Estimasi Ozon Permukaan')

        plt.tight_layout(rect=[0, 0, 0.95, 1]) # Adjust layout to make space for the common colorbar
        plt.suptitle('Visualisasi Estimasi Ozon Permukaan (Legend Sama)', fontsize=16, y=1.02)
        plt.show()

"""Visualisasi Tahunan"""

import os
import glob
import numpy as np
import rasterio
import matplotlib.pyplot as plt
from collections import defaultdict

# Folder raster
folder_path = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_O3_TIFF'
tif_files = sorted(glob.glob(os.path.join(folder_path, '*.tif')))

if not tif_files:
    print("Tidak ada file ditemukan.")
    exit()

# Kelompokkan berdasarkan tahun
raster_by_year = defaultdict(list)
for tif_file in tif_files:
    filename = os.path.basename(tif_file)
    parts = filename.replace('.tif', '').split('_')
    for part in parts:
        if part.isdigit() and len(part) == 4:
            raster_by_year[part].append(tif_file)
            break

# Hitung rata-rata raster per tahun
mean_rasters = {}  # Dict {year: mean_raster_array}
yearly_avg_values = {}  # Dict {year: mean value of valid pixels}
global_min, global_max = float('inf'), float('-inf')

for year, files in sorted(raster_by_year.items()):
    raster_stack = []
    for tif_file in files:
        with rasterio.open(tif_file) as src:
            img = src.read(1).astype('float32')
            img[~np.isfinite(img)] = np.nan
            raster_stack.append(img)

    # Rata-rata citra per tahun (setiap piksel)
    stack_array = np.stack(raster_stack)
    mean_array = np.nanmean(stack_array, axis=0)
    mean_rasters[year] = mean_array

    # Rata-rata nilai seluruh piksel valid (satu angka per tahun)
    valid_pixels = mean_array[np.isfinite(mean_array)]
    yearly_mean = np.nan if valid_pixels.size == 0 else np.nanmean(valid_pixels)
    yearly_avg_values[year] = yearly_mean

    # Update rentang legenda global
    if valid_pixels.size > 0:
        global_min = min(global_min, np.min(valid_pixels))
        global_max = max(global_max, np.max(valid_pixels))

print(f"Global min: {global_min:.2f}, max: {global_max:.2f}")

# Visualisasikan rata-rata per tahun
years = sorted(mean_rasters.keys())
cols = 4
rows = (len(years) + cols - 1) // cols
fig, axs = plt.subplots(rows, cols, figsize=(18, 5 * rows))
axs = axs.flatten()

for idx, year in enumerate(years):
    img = mean_rasters[year]
    im = axs[idx].imshow(img, cmap='jet', vmin=global_min, vmax=global_max)
    mean_val = yearly_avg_values[year]
    axs[idx].set_title(f"{year}\nMean: {mean_val:.2f} Âµg/mÂ³", fontsize=10)
    axs[idx].axis('off')

# Kosongkan subplot sisa
for ax in axs[len(years):]:
    ax.axis('off')

# Tambahkan colorbar umum untuk semua subplot
fig.colorbar(im, ax=axs.tolist(), orientation='vertical', fraction=0.02, pad=0.02, label='Estimasi Ozon Permukaan (Âµg/mÂ³)')

# Tambahkan judul utama dengan jarak vertikal yang lebih tinggi
plt.suptitle('Rata-rata Estimasi Ozon Permukaan per Tahun', fontsize=18, y=1.05)

# Atur ulang tata letak agar tidak tabrakan
plt.tight_layout(rect=[0, 0, 1, 0.96])

plt.show()

# Folder output untuk menyimpan raster rerata
output_folder = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/RATA_RATA_TAHUNAN_EN'
os.makedirs(output_folder, exist_ok=True)

for year, mean_array in mean_rasters.items():
    ref_file = raster_by_year[year][0]  # Gunakan file pertama sebagai referensi metadata
    with rasterio.open(ref_file) as src:
        meta = src.meta.copy()
        meta.update({
            'dtype': 'float32',
            'count': 1,
            'compress': 'lzw'
        })

    output_path = os.path.join(output_folder, f'ozon_mean_{year}.tif')
    with rasterio.open(output_path, 'w', **meta) as dst:
        dst.write(mean_array.astype('float32'), 1)

    print(f"Citra rerata tahunan untuk {year} disimpan di: {output_path}")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import glob
import os
import numpy as np
import matplotlib.patches as mpatches
import matplotlib.lines as mlines
from matplotlib.legend_handler import HandlerTuple # Import HandlerTuple

# === 1. Baca Semua File CSV dalam Folder ===
folder_path = '/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_O3_CSV'
all_files = glob.glob(os.path.join(folder_path, "*.csv"))

if len(all_files) == 0:
    raise FileNotFoundError("Tidak ada file CSV ditemukan di folder tersebut!")

# Gabungkan semua file
df_list = []
for file in all_files:
    df = pd.read_csv(file)
    if not {'Waktu', 'Estimasi_O3'}.issubset(df.columns):
        raise ValueError(f"File {file} tidak mengandung kolom 'Waktu' atau 'Estimasi_O3'")
    df['Waktu'] = pd.to_datetime(df['Waktu'], errors='coerce')
    df = df.dropna(subset=['Waktu'])
    df['Bulan'] = df['Waktu'].dt.month
    df['Tahun'] = df['Waktu'].dt.year
    df_list.append(df)

df_all = pd.concat(df_list, ignore_index=True)

# === 2. Ubah Bulan Jadi Nama Bulan ===
bulan_map = {
    1: 'January', 2: 'February', 3: 'March', 4: 'April',
    5: 'May', 6: 'June', 7: 'July', 8: 'August',
    9: 'September', 10: 'October', 11: 'November', 12: 'December'
}
df_all['Bulan'] = df_all['Bulan'].map(bulan_map)

# === 3. Hitung Rata-rata Bulanan per Tahun ===
df_grouped = df_all.groupby(['Tahun', 'Bulan'], as_index=False)['Estimasi_O3'].mean()

# === 4. Urutkan Bulan ===
month_order = ['January', 'February', 'March', 'April', 'May', 'June',
               'July', 'August', 'September', 'October', 'November', 'December']
df_grouped['Bulan'] = pd.Categorical(df_grouped['Bulan'], categories=month_order, ordered=True)
df_grouped = df_grouped.sort_values(['Tahun', 'Bulan'])

# Buat pivot table untuk plot bar dan line
pivot_df = df_grouped.pivot(index='Bulan', columns='Tahun', values='Estimasi_O3').loc[month_order]


# === 6. Plot Bar dan Line secara bersamaan menggunakan matplotlib ===
fig, ax = plt.subplots(figsize=(12, 6))

x = np.arange(len(month_order))  # Posisi bulan
width = 0.15  # Lebar bar
colors = plt.cm.tab10.colors  # Palet warna

bars = []
lines = []

for i, year in enumerate(pivot_df.columns):
    bar = ax.bar(x + (i - 1) * width, pivot_df[year], width, color=colors[i % len(colors)])
    line, = ax.plot(x, pivot_df[year], marker='o', color=colors[i % len(colors)])
    bars.append(bar)
    lines.append(line)

ax.set_xticks(x)
ax.set_xticklabels(month_order, rotation=45)
ax.set_xlabel('Month', fontweight='bold')
ax.set_ylabel('Monthly Concentration (Âµg/mÂ³)', fontweight='bold')
#ax.set_title("Tren Temporal Konsentrasi Ozon Permukaan", loc='center', fontsize=20, fontweight='bold')
ax.grid(False)

# Buat pasangan patch dan line sebagai proxy legend handles
proxy_handles = []
for i, year in enumerate(pivot_df.columns):
    patch = mpatches.Patch(color=colors[i % len(colors)])
    line = mlines.Line2D([], [], color=colors[i % len(colors)], marker='o', linestyle='-')
    proxy_handles.append((patch, line))  # tuple of handles

# Buat legend, gunakan HandlerTuple supaya tuple (patch,line) jadi satu simbol di legend
ax.legend(proxy_handles, [str(year) for year in pivot_df.columns], handler_map={tuple: HandlerTuple(ndivide=None)},  loc='best')

plt.tight_layout()
plt.show()

"""Tren Temporal"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import glob

# 1. Path ke folder berisi file prediksi per bulan
folder_path = "/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_O3_CSV"  # ganti sesuai lokasi
all_files = glob.glob(os.path.join(folder_path, "Estimasi_O3_*.csv"))

# 2. Gabungkan semua file prediksi
list_df = []
for file in all_files:
    df_temp = pd.read_csv(file)
    list_df.append(df_temp)

df_pred = pd.concat(list_df, ignore_index=True)

# 3. Ubah kolom waktu ke datetime
df_pred['Waktu'] = pd.to_datetime(df_pred['Waktu'])

# 4. Load data aktual
df_aktual = pd.read_csv("/content/drive/MyDrive/PENGOLAHAN/DATA/EKTRAKSI PIKSEL/Hasil Ekstraksi/Ekstraksi Stasiun/Data_TrainTest_20222024.csv")
df_aktual['Waktu'] = pd.to_datetime(df_aktual['Waktu'])

# 5. Hitung rata-rata per bulan
pred_monthly = df_pred.groupby(df_pred['Waktu'].dt.to_period('M')).mean(numeric_only=True)
obs_monthly = df_aktual.groupby(df_aktual['Waktu'].dt.to_period('M')).mean(numeric_only=True)

# 6. Gabungkan berdasarkan Tahun dan Bulan
pred_monthly.index = pred_monthly.index.to_timestamp()
obs_monthly.index = obs_monthly.index.to_timestamp()

# 7. Buat plot
plt.figure(figsize=(14, 6))

# Tambah shading background tiap tahun
plt.axvspan(pd.to_datetime('2022-01-01'), pd.to_datetime('2022-12-31'), facecolor='#fff3e0', alpha=0.6)  # Krem terang
plt.axvspan(pd.to_datetime('2023-01-01'), pd.to_datetime('2023-12-31'), facecolor='#e3f2fd', alpha=0.6)  # Biru terang
plt.axvspan(pd.to_datetime('2024-01-01'), pd.to_datetime('2024-12-31'), facecolor='#f3e5f5', alpha=0.6)  # Ungu terang


# Plot Predicted Ozone
plt.plot(pred_monthly.index, pred_monthly['Estimasi_O3'], label='Predicted_Ozone',
         color='#f4a300', marker='s', linestyle='-', linewidth=2, markersize=5)

# Plot Measured Ozone
plt.plot(obs_monthly.index, obs_monthly['StasiunO3'], label='Measured_Ozone',
         color='#32cd32', marker='o', linestyle='-', linewidth=2, markersize=5)

# Label Tahun di tengah
for year in range(2022, 2025):
    plt.text(pd.to_datetime(f'{year}-06-15'), 150, str(year),
             fontsize=20, fontweight='bold', ha='center')

# Styling
plt.ylabel("Monthly Concentration (Âµg/mÂ³)", fontsize=12)
plt.xlabel("Study Period", fontsize=12)
plt.xticks(pd.date_range('2022-01', '2024-12', freq='3M'),
           labels=['Jan', 'Apr', 'Jul', 'Oct']*3, rotation=45)
plt.ylim(0, 160)
plt.grid(True, linestyle='--', alpha=0.5)

# Legend
plt.legend(loc='upper right', fontsize=10, frameon=False)

# Tampilkan
plt.tight_layout()
plt.show()

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Gabungkan data prediksi dan observasi berdasarkan waktu (inner join agar hanya data yang saling cocok)
df_eval = pd.merge(pred_monthly[['Estimasi_O3']], obs_monthly[['StasiunO3']],
                   left_index=True, right_index=True, how='inner')

# Hitung error metrics
rmse = np.sqrt(mean_squared_error(df_eval['StasiunO3'], df_eval['Estimasi_O3']))
mse = mean_squared_error(df_eval['StasiunO3'], df_eval['Estimasi_O3'])
mae = mean_absolute_error(df_eval['StasiunO3'], df_eval['Estimasi_O3'])
r2 = r2_score(df_eval['StasiunO3'], df_eval['Estimasi_O3'])

# Tampilkan hasil evaluasi
print("ðŸ“Š Evaluasi Prediksi Ozon (Bulanan):")
print(f"RMSE: {rmse:.3f}")
print(f"MSE : {mse:.3f}")
print(f"MAE : {mae:.3f}")
print(f"RÂ²  : {r2:.3f}")

"""# Prediksi 2025 Tanpa Easting & Northing"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import numpy as np

# 1. Load data
df = pd.read_csv("/content/drive/MyDrive/PENGOLAHAN/HASIL/EDA/Outlier_Handled/Data_20222024_OutlierHandled.csv")

# 2. Parsing waktu
df['Waktu'] = pd.to_datetime(df['Waktu'])
df['Tahun'] = df['Waktu'].dt.year
df['Bulan'] = df['Waktu'].dt.month

# 3. Visualisasi tren ozon
plt.figure(figsize=(12, 4))
sns.lineplot(data=df, x='Waktu', y='TropomiO3', label='Tropomi Oâ‚ƒ')
plt.title("Tren Ozon 2022â€“2024")
plt.ylabel("Tropomi O3 (ppb)")
plt.grid(True)
plt.show()

# 4. Fitur dan target (tanpa Easting dan Northing)
fitur = ['Station_ID', 'NO2', 'HCHO', 'CO', 'SO2', 'TropomiO3', 'U10',
         'V10', 'SP', 'TP', 'E', 'T2M', 'SSR', 'EVI', 'LST', 'NTL',
         'StasiunO3', 'Bulan', 'Tahun']

X = df[fitur]
y = df['StasiunO3']

# 5. Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 6. Model
model = lgb.LGBMRegressor()
model.fit(X_train, y_train)

# 7. Evaluasi
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"âœ… Evaluation Results:")
print(f"RMSE: {rmse:.3f}")
print(f"MAE: {mae:.3f}")
print(f"MSE: {mse:.3f}")
print(f"RÂ²: {r2:.3f}")

# 8. Simulasi data untuk tahun 2025 dari rata-rata bulanan 2024
data_2025 = df[df['Tahun'] == 2024].groupby('Bulan').mean(numeric_only=True).reset_index()
data_2025['Tahun'] = 2025
data_2025['Waktu'] = pd.to_datetime(dict(year=data_2025['Tahun'], month=data_2025['Bulan'], day=1))

# 9. Prediksi ozon 2025
X_2025 = data_2025[fitur]
data_2025['Prediksi_Ozon_2025'] = model.predict(X_2025)

# 10. Visualisasi prediksi ozon 2025
plt.figure(figsize=(10, 4))
sns.lineplot(data=data_2025, x='Waktu', y='Prediksi_Ozon_2025', marker='o')
plt.title("Prediksi Ozon Tahun 2025 (Bulanan)")
plt.ylabel("StasiunO3 (Prediksi)")
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# 11. Simulasi data 2025 per stasiun berdasarkan rata-rata bulanan 2024
data_2024 = df[df['Tahun'] == 2024]

# Ambil rata-rata bulanan per stasiun
data_2025_stasiun = data_2024.groupby(['Station_ID', 'Bulan']).mean(numeric_only=True).reset_index()
data_2025_stasiun['Tahun'] = 2025

# Tambahkan kolom 'Waktu' untuk keperluan visualisasi
data_2025_stasiun['Waktu'] = pd.to_datetime(dict(
    year=data_2025_stasiun['Tahun'],
    month=data_2025_stasiun['Bulan'],
    day=1
))

# Prediksi menggunakan model
X_2025_stasiun = data_2025_stasiun[fitur]
data_2025_stasiun['Prediksi_Ozon_2025'] = model.predict(X_2025_stasiun)

# 12. Visualisasi hasil prediksi per stasiun (contoh beberapa stasiun)
plt.figure(figsize=(12, 6))
unique_stations = data_2025_stasiun['Station_ID'].unique()

# Tampilkan maksimal 6 stasiun sebagai contoh visualisasi
for station in unique_stations[:6]:
    subset = data_2025_stasiun[data_2025_stasiun['Station_ID'] == station]
    sns.lineplot(data=subset, x='Waktu', y='Prediksi_Ozon_2025', label=f'Stasiun {station}')

plt.title("Prediksi Ozon 2025 per Stasiun")
plt.ylabel("StasiunO3 (Prediksi)")
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.legend()
plt.show()

# Simpan hasil prediksi lengkap ke file
data_2025_stasiun.to_csv("/content/drive/MyDrive/PENGOLAHAN/HASIL/Prediksi_Ozon_2025_per_Stasiun.csv", index=False)
print("âœ… Prediksi ozon per stasiun untuk tahun 2025 berhasil disimpan.")

# Simpan hasil prediksi ozon 2025 ke file CSV
data_2025.to_csv("/content/drive/MyDrive/PENGOLAHAN/HASIL/Prediksi_Ozon_2025_Bulanan.csv", index=False)
print("âœ… File CSV berhasil disimpan: Prediksi_Ozon_2025_Bulanan.csv")

"""# Prediksi 2025 Dengan Easting & Northing"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import numpy as np

# 1. Load data
df = pd.read_csv("/content/drive/MyDrive/PENGOLAHAN/HASIL/EDA/Outlier_Handled/Data_20222024_OutlierHandled.csv")

# 2. Parsing waktu
df['Waktu'] = pd.to_datetime(df['Waktu'])
df['Tahun'] = df['Waktu'].dt.year
df['Bulan'] = df['Waktu'].dt.month

# 3. Visualisasi tren ozon
plt.figure(figsize=(12, 4))
sns.lineplot(data=df, x='Waktu', y='TropomiO3', label='Tropomi Oâ‚ƒ')
plt.title("Tren Ozon 2022â€“2024")
plt.ylabel("Tropomi O3 (ppb)")
plt.grid(True)
plt.show()

# 4. Fitur dan target (tanpa Easting dan Northing)
fitur = ['Station_ID', 'NO2', 'HCHO', 'CO', 'SO2', 'TropomiO3', 'U10',
         'V10', 'SP', 'TP', 'E', 'T2M', 'SSR', 'EVI', 'LST', 'NTL',
         'StasiunO3', 'Bulan', 'Tahun','Easting','Northing']

X = df[fitur]
y = df['StasiunO3']

# 5. Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 6. Model
model = lgb.LGBMRegressor()
model.fit(X_train, y_train)

# 7. Evaluasi
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"âœ… Evaluation Results:")
print(f"RMSE: {rmse:.3f}")
print(f"MAE: {mae:.3f}")
print(f"MSE: {mse:.3f}")
print(f"RÂ²: {r2:.3f}")

# 8. Simulasi data untuk tahun 2025 dari rata-rata bulanan 2024
data_2025 = df[df['Tahun'] == 2024].groupby('Bulan').mean(numeric_only=True).reset_index()
data_2025['Tahun'] = 2025
data_2025['Waktu'] = pd.to_datetime(dict(year=data_2025['Tahun'], month=data_2025['Bulan'], day=1))

# 9. Prediksi ozon 2025
X_2025 = data_2025[fitur]
data_2025['Prediksi_Ozon_2025'] = model.predict(X_2025)

# 10. Visualisasi prediksi ozon 2025
plt.figure(figsize=(10, 4))
sns.lineplot(data=data_2025, x='Waktu', y='Prediksi_Ozon_2025', marker='o')
plt.title("Prediksi Ozon Tahun 2025 (Bulanan) Dengan Easting & Northing")
plt.ylabel("StasiunO3 (Prediksi)")
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# 11. Simulasi data 2025 per stasiun berdasarkan rata-rata bulanan 2024
data_2024 = df[df['Tahun'] == 2024]

# Ambil rata-rata bulanan per stasiun
data_2025_stasiun = data_2024.groupby(['Station_ID', 'Bulan']).mean(numeric_only=True).reset_index()
data_2025_stasiun['Tahun'] = 2025

# Tambahkan kolom 'Waktu' untuk keperluan visualisasi
data_2025_stasiun['Waktu'] = pd.to_datetime(dict(
    year=data_2025_stasiun['Tahun'],
    month=data_2025_stasiun['Bulan'],
    day=1
))

# Prediksi menggunakan model
X_2025_stasiun = data_2025_stasiun[fitur]
data_2025_stasiun['Prediksi_Ozon_2025'] = model.predict(X_2025_stasiun)

# 12. Visualisasi hasil prediksi per stasiun (contoh beberapa stasiun)
plt.figure(figsize=(12, 6))
unique_stations = data_2025_stasiun['Station_ID'].unique()

# Tampilkan maksimal 6 stasiun sebagai contoh visualisasi
for station in unique_stations[:6]:
    subset = data_2025_stasiun[data_2025_stasiun['Station_ID'] == station]
    sns.lineplot(data=subset, x='Waktu', y='Prediksi_Ozon_2025', label=f'Stasiun {station}')

plt.title("Prediksi Ozon 2025 per Stasiun Dengan Easting & Northing")
plt.ylabel("StasiunO3 (Prediksi)")
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.legend()
plt.show()

# Simpan hasil prediksi lengkap ke file
data_2025_stasiun.to_csv("/content/drive/MyDrive/PENGOLAHAN/HASIL/Prediksi_Ozon_2025_per_Stasiun_EN.csv", index=False)
print("âœ… Prediksi ozon per stasiun untuk tahun 2025 berhasil disimpan.")


# Simpan hasil prediksi ozon 2025 ke file CSV
data_2025.to_csv("/content/drive/MyDrive/PENGOLAHAN/HASIL/Prediksi_Ozon_2025_Bulanan_EN.csv", index=False)
print("âœ… File CSV berhasil disimpan: Prediksi_Ozon_2025_Bulanan.csv")

"""# LCZ"""

!pip install rasterstats

import geopandas as gpd
from rasterstats import zonal_stats
import rasterio
import os
from rasterio.warp import calculate_default_transform, reproject
from rasterio.enums import Resampling
import numpy as np # Ensure numpy is imported if used later

# Load LCZ dan batas administratif
lcz = gpd.read_file("/content/drive/MyDrive/PENGOLAHAN/DATA/LCZ Jakarta/LCZ_DKI JAKARTA.shp")
adm = gpd.read_file("/content/drive/MyDrive/PENGOLAHAN/DATA/AOI/JAKARTA.shp")

# Check if input data is loaded correctly
print(f"LCZ loaded: {len(lcz)} features")
print(f"ADM loaded: {len(adm)} features")

# Check CRS of input data
print(f"LCZ CRS: {lcz.crs}")
print(f"ADM CRS: {adm.crs}")

# Intersect LCZ dan admin
# Reproject one to match the other if CRSs are different. Let's reproject adm to lcz's CRS
if lcz.crs and adm.crs and lcz.crs != adm.crs: # Add checks for non-None CRS
    print(f"Reprojecting ADM from {adm.crs} to {lcz.crs}")
    adm = adm.to_crs(lcz.crs)
elif not lcz.crs or not adm.crs:
    print("Warning: One or both input shapefiles are missing CRS information.")


lcz_adm = gpd.overlay(lcz, adm, how='intersection')

# Check if lcz_adm has features after overlay
print(f"LCZ_ADM features after overlay: {len(lcz_adm)}")
if lcz_adm.empty:
    print("lcz_adm is empty after overlay. Check input shapefiles and their overlap.")

# Add area calculation only if lcz_adm is not empty
if not lcz_adm.empty:
    lcz_adm["Area_ha"] = lcz_adm.geometry.area / 10_000
    # Hitung proporsi LCZ di tiap wilayah administratif
    proporsi_lcz = lcz_adm.groupby(["WADMKK", "Kelas"])["Area_ha"].sum().reset_index()
    print("Proporsi LCZ calculated.")

import geopandas as gpd
from rasterstats import zonal_stats
import pandas as pd
import matplotlib.pyplot as plt

# EPSG untuk UTM zona 48S (wilayah Jakarta)
utm_crs = "EPSG:32748"

# Load shapefile LCZ dan administrasi
lcz = gpd.read_file("/content/drive/MyDrive/PENGOLAHAN/DATA/LCZ Jakarta/LCZ_DKI JAKARTA.shp")
adm = gpd.read_file("/content/drive/MyDrive/PENGOLAHAN/DATA/AOI/JAKARTA.shp")

# Reproject ke UTM 48S
lcz = lcz.to_crs(utm_crs)
adm = adm.to_crs(utm_crs)

# Intersect antara LCZ dan batas admin
lcz_adm = gpd.overlay(lcz, adm, how='intersection')
lcz_adm["Area_ha"] = lcz_adm.geometry.area / 10_000  # Luas dalam hektar

# Fungsi ekstraksi zonal stats dari raster Oâ‚ƒ tahunan
def extract_o3_by_year(vector_gdf, raster_path, year_label):
    stats = zonal_stats(vector_gdf, raster_path, stats=["mean"], geojson_out=True)
    gdf = gpd.GeoDataFrame.from_features(stats)
    gdf = gdf[["WADMKK", "Kelas", "mean"]].rename(columns={"mean": f"O3_{year_label}"})
    return gdf

# Ekstraksi dari tiap raster tahunan (ubah path sesuai filenya)
o3_2022 = extract_o3_by_year(lcz_adm, "/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/RATA_RATA_TAHUNAN/ozon_mean_2022.tif", "2022")
o3_2023 = extract_o3_by_year(lcz_adm, "/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/RATA_RATA_TAHUNAN/ozon_mean_2023.tif", "2023")
o3_2024 = extract_o3_by_year(lcz_adm, "/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/RATA_RATA_TAHUNAN/ozon_mean_2024.tif", "2024")

# Gabungkan hasil per tahun
merged = o3_2022.merge(o3_2023, on=["WADMKK", "Kelas"]).merge(o3_2024, on=["WADMKK", "Kelas"])

# Agregasi per wilayah administratif
adm_summary = merged.groupby("WADMKK")[["O3_2022", "O3_2023", "O3_2024"]].mean().reset_index()

# Visualisasi hasilnya
adm_summary.plot(
    x="WADMKK",
    kind="bar",
    figsize=(10, 6),
    ylabel="Konsentrasi Oâ‚ƒ (Âµg/mÂ³)",
    xlabel="Wilayah Administratif",
    title="Rata-rata Konsentrasi Oâ‚ƒ Tahunan per Wilayah Administratif (DKI Jakarta)",
    rot=45
)
plt.tight_layout()
plt.show()

# Agregasi per wilayah administratif
adm_summary = merged.groupby("Kelas")[["O3_2022", "O3_2023", "O3_2024"]].mean().reset_index()

# Visualisasi hasilnya
adm_summary.plot(
    x="Kelas",
    kind="bar",
    figsize=(10, 6),
    ylabel="Konsentrasi Oâ‚ƒ (Âµg/mÂ³)",
    xlabel="LCZ Type",
    title="Hubungan LCZ dengan Ozon",
    rot=45
)
plt.tight_layout()
plt.show()

import geopandas as gpd
from rasterstats import zonal_stats
import pandas as pd
import matplotlib.pyplot as plt

# CRS target UTM zona 48S
utm_crs = "EPSG:32748"

# Load shapefile LCZ dan reproject
lcz = gpd.read_file("/content/drive/MyDrive/PENGOLAHAN/DATA/LCZ Jakarta/LCZ_DKI JAKARTA.shp")
lcz = lcz.to_crs(utm_crs)

# Fungsi untuk ekstraksi zonal stats O3 tahunan berdasarkan LCZ
def extract_o3_by_lcz(lcz_gdf, raster_path, year_label):
    stats = zonal_stats(lcz_gdf, raster_path, stats=["mean"], geojson_out=True)
    gdf = gpd.GeoDataFrame.from_features(stats)
    gdf = gdf[["Kelas", "mean"]].rename(columns={"mean": f"Mean_O3_{year_label}"})
    return gdf

# Ekstraksi untuk masing-masing tahun (pastikan nama file raster sesuai)
o3_2022 = extract_o3_by_lcz(lcz, "/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/RATA_RATA_TAHUNAN/ozon_mean_2022.tif", "2022")
o3_2023 = extract_o3_by_lcz(lcz, "/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/RATA_RATA_TAHUNAN/ozon_mean_2023.tif", "2023")
o3_2024 = extract_o3_by_lcz(lcz, "/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/RATA_RATA_TAHUNAN/ozon_mean_2024.tif", "2024")

# Gabungkan semua data berdasarkan LCZ_TYPE
merged = o3_2022.merge(o3_2023, on="Kelas").merge(o3_2024, on="Kelas")

# Hitung rata-rata per LCZ_TYPE
table = merged.groupby("Kelas")[["Mean_O3_2022", "Mean_O3_2023", "Mean_O3_2024"]].mean().reset_index()

# Format angka dan satuan
formatted_table = table.copy()
for col in ["Mean_O3_2022", "Mean_O3_2023", "Mean_O3_2024"]:
    formatted_table[col] = formatted_table[col].apply(lambda x: f"{x:.1f} Âµg/mÂ³")

# Tampilkan tabel
print("Tabel Rata-Rata Konsentrasi Oâ‚ƒ per Kelas LCZ (2022â€“2024):")
print(formatted_table.to_markdown(index=False))

# Plot visualisasi bar chart
table.set_index("Kelas").plot(kind="bar", figsize=(10, 6))
plt.ylabel("Konsentrasi Oâ‚ƒ (Âµg/mÂ³)")
plt.xlabel("Tipe LCZ")
plt.title("Rata-Rata Konsentrasi Oâ‚ƒ Tahunan Berdasarkan Kelas LCZ (2022â€“2024)")
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# prompt: buat code untuk korelasi pearson

# Menghitung korelasi Pearson
correlation_matrix = df_clean[numerical_columns].corr(method="pearson")

plt.figure(figsize=(12,10))
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')
plt.title('Pearson Correlation Heatmap', fontsize=16)
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

"""# Zonal Statistic"""

!pip install rasterstats

import geopandas as gpd
import rasterio
from rasterio.mask import mask
from rasterstats import zonal_stats
import pandas as pd
import glob
import os

# 1. Baca shapefile dan ubah ke UTM 48S (EPSG:32748)
gdf = gpd.read_file("/content/drive/MyDrive/PENGOLAHAN/DATA/AOI/JAKARTA.shp")
gdf = gdf.to_crs(epsg=32748)

# Filter hanya wilayah administrasi kota di Jakarta
target_kota = ['Kota Jakarta Utara', 'Kota Jakarta Barat', 'Kota Jakarta Selatan', 'Kota Jakarta Timur', 'Kota Jakarta Pusat']
gdf = gdf[gdf['WADMKK'].isin(target_kota)]  # Sesuaikan kolom nama kota

# 2. Dapatkan daftar file raster (asumsikan tersimpan di folder "ozon_raster")
raster_files = sorted(glob.glob("/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_OZON_TIFF/Estimasi_O3_*.tif"))

# 3. Loop untuk melakukan zonal statistik per bulan
results = []

for raster_fp in raster_files:
    with rasterio.open(raster_fp) as src:
        # Pastikan raster sudah di EPSG:32748
        if src.crs.to_epsg() != 32748:
            raise ValueError("Raster harus dalam CRS EPSG:32748")

        # Crop raster dengan boundary shapefile
        stats = zonal_stats(
            gdf,
            raster_fp,
            stats=["mean"],
            geojson_out=True,
            nodata=src.nodata
        )

        # Ekstrak nama file sebagai penanda waktu (misal: ozon_2022_01.tif â†’ 2022-01)
        nama_file = os.path.basename(raster_fp)
        waktu = nama_file.replace("Estimasi_O3_", "").replace(".tif", "").replace("_", "-")

        # Simpan hasil
        for i, s in enumerate(stats):
            kota = s['properties']['WADMKK']
            mean_ozon = s['properties']['mean']
            results.append({
                'Kota': kota,
                'Waktu': waktu,
                'Ozon': mean_ozon
            })

# 4. Simpan sebagai CSV
df = pd.DataFrame(results)
df.to_csv("/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/zonal_statistik_ozon_dki.csv", index=False)

import geopandas as gpd
import rasterio
from rasterio.mask import mask
from rasterstats import zonal_stats
import pandas as pd
import glob
import os

# 1. Baca shapefile dan ubah ke UTM 48S (EPSG:32748)
gdf = gpd.read_file("/content/drive/MyDrive/PENGOLAHAN/DATA/AOI/JAKARTA.shp")
gdf = gdf.to_crs(epsg=32748)

# Filter hanya wilayah administrasi kota di Jakarta
target_kota = ['Kota Jakarta Utara', 'Kota Jakarta Barat', 'Kota Jakarta Selatan', 'Kota Jakarta Timur', 'Kota Jakarta Pusat']
gdf = gdf[gdf['WADMKK'].isin(target_kota)]  # Sesuaikan kolom nama kota

# 2. Dapatkan daftar file raster (asumsikan tersimpan di folder "ozon_raster")
raster_files = sorted(glob.glob("/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/ESTIMASI_O3_TIFF/Estimasi_O3_*.tif"))

# 3. Loop untuk melakukan zonal statistik per bulan
results = []

for raster_fp in raster_files:
    with rasterio.open(raster_fp) as src:
        # Pastikan raster sudah di EPSG:32748
        if src.crs.to_epsg() != 32748:
            raise ValueError("Raster harus dalam CRS EPSG:32748")

        # Crop raster dengan boundary shapefile
        stats = zonal_stats(
            gdf,
            raster_fp,
            stats=["mean"],
            geojson_out=True,
            nodata=src.nodata
        )

        # Ekstrak nama file sebagai penanda waktu (misal: ozon_2022_01.tif â†’ 2022-01)
        nama_file = os.path.basename(raster_fp)
        waktu = nama_file.replace("Estimasi_O3_", "").replace(".tif", "").replace("_", "-")

        # Simpan hasil
        for i, s in enumerate(stats):
            kota = s['properties']['WADMKK']
            mean_ozon = s['properties']['mean']
            results.append({
                'Kota': kota,
                'Waktu': waktu,
                'Ozon': mean_ozon
            })

# 4. Simpan sebagai CSV
df = pd.DataFrame(results)
df.to_csv("/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/zonal_statistik_ozon_dki_EN.csv", index=False)

import pandas as pd
import matplotlib.pyplot as plt

# 1. Baca file CSV hasil zonal statistik
csv_path = "/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/zonal_statistik_ozon_dki.csv"
df = pd.read_csv(csv_path)

# 2. Ubah kolom waktu ke datetime dan buat kolom tahun dan bulan
df['Waktu'] = pd.to_datetime(df['Waktu'], format="%Y-%m")
df['Tahun'] = df['Waktu'].dt.year
df['Bulan'] = df['Waktu'].dt.month

# 3. Mapping angka bulan ke nama bulan (Indonesia)
nama_bulan = {
    1: "Januari", 2: "Februari", 3: "Maret", 4: "April", 5: "Mei", 6: "Juni",
    7: "Juli", 8: "Agustus", 9: "September", 10: "Oktober", 11: "November", 12: "Desember"
}
df['Nama_Bulan'] = df['Bulan'].map(nama_bulan)

# Urutan bulan untuk X-axis
urutan_bulan = [nama_bulan[i] for i in range(1, 13)]

# 4. Daftar kota dan tahun
kota_list = df['Kota'].unique()
tahun_list = sorted(df['Tahun'].unique())

# 5. Buat grafik per tahun
for tahun in tahun_list:
    df_tahun = df[df['Tahun'] == tahun]

    plt.figure(figsize=(11, 6))

    for kota in kota_list:
        df_kota = df_tahun[df_tahun['Kota'] == kota]
        df_kota = df_kota.set_index('Nama_Bulan').reindex(urutan_bulan).reset_index()
        plt.plot(df_kota['Nama_Bulan'], df_kota['Ozon'], marker='o', label=kota)

    plt.title(f"Konsentrasi Ozon Bulanan per Kota di DKI Jakarta - {tahun}")
    plt.xlabel("Bulan")
    plt.ylabel("Konsentrasi Ozon (Î¼g/mÂ³)")  # Ubah satuan jika perlu
    plt.xticks(rotation=45)
    plt.legend()
    plt.grid(False)
    plt.tight_layout()

# 6. Tampilkan tabel ozon per kota dan bulan untuk tiap tahun
for tahun in tahun_list:
    print(f"\nTabel Konsentrasi Ozon Tahun {tahun}")

    df_tahun = df[df['Tahun'] == tahun]

    # Buat pivot table: index = Nama_Bulan, columns = Kota, values = Ozon
    tabel = df_tahun.pivot(index='Nama_Bulan', columns='Kota', values='Ozon')

    # Susun urutan bulan
    tabel = tabel.reindex(urutan_bulan)

    print(tabel.round(2))  # Membulatkan nilai ke 2 desimal



# Simpan ke Excel, satu sheet per tahun
excel_path = "/content/drive/MyDrive/PENGOLAHAN/HASIL/tabel_ozon_per_kota_per_tahun.xlsx"
with pd.ExcelWriter(excel_path) as writer:
    for tahun in tahun_list:
        df_tahun = df[df['Tahun'] == tahun]
        tabel = df_tahun.pivot(index='Nama_Bulan', columns='Kota', values='Ozon')
        tabel = tabel.reindex(urutan_bulan)
        tabel.to_excel(writer, sheet_name=str(tahun))

import pandas as pd
import matplotlib.pyplot as plt

# 1. Baca file CSV hasil zonal statistik
csv_path = "/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/zonal_statistik_ozon_dki_EN.csv"
df = pd.read_csv(csv_path)

# 2. Ubah kolom waktu ke datetime dan buat kolom tahun dan bulan
df['Waktu'] = pd.to_datetime(df['Waktu'], format="%Y-%m")
df['Tahun'] = df['Waktu'].dt.year
df['Bulan'] = df['Waktu'].dt.month

# 3. Mapping angka bulan ke nama bulan (Indonesia)
nama_bulan = {
    1: "Januari", 2: "Februari", 3: "Maret", 4: "April", 5: "Mei", 6: "Juni",
    7: "Juli", 8: "Agustus", 9: "September", 10: "Oktober", 11: "November", 12: "Desember"
}
df['Nama_Bulan'] = df['Bulan'].map(nama_bulan)

# Urutan bulan untuk X-axis
urutan_bulan = [nama_bulan[i] for i in range(1, 13)]

# 4. Daftar kota dan tahun
kota_list = df['Kota'].unique()
tahun_list = sorted(df['Tahun'].unique())

# 5. Buat grafik per tahun
for tahun in tahun_list:
    df_tahun = df[df['Tahun'] == tahun]

    plt.figure(figsize=(11, 6))

    for kota in kota_list:
        df_kota = df_tahun[df_tahun['Kota'] == kota]
        df_kota = df_kota.set_index('Nama_Bulan').reindex(urutan_bulan).reset_index()
        plt.plot(df_kota['Nama_Bulan'], df_kota['Ozon'], marker='o', label=kota)

    plt.title(f"Konsentrasi Ozon Bulanan per Kota di DKI Jakarta - {tahun}")
    plt.xlabel("Bulan")
    plt.ylabel("Konsentrasi Ozon (Î¼g/mÂ³)")  # Ubah satuan jika perlu
    plt.xticks(rotation=45)
    plt.legend()
    plt.grid(False)
    plt.tight_layout()

# 6. Tampilkan tabel ozon per kota dan bulan untuk tiap tahun
for tahun in tahun_list:
    print(f"\nTabel Konsentrasi Ozon Tahun {tahun}")

    df_tahun = df[df['Tahun'] == tahun]

    # Buat pivot table: index = Nama_Bulan, columns = Kota, values = Ozon
    tabel = df_tahun.pivot(index='Nama_Bulan', columns='Kota', values='Ozon')

    # Susun urutan bulan
    tabel = tabel.reindex(urutan_bulan)

    print(tabel.round(2))  # Membulatkan nilai ke 2 desimal



# Simpan ke Excel, satu sheet per tahun
excel_path = "/content/drive/MyDrive/PENGOLAHAN/HASIL/tabel_ozon_per_kota_per_tahun_EN.xlsx"
with pd.ExcelWriter(excel_path) as writer:
    for tahun in tahun_list:
        df_tahun = df[df['Tahun'] == tahun]
        tabel = df_tahun.pivot(index='Nama_Bulan', columns='Kota', values='Ozon')
        tabel = tabel.reindex(urutan_bulan)
        tabel.to_excel(writer, sheet_name=str(tahun))

# prompt: bagaimana membuat tabelnya nilai konsentrasi ozon tiap stasiun perbulan selama 2022-2024

# === 1. Baca file CSV hasil zonal statistik
csv_path = "/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/zonal_statistik_ozon_dki.csv"
df = pd.read_csv(csv_path)

# 2. Ubah kolom waktu ke datetime dan buat kolom tahun dan bulan
df['Waktu'] = pd.to_datetime(df['Waktu'], format="%Y-%m")
df['Tahun'] = df['Waktu'].dt.year
df['Bulan'] = df['Waktu'].dt.month

# 3. Filter data untuk tahun 2022, 2023, dan 2024
df_filtered = df[(df['Tahun'] >= 2022) & (df['Tahun'] <= 2024)].copy()

# 4. Buat pivot table untuk menghasilkan tabel nilai konsentrasi ozon per stasiun dan per bulan
# Asumsikan "Kota" di sini merepresentasikan "stasiun" berdasarkan konteks sebelumnya yang memfilter per WADMKK
# Pivot table akan memiliki "Kota" sebagai index, "Waktu" sebagai kolom, dan "Ozon" sebagai nilai
table_ozon = df_filtered.pivot_table(index='Kota', columns='Waktu', values='Ozon', aggfunc='mean')

# 5. Tampilkan tabel
print("Tabel Rata-rata Konsentrasi Ozon (Âµg/mÂ³) per Kota per Bulan (2022-2024):")
# Format float ke 2 angka desimal
table_ozon_formatted = table_ozon.applymap(lambda x: f"{x:.2f}" if pd.notna(x) else "")
display(table_ozon_formatted)

# 6. Simpan tabel ke CSV
output_table_path = "/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/tabel_ozon_kota_bulanan_2022-2024.csv"
table_ozon.to_csv(output_table_path)
print(f"\nTabel juga disimpan ke: {output_table_path}")

# prompt: menampilkan kota dengan nilai konsentrasi ozon tertinggi dan terendah setiap bulan

# 7. Temukan kota dengan nilai tertinggi dan terendah setiap bulan
print("\nKota dengan Konsentrasi Ozon Tertinggi dan Terendah setiap Bulan:")
for waktu in df_filtered['Waktu'].unique():
    df_bulan = df_filtered[df_filtered['Waktu'] == waktu].dropna(subset=['Ozon'])

    if df_bulan.empty:
        print(f"Data untuk {waktu.strftime('%Y-%m')} tidak tersedia atau kosong setelah filtering.")
        continue

    # Temukan kota dengan ozon tertinggi
    kota_max = df_bulan.loc[df_bulan['Ozon'].idxmax()]
    # Temukan kota dengan ozon terendah
    kota_min = df_bulan.loc[df_bulan['Ozon'].idxmin()]

    print(f"  {waktu.strftime('%Y-%m')}:")
    print(f"    Tertinggi: {kota_max['Kota']} ({kota_max['Ozon']:.2f} Âµg/mÂ³)")
    print(f"    Terendah: {kota_min['Kota']} ({kota_min['Ozon']:.2f} Âµg/mÂ³)")

# prompt: gimana kalau rata-rata nilai ozon tiap musimnya per tahun

from collections import defaultdict

# 1. Baca file CSV hasil zonal statistik
csv_path = "/content/drive/MyDrive/PENGOLAHAN/HASIL/ESTIMASI OZON PERMUKAAN JAKARTA/zonal_statistik_ozon_dki.csv"
df = pd.read_csv(csv_path)

# 2. Ubah kolom waktu ke datetime dan buat kolom tahun dan bulan
df['Waktu'] = pd.to_datetime(df['Waktu'], format="%Y-%m")
df['Tahun'] = df['Waktu'].dt.year
df['Bulan'] = df['Waktu'].dt.month

# 3. Buat kolom Musim
# Contoh pembagian musim:
# Musim Hujan: Desember, Januari, Februari
# Musim Pancaroba I: Maret, April
# Musim Kemarau: Mei, Juni, Juli, Agustus, September, Oktober
# Musim Pancaroba II: November
def get_musim(month):
    if month in [12, 1, 2]:
        return 'Musim Hujan'
    elif month in [3, 4]:
        return 'Musim Pancaroba I'
    elif month in [5, 6, 7, 8, 9, 10]:
        return 'Musim Kemarau'
    elif month == 11:
        return 'Musim Pancaroba II'
    else:
        return 'Tidak Diketahui'

df['Musim'] = df['Bulan'].apply(get_musim)

# 4. Hitung rata-rata ozon per musim dan per tahun
average_ozon_per_season_year = df.groupby(['Tahun', 'Musim'])['Ozon'].mean().reset_index()

# 5. Tampilkan hasilnya
print("Rata-rata Konsentrasi Ozon (Âµg/mÂ³) per Musim per Tahun:")
# Urutkan berdasarkan Tahun dan Musim (manual order untuk musim)
musim_order = ['Musim Hujan', 'Musim Pancaroba I', 'Musim Kemarau', 'Musim Pancaroba II']
average_ozon_per_season_year['Musim'] = pd.Categorical(average_ozon_per_season_year['Musim'], categories=musim_order, ordered=True)
average_ozon_per_season_year = average_ozon_per_season_year.sort_values(['Tahun', 'Musim'])

print(average_ozon_per_season_year.to_markdown(index=False, floatfmt=".2f"))

# Opsional: Visualisasi Tren Musiman Tahunan
plt.figure(figsize=(12, 6))
sns.lineplot(data=average_ozon_per_season_year, x='Musim', y='Ozon', hue='Tahun', marker='o')

plt.title("Tren Konsentrasi Ozon Tahunan per Musim di DKI Jakarta")
plt.xlabel("Musim")
plt.ylabel("Rata-rata Konsentrasi Ozon (Î¼g/mÂ³)")
plt.xticks(rotation=45)
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()